{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Prophet-Andrew-Ng/blob/main/langchain/%E6%9D%8E%E9%B2%81%E9%B2%81%E5%AD%A6LangChain_25_Kor%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 李鲁鲁学LangChain 25 Kor信息抽取\n",
        "\n",
        "这是李鲁鲁的学习笔记，对Sam Witteveen的油管课程的记录\n",
        "\n",
        "增加了李鲁鲁学习时候的吐槽\n",
        "\n",
        "因为一个独立的md文件导入知乎会更方便，所以这个课程的笔记会记录在md中\n",
        "\n",
        "比如这节课在\n",
        "\n",
        "https://github.com/LC1332/Prophet-Andrew-Ng/blob/main/langchain/%E6%9D%8E%E9%B2%81%E9%B2%81%E5%AD%A6LangChain%2025.md\n",
        "\n",
        "欢迎访问[骆驼项目](https://github.com/LC1332/Luotuo-Chinese-LLM)主页和点赞\n",
        "\n",
        "这篇笔记同时也是我们用来抽取Chat凉宫春日台本的原型代码"
      ],
      "metadata": {
        "id": "XgYaoQc_-iiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://eyurtsev.github.io/kor/nested_objects.html"
      ],
      "metadata": {
        "id": "nDnYqwFcwLiF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRYSu48huSUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82b089c-ae78-488a-eb2d-ce4e90d4fb85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai google-search-results tiktoken\n",
        "!pip -q install kor markdownify"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "id": "J-KFB7J_u_3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a1cb1d-acad-45d3-c8cc-5f3d65d2414c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.245\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://www.github.com/hwchase17/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, langsmith, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: kor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kor.extraction import create_extraction_chain\n",
        "from kor.nodes import Object, Text, Number\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "4g4MiT_ZBiNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2oZ858-xUjFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "1zM0lwApu8jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = Object(\n",
        "    id=\"personal_info\",\n",
        "    description=\"Personal information about a given person.\",\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"first_name\",\n",
        "            description=\"The first name of the person\",\n",
        "            # examples=[(\"John Smith went to the store\", \"John\")]\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"last_name\",\n",
        "            description=\"The last name of the person\",\n",
        "            # examples=[(\"John Smith went to the store\", \"Smith\")],\n",
        "        ),\n",
        "        Number(\n",
        "            id=\"age\",\n",
        "            description=\"The age of the person in years.\",\n",
        "            # examples=[(\"23 years old\", \"23\"), (\"I turned three on sunday\", \"3\")]\n",
        "        ),\n",
        "    ],\n",
        "    examples=[\n",
        "        (\n",
        "            \"John Smith was 23 years old. He was very tall. He knew Jane Doe. She was 5 years old.\",\n",
        "            [\n",
        "                {\"first_name\": \"John\", \"last_name\": \"Smith\", \"age\": 23},\n",
        "                {\"first_name\": \"Jane\", \"last_name\": \"Doe\", \"age\": 5},\n",
        "            ],\n",
        "        )\n",
        "    ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "PkGvJwaRv-zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain(llm, schema)\n",
        "print(chain.prompt.format_prompt(text=\"[user input]\").to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVawvIr42EUI",
        "outputId": "042eafb0-6d37-474d-d5da-355c13f99eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
            "\n",
            "```TypeScript\n",
            "\n",
            "personal_info: Array<{ // Personal information about a given person.\n",
            " first_name: string // The first name of the person\n",
            " last_name: string // The last name of the person\n",
            " age: number // The age of the person in years.\n",
            "}>\n",
            "```\n",
            "\n",
            "\n",
            "Please output the extracted information in CSV format in Excel dialect. Please use a | as the delimiter. \n",
            " Do NOT add any clarifying information. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.\n",
            "\n",
            "\n",
            "\n",
            "Input: John Smith was 23 years old. He was very tall. He knew Jane Doe. She was 5 years old.\n",
            "Output: first_name|last_name|age\n",
            "John|Smith|23\n",
            "Jane|Doe|5\n",
            "\n",
            "Input: [user input]\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\n",
        "        \"My name is Bob Alice and my phone number is (123)-444-9999. I found my true love one\"\n",
        "        \" on a blue sunday. Her number was (333)1232832. Her name was Moana Sunrise and she was 10 years old.\"\n",
        ")[\"data\"]"
      ],
      "metadata": {
        "id": "l17LdCANwBLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-Uf\""
      ],
      "metadata": {
        "id": "tYmHuVzVAEbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "I513A3A4AOyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 长的prompt\n",
        "\n",
        "schema = Object(\n",
        "    id=\"script\",\n",
        "    description=\"Adapted from the novel into script\",\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"role\",\n",
        "            description=\"The character who is speaking or performing an action\",\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"dialogue\",\n",
        "            description=\"The dialogue spoken by the characters in the sentence\",\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"action\",\n",
        "            description='''The actions performed by the characters in the text, A high-level summary of a character's behavior. action equals \"对话\" or \"独白\" if it's dialogue in sentence, equals other action if it's no dialogue''',\n",
        "        )\n",
        "    ],\n",
        "    examples=[\n",
        "        (\n",
        "            '''韦小宝心中闪过一个念头：“我如得了这一千两赏银，我和妈娘儿俩可有得花了，鸡鸭鱼肉，赌钱玩乐，几年也花不光。”见茅十八仍是侧头瞧着自己，脸上神气颇有些古怪，韦小宝怒道：“你心里在想什么你猜我会去通风报信，领这赏银”茅十八道：“是啊，白花花的银子，谁又不爱”''',\n",
        "            [\n",
        "                {\"role\": \"韦小宝\", \"dialogue\": \"我如得了这一千两赏银，我和妈娘儿俩可有得花了，鸡鸭鱼肉，赌钱玩乐，几年也花不光。\",\"action\":\"独白\"},\n",
        "                {\"role\": \"韦小宝\", \"dialogue\": \"你心里在想什么你猜我会去通风报信，领这赏银。\",\"action\":\"对话\"},\n",
        "                {\"role\": \"茅十八\", \"dialogue\": \"是啊，白花花的银子，谁又不爱。\",\"action\":\"对话\"},\n",
        "            ],\n",
        "        ),\n",
        "        (\n",
        "            '''澄观一直站在禅房门口等候。他内力深厚，韦小宝和那女郎的对答，虽微声细语，亦无不入耳，只觉这位师叔“劝说”女施主的言语，委实高深莫测，什么老公、老婆、孙子、爷爷，似乎均与武功无关，正自感佩赞叹，听得他问起解穴之法，忙道：“这位女施主被封的是大包穴，乃属足太阴脾经，师叔替她在腿上箕门、血海两处穴道推血过宫，即可解开。”''',\n",
        "            [\n",
        "                {\"role\": \"澄观\", \"dialogue\": \"\",\"action\":\"站在禅房门口听韦小宝和女郎对话，听到韦小宝询问解穴方法\"},\n",
        "                {\"role\": \"澄观\", \"dialogue\": \"这位女施主被封的是大包穴，乃属足太阴脾经，师叔替她在腿上箕门、血海两处穴道推血过宫，即可解开。\",\"action\":\"对话\"},\n",
        "            ],\n",
        "        )\n",
        "    ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DZlfwc5f33v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 短的prompt\n",
        "\n",
        "schema = Object(\n",
        "    id=\"script\",\n",
        "    description=\"Adapted from the novel into script\",\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"role\",\n",
        "            description=\"The character who is speaking or performing an action\",\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"dialogue\",\n",
        "            description=\"The dialogue spoken by the characters in the sentence\",\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"action\",\n",
        "            description='''The actions performed by the characters in the text, A high-level summary of a character's behavior. action equals \"对话\" or \"独白\" if it's dialogue in sentence, equals other action if it's no dialogue''',\n",
        "        )\n",
        "    ],\n",
        "    examples=[\n",
        "        (\n",
        "            '''韦小宝心中闪过一个念头：“我如得了这一千两，我和妈娘儿俩可有得花了” 见茅十八仍是侧头瞧着自己，韦小宝怒道：“你肯定猜我会去通风报信，领这赏银”茅十八道：“是啊，银子谁不爱”''',\n",
        "            [\n",
        "                {\"role\": \"韦小宝\", \"dialogue\": \"我如得了这一千两赏银，我和妈娘儿俩可有得花了\",\"action\":\"独白\"},\n",
        "                {\"role\": \"韦小宝\", \"dialogue\": \"你肯定猜我会去通风报信，领这赏银\",\"action\":\"对话\"},\n",
        "                {\"role\": \"茅十八\", \"dialogue\": \"是啊，银子谁不爱\",\"action\":\"对话\"},\n",
        "            ],\n",
        "        ),\n",
        "        (\n",
        "            '''澄观一直站在禅房门口等候。韦小宝和那女郎的对答，虽微声细语，亦无不入耳，只觉这位师叔“劝说”女施主的言语，委实高深莫测，正自感佩赞叹，听得他问起解穴之法，忙道：“这位女施主被封的是大包穴，师叔替她解开即可”''',\n",
        "            [\n",
        "                {\"role\": \"澄观\", \"dialogue\": \"\",\"action\":\"站在禅房门口听韦小宝和女郎对话，听到韦小宝询问解穴方法\"},\n",
        "                {\"role\": \"澄观\", \"dialogue\": \"这位女施主被封的是大包穴，师叔替她解开即可\",\"action\":\"对话\"},\n",
        "            ],\n",
        "        )\n",
        "    ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "sLNmvOdpAZix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain(llm, schema)\n",
        "print(chain.prompt.format_prompt(text=\"[user input]\").to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8KGE31z5oOy",
        "outputId": "2ab78c49-b573-47c1-8efb-ecc593a98830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
            "\n",
            "```TypeScript\n",
            "\n",
            "script: Array<{ // Adapted from the novel into script\n",
            " role: string // The character who is speaking or performing an action\n",
            " dialogue: string // The dialogue spoken by the characters in the sentence\n",
            " action: string // The actions performed by the characters in the text, A high-level summary of a character's behavior. action equals \"对话\" or \"独白\" if it's dialogue in sentence, equals other action if it's no dialogue\n",
            "}>\n",
            "```\n",
            "\n",
            "\n",
            "Please output the extracted information in CSV format in Excel dialect. Please use a | as the delimiter. \n",
            " Do NOT add any clarifying information. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.\n",
            "\n",
            "\n",
            "\n",
            "Input: 韦小宝心中闪过一个念头：“我如得了这一千两，我和妈娘儿俩可有得花了” 见茅十八仍是侧头瞧着自己，韦小宝怒道：“你肯定猜我会去通风报信，领这赏银”茅十八道：“是啊，银子谁不爱”\n",
            "Output: role|dialogue|action\n",
            "韦小宝|我如得了这一千两赏银，我和妈娘儿俩可有得花了|独白\n",
            "韦小宝|你肯定猜我会去通风报信，领这赏银|对话\n",
            "茅十八|是啊，银子谁不爱|对话\n",
            "\n",
            "Input: 澄观一直站在禅房门口等候。韦小宝和那女郎的对答，虽微声细语，亦无不入耳，只觉这位师叔“劝说”女施主的言语，委实高深莫测，正自感佩赞叹，听得他问起解穴之法，忙道：“这位女施主被封的是大包穴，师叔替她解开即可”\n",
            "Output: role|dialogue|action\n",
            "澄观||站在禅房门口听韦小宝和女郎对话，听到韦小宝询问解穴方法\n",
            "澄观|这位女施主被封的是大包穴，师叔替她解开即可|对话\n",
            "\n",
            "Input: [user input]\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.run(\n",
        "        \"\"\"黄龙使殷锦忙道：“夫人高见。取经之事，想来和福份大小，干系极大。黑龙使也不是不努力。不肯替教主立功，可是始终阻难重重，多半是福气不够，因此宝经难以到手。”洪夫人微笑道：“依你之见，谁的福份够呢”殷锦道：“本教福气最大的，自然是教主他老人家，其次是夫人。不过总不能劳动两位大驾亲自出马。更其次福份最大的，首推白龙使。他识得碣文，又立下大功，印堂隐隐透出红光，福份之大，教主属下无人能出其右。”\n",
        "\n",
        "    教主捻须微笑，道：“但他小小孩童，能担当这件大任么”\n",
        "\n",
        "    白龙使一职，在神龙教虽然甚尊，在韦小宝心里，却半点份量也没有，他既陷身岛上，只好随遇而安，瞧着闭月羞花的洪夫人。自是过瘾之极，但瞧得多了，如给教主发觉自己色迷迷的神色，难免有杀身之祸，还是尽速回北京为妙，听教主这么说，正是脱身的良机，便道：“教主，夫人，承蒙提拔，属下十分感激，我本事是没有的，但托了两位大福气，混进皇宫中去偷这四部宝经，倒也有成功的指望。”洪教主点了点头。洪夫人喜道：“你肯自告奋勇，足见对教主忠心。我知你聪明伶俐，福份又大，恐怕正是上天派来给教主办成这件大事的。”\"\"\"\n",
        ")[\"data\"]"
      ],
      "metadata": {
        "id": "qM6VaR_E_pL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chat in (response['script']):\n",
        "    print(chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH2uM7E1UvN1",
        "outputId": "91a9d7a7-0db2-4fce-940e-e4fd15ce12ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'role': '黄龙使殷锦', 'dialogue': '夫人高见。取经之事，想来和福份大小，干系极大。黑龙使也不是不努力。不肯替教主立功，可是始终阻难重重，多半是福气不够，因此宝经难以到手。', 'action': '对话'}\n",
            "{'role': '洪夫人', 'dialogue': '依你之见，谁的福份够呢', 'action': '对话'}\n",
            "{'role': '殷锦', 'dialogue': '本教福气最大的，自然是教主他老人家，其次是夫人。不过总不能劳动两位大驾亲自出马。更其次福份最大的，首推白龙使。他识得碣文，又立下大功，印堂隐隐透出红光，福份之大，教主属下无人能出其右。', 'action': '对话'}\n",
            "{'role': '教主', 'dialogue': '但他小小孩童，能担当这件大任么', 'action': '对话'}\n",
            "{'role': '白龙使', 'dialogue': '教主，夫人，承蒙提拔，属下十分感激，我本事是没有的，但托了两位大福气，混进皇宫中去偷这四部宝经，倒也有成功的指望。', 'action': '对话'}\n",
            "{'role': '洪教主', 'dialogue': '点了点头', 'action': '对话'}\n",
            "{'role': '洪夫人', 'dialogue': '你肯自告奋勇，足见对教主忠心。我知你聪明伶俐，福份又大，恐怕正是上天派来给教主办成这件大事的。', 'action': '对话'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Kpz64jxVNzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们来批量运行下这个代码"
      ],
      "metadata": {
        "id": "bLGyUNRNVOfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAQGV1OBVQVh",
        "outputId": "7540b7bf-37a6-4fc0-c302-0e9b37e6fdd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "save_folder = \"/content/drive/MyDrive/GPTData/weixiaobao_extract\"\n",
        "\n",
        "确认这个folder的存在性，如果不存在这个folder，则新建这个folder"
      ],
      "metadata": {
        "id": "V0iqMBwlVy_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/GPTData/weixiaobao_extract\"\n",
        "\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder)"
      ],
      "metadata": {
        "id": "CnnOHg9tVZRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/LC1332/Prophet-Andrew-Ng/main/langchain/%E9%B9%BF%E9%BC%8E%E8%AE%B0.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nm1Uuk3V9zd",
        "outputId": "c062bf04-a81f-44d9-dd2d-83847f962ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-28 07:13:39--  https://raw.githubusercontent.com/LC1332/Prophet-Andrew-Ng/main/langchain/%E9%B9%BF%E9%BC%8E%E8%AE%B0.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3701970 (3.5M) [text/plain]\n",
            "Saving to: ‘鹿鼎记.txt’\n",
            "\n",
            "鹿鼎记.txt          100%[===================>]   3.53M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-07-28 07:13:40 (40.3 MB/s) - ‘鹿鼎记.txt’ saved [3701970/3701970]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read /content/鹿鼎记.txt into python string raw_text\n",
        "with open('/content/鹿鼎记.txt', 'r', encoding='utf-8') as f:\n",
        "    raw_text = f.read()"
      ],
      "metadata": {
        "id": "hWfr_Y8sWLNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "根据\\n将 raw_text的文本切开，存储到split_text中，用python实现"
      ],
      "metadata": {
        "id": "xTwe_-i4WeyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_text = raw_text.split('\\n')"
      ],
      "metadata": {
        "id": "DQWdB0gsWaUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(split_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY6uOb01WstC",
        "outputId": "7d062b9e-4053-4d28-c945-05f7321be69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install tiktoken"
      ],
      "metadata": {
        "id": "8IyZrBpgW0Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")"
      ],
      "metadata": {
        "id": "h-C1RNpKW7oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split_text中存储着一个python的list of string\n",
        "\n",
        "已知 len(enc.encode( my_str )) 会计算my_str的token长度\n",
        "\n",
        "定义max_token_len = 1000\n",
        "\n",
        "生成一个新的数组chunk_text\n",
        "\n",
        "里面的每个元素分别是split_text的顺序拼接\n",
        "\n",
        "保证每个chunk_text的长度不要超过max_token_len"
      ],
      "metadata": {
        "id": "UNq4LCUcXAIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_token_len = 1000\n",
        "chunk_text = []\n",
        "\n",
        "curr_len = 0\n",
        "curr_chunk = ''\n",
        "\n",
        "for line in split_text:\n",
        "  line_len = len(enc.encode( line ))\n",
        "\n",
        "  if line_len > max_token_len:\n",
        "    print('warning line_len = ', line_len)\n",
        "\n",
        "  if curr_len + line_len <= max_token_len:\n",
        "    curr_chunk += line\n",
        "    curr_chunk += '\\n'\n",
        "    curr_len += line_len\n",
        "    curr_len += 1\n",
        "  else:\n",
        "    chunk_text.append(curr_chunk)\n",
        "    curr_chunk = line\n",
        "    curr_len = line_len\n",
        "\n",
        "if curr_chunk:\n",
        "  chunk_text.append(curr_chunk)"
      ],
      "metadata": {
        "id": "XLbrbDVdXl97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(chunk_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-EMviXjXzXr",
        "outputId": "ab37aa11-775a-4b35-d860-28b40595978e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunk_text[123])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACsB7DthYD-o",
        "outputId": "db5d7e57-3482-4485-f58f-0de7c446466c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    韦小宝回到屋中，向海老公道：“公公，你的法子不管用，太也稀松平常。”海老公哼了一声，说道：“没出息，又打输了。”韦小宝道：“如果用我自己的法子，虽然不一定准赢，也不见得准输。可是你的法子太也脓包，人家也都会的，有什么希奇”海老公奇道：“他也知道这法子你试给我瞧瞧。”韦小宝心想：“你眼睛瞎了，试给你看看，难道你看得见么”突然心念一动：“不知他是真瞎还是假瞎，可得试他一试。”当即双肘向后一撞，道：“他这么一撞，只撞得我全身三千根骨头，根根都痛。”海老公叹了口气，道：“你说这么一撞，我又怎瞧得见”颤巍巍的站起身来，道：“你试着学他的样。”韦小宝心下暗喜：“老乌龟是真的瞎了。”背心向着他，挺肘缓缓向后撞去，道：“他用手肘这样撞我。”待得手肘碰到了海老公胸口，便不再使力。海老公嗯了一声，说道：“这是腋底锤，那也算不了什么。”韦小宝道：“还有这样。”拉住了海老公左手，放在自己右肩，说道：“他用力一甩，我身子便从他头顶飞了过去。”这一招其实是他甩倒小玄子的得意之作，故意倒转来说，要考一考海老公。海老公道：“这是羚羊挂角。”韦小宝道：“原来你早知道了。”跟着拉住他手臂，慢慢而后拗转。海老公道：“嗯，这是倒折梅中的第三手。还有什么”\n",
            "    韦小宝道：“原来小玄子这些手法都有名堂，我跟他乱打乱扭，那些手段可也得有几个好听的名堂才成啊。我向他扑过去，这小子向旁闪开，却在我背上顺势一推，我就”海老公不等他说完，便问：“他推在你哪里”韦小宝道：“他一推我便摔得七荤八素，怎还记得推在哪里。”海老公道：“你记记看。是推在这里么”说着伸手按在他左肩背后。韦小宝道：“不是。”海老公道：“是这里么”按在他右肩背后。韦小宝仍道：“不是。”海老公连按了六七个部位，韦小宝都说不是。海老公伸掌按在他右腰肋骨之下，问道：“是这里么”说着轻轻一推。韦小宝一个踉跄，跌出几步，立时记起小玄子推他的正是这个所在，大声道：“是了，一点不错，正是这里。公公，你怎么知道”\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.run( chunk_text[123] )[\"data\"]"
      ],
      "metadata": {
        "id": "9QCKCgN-YNQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chat in (response['script']):\n",
        "    print(chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZjZXICyYVIi",
        "outputId": "003ba896-877f-4176-a775-6f9aafbb473d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'role': '韦小宝', 'dialogue': '公公，你的法子不管用，太也稀松平常', 'action': '对话'}\n",
            "{'role': '海老公', 'dialogue': '没出息，又打输了', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '如果用我自己的法子，虽然不一定准赢，也不见得准输。可是你的法子太也脓包，人家也都会的，有什么希奇', 'action': '对话'}\n",
            "{'role': '海老公', 'dialogue': '他也知道这法子你试给我瞧瞧', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '他这么一撞，只撞得我全身三千根骨头，根根都痛', 'action': '独白'}\n",
            "{'role': '海老公', 'dialogue': '你说这么一撞，我又怎瞧得见', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '你试着学他的样', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '他用手肘这样撞我', 'action': '独白'}\n",
            "{'role': '海老公', 'dialogue': '这是腋底锤，那也算不了什么', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '还有这样', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '他用力一甩，我身子便从他头顶飞了过去', 'action': '独白'}\n",
            "{'role': '海老公', 'dialogue': '这是羚羊挂角', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '原来你早知道了', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '他一推我便摔得七荤八素，怎还记得推在哪里', 'action': '独白'}\n",
            "{'role': '海老公', 'dialogue': '你记记看。是推在这里么', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '不是', 'action': '独白'}\n",
            "{'role': '海老公', 'dialogue': '是这里么', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '不是', 'action': '独白'}\n",
            "{'role': '海老公', 'dialogue': '是这里么', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '不是', 'action': '独白'}\n",
            "{'role': '海老公', 'dialogue': '是这里么', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '不是', 'action': '独白'}\n",
            "{'role': '海老公', 'dialogue': '是这里么', 'action': '对话'}\n",
            "{'role': '韦小宝', 'dialogue': '是了，一点不错，正是这里。公公，你怎么知道', 'action': '对话'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4LRMzfCvZnT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(chunk_text)):\n"
      ],
      "metadata": {
        "id": "Xhtyi5HYZZG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "已知\n",
        "for chat in (response['script']):\n",
        "    print(chat)\n",
        "\n",
        "的输出结果如下\n",
        "\n",
        "{'role': '韦小宝', 'dialogue': '公公，你的法子不管用，太也稀松平常', 'action': '对话'}\n",
        "{'role': '海老公', 'dialogue': '没出息，又打输了', 'action': '对话'}\n",
        "{'role': '韦小宝', 'dialogue': '如果用我自己的法子，虽然不一定准赢，也不见得准输。可是你的法子太也脓包，人家也都会的，有什么希奇', 'action': '对话'}\n",
        "{'role': '海老公', 'dialogue': '他也知道这法子你试给我瞧瞧', 'action': '对话'}\n",
        "{'role': '韦小宝', 'dialogue': '他这么一撞，只撞得我全身三千根骨头，根根都痛', 'action': '独白'}\n",
        "\n",
        "定义save_name = 'output.jsonl'\n",
        "\n",
        "将程序改写为把response['script']中的内容保存到save_name"
      ],
      "metadata": {
        "id": "59U2lbEBYiY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "# save_name = '/content/test_output.jsonl'\n",
        "\n",
        "# with open(save_name, 'w', encoding='utf-8') as f:\n",
        "\n",
        "#   for chat in response['script']:\n",
        "\n",
        "#     json_str = json.dumps(chat, ensure_ascii=False)\n",
        "#     f.write(json_str+\"\\n\")"
      ],
      "metadata": {
        "id": "-yeeomNqY3zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "save_folder = \"/content/drive/MyDrive/GPTData/weixiaobao_extract\"\n",
        "\n",
        "i从0到100循环\n",
        "\n",
        "根据数字i 组织一个jsonl的保存文件名\n",
        "\n",
        "如果文件名对应的文件已经存在，则跳过当前步骤\n",
        "\n",
        "不然则运行\n",
        "\n",
        "```python\n",
        "with open(save_name, 'w', encoding='utf-8') as f:\n",
        "\n",
        "  for chat in response['script']:\n",
        "    \n",
        "    json_str = json.dumps(chat, ensure_ascii=False)\n",
        "    f.write(json_str+\"\\n\")\n",
        "```\n",
        "\n",
        "进行写文件\n",
        "\n",
        "整体的循环再增加一个进度条提示\n"
      ],
      "metadata": {
        "id": "MPrbgx8HZ5By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/GPTData/weixiaobao_extract\"\n",
        "\n",
        "for i in tqdm(range(29,len(chunk_text))):\n",
        "\n",
        "  save_name = os.path.join(save_folder, f\"{i}.txt\")\n",
        "\n",
        "  if os.path.exists(save_name):\n",
        "    continue\n",
        "\n",
        "  response = chain.run( chunk_text[i] )[\"data\"]\n",
        "\n",
        "  with open(save_name, 'w', encoding='utf-8') as f:\n",
        "\n",
        "    if 'script' not in response:\n",
        "        print('Error: response does not contain key \"script\"')\n",
        "    else:\n",
        "        for chat in response['script']:\n",
        "            json_str = json.dumps(chat, ensure_ascii=False)\n",
        "            f.write(json_str+\"\\n\")\n",
        "\n",
        "\n",
        "#   break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJgsmT_4aHOi",
        "outputId": "3c0b1c8c-7da6-41f1-b81f-042ebca9ef44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 33/1847 [07:26<9:27:51, 18.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 44/1847 [10:33<9:33:28, 19.08s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 28 Jul 2023 07:59:23 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7edb8cfdc8b149fa-TPE', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            "  6%|▌         | 105/1847 [34:02<10:06:24, 20.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 131/1847 [42:18<5:48:16, 12.18s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            "  8%|▊         | 148/1847 [46:50<7:23:31, 15.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 168/1847 [52:23<8:26:44, 18.11s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 10%|█         | 186/1847 [58:02<8:54:26, 19.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 205/1847 [1:03:27<9:04:34, 19.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 226/1847 [1:09:02<9:04:50, 20.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 245/1847 [1:14:29<8:26:02, 18.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 246/1847 [1:14:52<9:03:16, 20.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 251/1847 [1:16:54<10:11:00, 22.97s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 14%|█▎        | 252/1847 [1:17:34<12:33:09, 28.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 258/1847 [1:19:17<7:40:58, 17.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 270/1847 [1:22:50<8:54:55, 20.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 301/1847 [1:32:09<6:06:39, 14.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 302/1847 [1:32:40<8:15:13, 19.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 315/1847 [1:36:02<6:52:58, 16.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 328/1847 [1:39:31<8:49:57, 20.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▊        | 342/1847 [1:42:29<5:30:05, 13.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▊        | 345/1847 [1:43:25<7:21:56, 17.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 349/1847 [1:44:03<4:53:10, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 365/1847 [1:48:30<6:56:48, 16.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 385/1847 [1:53:56<5:40:36, 13.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 391/1847 [1:55:58<8:32:10, 21.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 401/1847 [1:59:32<9:14:26, 23.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 411/1847 [2:02:39<7:58:46, 20.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 417/1847 [2:04:29<7:11:18, 18.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 420/1847 [2:05:44<9:16:08, 23.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 427/1847 [2:08:18<8:35:09, 21.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 429/1847 [2:09:03<8:38:33, 21.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 432/1847 [2:09:58<7:19:34, 18.64s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 28 Jul 2023 09:59:20 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7edc3cae8bc64a52-TPE', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 24%|██▍       | 446/1847 [2:20:10<6:48:39, 17.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 449/1847 [2:21:11<7:40:03, 19.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 480/1847 [2:29:24<5:30:44, 14.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 482/1847 [2:29:59<6:26:57, 17.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 483/1847 [2:30:16<6:23:33, 16.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 498/1847 [2:34:07<6:05:01, 16.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 500/1847 [2:34:40<6:14:01, 16.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 533/1847 [2:44:16<6:22:13, 17.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 548/1847 [2:47:53<5:36:22, 15.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 550/1847 [2:48:29<6:11:14, 17.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 560/1847 [2:50:50<5:10:46, 14.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 574/1847 [2:55:03<11:08:56, 31.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 640/1847 [3:10:36<3:49:15, 11.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 641/1847 [3:11:10<6:05:01, 18.16s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 35%|███▌      | 647/1847 [3:13:17<5:33:38, 16.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 658/1847 [3:15:33<4:01:41, 12.20s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 36%|███▌      | 664/1847 [3:17:37<4:48:46, 14.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 669/1847 [3:18:48<4:53:22, 14.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 684/1847 [3:22:21<5:04:21, 15.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 689/1847 [3:23:34<4:47:04, 14.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 711/1847 [3:28:55<5:17:38, 16.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 716/1847 [3:30:02<4:54:56, 15.65s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 39%|███▉      | 717/1847 [3:31:01<8:56:59, 28.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 733/1847 [3:34:37<4:12:50, 13.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 745/1847 [3:37:43<6:07:57, 20.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 751/1847 [3:38:54<4:19:34, 14.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 756/1847 [3:40:21<5:44:56, 18.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 758/1847 [3:40:58<5:33:25, 18.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 773/1847 [3:44:33<3:36:41, 12.11s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 42%|████▏     | 774/1847 [3:45:32<7:45:10, 26.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 775/1847 [3:45:57<7:42:11, 25.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 794/1847 [3:51:18<4:44:35, 16.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 799/1847 [3:52:43<4:52:20, 16.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 802/1847 [3:53:49<6:04:43, 20.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 812/1847 [3:56:44<4:37:23, 16.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 823/1847 [3:59:09<3:57:37, 13.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 830/1847 [4:01:24<5:57:20, 21.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 835/1847 [4:02:35<4:38:56, 16.54s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 45%|████▌     | 836/1847 [4:03:28<7:46:09, 27.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 838/1847 [4:04:22<7:39:15, 27.31s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 46%|████▌     | 842/1847 [4:05:56<5:43:05, 20.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 843/1847 [4:06:16<5:41:46, 20.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 872/1847 [4:15:24<4:06:46, 15.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 888/1847 [4:20:21<4:53:42, 18.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▊     | 896/1847 [4:22:43<4:23:04, 16.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 924/1847 [4:30:13<4:26:04, 17.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 934/1847 [4:32:41<3:28:47, 13.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 942/1847 [4:35:29<5:17:52, 21.07s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 28 Jul 2023 12:24:22 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7edd11132eee4a01-TPE', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 52%|█████▏    | 958/1847 [4:45:59<4:37:49, 18.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 962/1847 [4:47:31<5:25:25, 22.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 970/1847 [4:50:08<5:01:01, 20.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 972/1847 [4:50:32<3:56:49, 16.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 989/1847 [4:56:40<6:14:23, 26.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 992/1847 [4:57:36<4:47:48, 20.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 54%|█████▍    | 1000/1847 [5:01:04<5:59:40, 25.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 1014/1847 [5:05:56<5:01:40, 21.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▋    | 1041/1847 [5:15:40<4:26:58, 19.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 1052/1847 [5:18:33<3:51:48, 17.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 1065/1847 [5:22:59<4:37:15, 21.27s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 58%|█████▊    | 1080/1847 [5:28:22<4:25:35, 20.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 1085/1847 [5:31:12<6:00:06, 28.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 1086/1847 [5:31:43<6:08:40, 29.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 1091/1847 [5:33:09<4:27:29, 21.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 1098/1847 [5:35:24<4:11:37, 20.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 1110/1847 [5:39:59<4:40:20, 22.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 1120/1847 [5:43:21<4:02:15, 19.99s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 61%|██████    | 1129/1847 [5:47:06<3:41:35, 18.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████▏   | 1132/1847 [5:47:59<3:32:26, 17.83s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 61%|██████▏   | 1134/1847 [5:48:59<4:18:55, 21.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 1138/1847 [5:50:16<4:23:27, 22.30s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 62%|██████▏   | 1142/1847 [5:51:52<4:21:44, 22.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 1159/1847 [5:57:47<3:46:21, 19.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 1164/1847 [5:59:06<3:03:59, 16.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 1168/1847 [6:00:40<4:09:16, 22.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 1179/1847 [6:03:31<3:10:40, 17.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 1185/1847 [6:05:35<4:10:05, 22.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 1196/1847 [6:09:07<3:54:34, 21.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 1197/1847 [6:09:38<4:26:16, 24.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 1198/1847 [6:09:58<4:10:19, 23.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 1201/1847 [6:10:47<3:20:48, 18.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 1206/1847 [6:12:22<3:20:45, 18.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 1209/1847 [6:13:46<4:20:09, 24.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 1210/1847 [6:14:11<4:20:00, 24.49s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 66%|██████▌   | 1212/1847 [6:15:44<6:04:10, 34.41s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 66%|██████▌   | 1221/1847 [6:19:39<4:30:32, 25.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 1239/1847 [6:25:54<3:07:12, 18.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 1241/1847 [6:26:33<3:11:18, 18.94s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 67%|██████▋   | 1242/1847 [6:27:28<4:58:58, 29.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 1246/1847 [6:28:28<3:22:47, 20.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 1249/1847 [6:29:10<2:43:01, 16.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 1256/1847 [6:32:18<4:14:33, 25.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 1273/1847 [6:37:35<2:05:46, 13.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 1282/1847 [6:40:20<3:06:29, 19.80s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 28 Jul 2023 14:28:59 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7eddc7f32f284a6d-TPE', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 70%|███████   | 1299/1847 [6:50:47<2:41:58, 17.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 1302/1847 [6:51:26<2:15:28, 14.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 1304/1847 [6:51:53<2:09:30, 14.31s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 71%|███████   | 1308/1847 [6:53:49<3:29:22, 23.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████▏  | 1317/1847 [6:56:43<3:24:16, 23.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 1321/1847 [6:58:24<3:28:51, 23.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 1325/1847 [7:00:08<3:52:19, 26.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 1333/1847 [7:03:25<3:18:37, 23.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 1344/1847 [7:06:54<2:53:39, 20.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 1348/1847 [7:07:57<2:20:36, 16.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 1358/1847 [7:11:44<2:53:54, 21.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 1360/1847 [7:12:39<3:21:24, 24.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 1367/1847 [7:14:36<2:05:37, 15.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 1388/1847 [7:21:13<2:51:18, 22.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▋  | 1410/1847 [7:28:26<2:56:03, 24.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 28 Jul 2023 15:17:18 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7ede0e684cf54a6d-TPE', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 76%|███████▋  | 1411/1847 [7:34:27<15:11:57, 125.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 1413/1847 [7:35:23<9:08:06, 75.78s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 1419/1847 [7:37:02<2:46:10, 23.30s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 78%|███████▊  | 1432/1847 [7:40:54<1:43:41, 14.99s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 28 Jul 2023 15:29:36 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7ede20ae39f14a85-TPE', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 78%|███████▊  | 1433/1847 [7:46:35<12:57:50, 112.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 1437/1847 [7:48:16<5:24:19, 47.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 1438/1847 [7:48:23<4:01:58, 35.50s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 78%|███████▊  | 1440/1847 [7:49:45<4:12:31, 37.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 1444/1847 [7:50:58<2:33:45, 22.89s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: HTTP code 502 from API (<html>\n",
            "<head><title>502 Bad Gateway</title></head>\n",
            "<body>\n",
            "<center><h1>502 Bad Gateway</h1></center>\n",
            "<hr><center>cloudflare</center>\n",
            "</body>\n",
            "</html>\n",
            ").\n",
            " 78%|███████▊  | 1448/1847 [7:52:36<2:25:55, 21.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▊  | 1454/1847 [7:55:00<2:15:59, 20.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 1474/1847 [8:00:02<1:54:40, 18.45s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 80%|███████▉  | 1476/1847 [8:01:53<3:29:43, 33.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 1492/1847 [8:06:18<1:29:22, 15.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 1496/1847 [8:07:24<1:32:40, 15.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 1503/1847 [8:09:15<1:38:59, 17.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 1511/1847 [8:11:57<2:03:17, 22.02s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 28 Jul 2023 16:00:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7ede4e290cba4a7e-TPE', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 82%|████████▏ | 1520/1847 [8:19:58<2:18:48, 25.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 1528/1847 [8:22:38<1:41:46, 19.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 1541/1847 [8:27:20<2:01:17, 23.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 1544/1847 [8:28:05<1:29:44, 17.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 1550/1847 [8:30:05<1:40:55, 20.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1551/1847 [8:30:35<1:54:59, 23.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 1553/1847 [8:31:07<1:39:17, 20.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 1569/1847 [8:35:17<1:18:59, 17.05s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 28 Jul 2023 16:23:49 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7ede7055ca446a8d-TPE', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 85%|████████▌ | 1575/1847 [8:41:57<2:23:11, 31.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1618/1847 [8:53:26<1:01:22, 16.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1627/1847 [8:57:06<1:16:23, 20.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 1644/1847 [9:01:00<47:26, 14.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 1648/1847 [9:02:32<1:05:24, 19.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 1657/1847 [9:05:03<1:02:24, 19.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 1661/1847 [9:06:10<59:02, 19.04s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 90%|████████▉ | 1662/1847 [9:06:57<1:25:01, 27.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 1664/1847 [9:07:57<1:27:49, 28.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 1665/1847 [9:08:21<1:22:31, 27.21s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 91%|█████████ | 1676/1847 [9:12:46<1:05:06, 22.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 1683/1847 [9:15:06<1:03:22, 23.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████▏| 1688/1847 [9:17:03<1:07:20, 25.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1702/1847 [9:21:54<42:01, 17.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 1717/1847 [9:25:14<42:25, 19.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▎| 1727/1847 [9:29:02<54:25, 27.21s/it]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 94%|█████████▎| 1730/1847 [9:29:54<37:18, 19.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1771/1847 [9:41:15<19:56, 15.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1776/1847 [9:43:02<23:01, 19.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▋| 1778/1847 [9:43:35<20:57, 18.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▋| 1780/1847 [9:44:05<19:28, 17.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 1797/1847 [9:48:35<15:25, 18.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 1803/1847 [9:50:10<12:33, 17.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 1818/1847 [9:55:15<08:49, 18.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 1827/1847 [9:58:25<06:55, 20.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 1839/1847 [10:01:31<02:15, 16.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1840/1847 [10:01:46<01:55, 16.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1847/1847 [10:03:08<00:00, 19.59s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2DF38xvc4lV",
        "outputId": "0a65c455-399b-4891-a1cd-9a6a3b6573d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 抽取哈利波特"
      ],
      "metadata": {
        "id": "0NDljCJA_nEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain openai google-search-results tiktoken\n",
        "!pip -q install kor markdownify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7rAC_HU_pBh",
        "outputId": "03ed3825-2b45-44c8-813e-5afc74f759c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-UfivPp\""
      ],
      "metadata": {
        "id": "yKwsaQmBAdCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kor.extraction import create_extraction_chain\n",
        "from kor.nodes import Object, Text, Number\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "5Hny7Pc3AIcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.llms import OpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "STsuPwRKAZmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "哈利波特的组织结构和鹿鼎记有点不一样\n",
        "\n",
        "他是一个压缩包我们先下载过来"
      ],
      "metadata": {
        "id": "MDB97jINAkSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/LC1332/Prophet-Andrew-Ng/raw/main/langchain/%E5%93%88%E5%88%A9%E6%B3%A2%E7%89%B9%E7%94%B5%E5%AD%90%E7%89%88.zip\n",
        "\n",
        "!unzip -q 哈利波特电子版.zip -d harry"
      ],
      "metadata": {
        "id": "QKYoBeN0CYPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/harry/Book/EN/book_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdbcDZZSCik3",
        "outputId": "9c21b853-4f2f-4453-8fe5-ab441154391c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chapter_10.txt\tchapter_14.txt\tchapter_1.txt  chapter_5.txt  chapter_9.txt\n",
            "chapter_11.txt\tchapter_15.txt\tchapter_2.txt  chapter_6.txt\n",
            "chapter_12.txt\tchapter_16.txt\tchapter_3.txt  chapter_7.txt\n",
            "chapter_13.txt\tchapter_17.txt\tchapter_4.txt  chapter_8.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里我们想按顺序把chapter_1到chapter_17的文本进行组织"
      ],
      "metadata": {
        "id": "fTmbVotxCm_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "\n",
        "max_token_len = 1000\n",
        "chunk_text = []\n",
        "\n",
        "\n",
        "for j in range(1,8):\n",
        "    for i in range(1,40):\n",
        "        fname = '/content/harry/Book/EN/book_'+ str(j) +'/chapter_' + str(i) + '.txt'\n",
        "\n",
        "        #continue if it's no file exist\n",
        "        if not os.path.exists(fname):\n",
        "            continue\n",
        "        #read /content/鹿鼎记.txt into python string raw_text\n",
        "        with open(fname, 'r', encoding='utf-8') as f:\n",
        "            raw_text = f.read()\n",
        "\n",
        "        split_text = raw_text.split('\\n')\n",
        "\n",
        "        curr_len = 0\n",
        "        curr_chunk = ''\n",
        "\n",
        "        for line in split_text:\n",
        "            line_len = len(enc.encode( line ))\n",
        "\n",
        "            if line_len > max_token_len:\n",
        "                print('warning line_len = ', line_len)\n",
        "\n",
        "            if curr_len + line_len <= max_token_len:\n",
        "                curr_chunk += line\n",
        "                curr_chunk += '\\n'\n",
        "                curr_len += line_len\n",
        "                curr_len += 1\n",
        "            else:\n",
        "                chunk_text.append(curr_chunk)\n",
        "                curr_chunk = line\n",
        "                curr_len = line_len\n",
        "\n",
        "        if curr_chunk:\n",
        "            chunk_text.append(curr_chunk)\n",
        "\n",
        "    print('after book ' , j, ' chunk number = ', len(chunk_text))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9ODEuOrCr5j",
        "outputId": "99d0b3ce-3a03-42f3-b079-f6cbbb8d0da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after book  1  chunk number =  118\n",
            "after book  2  chunk number =  249\n",
            "after book  3  chunk number =  421\n",
            "after book  4  chunk number =  713\n",
            "after book  5  chunk number =  1100\n",
            "after book  6  chunk number =  1360\n",
            "after book  7  chunk number =  1659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunk_text[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAeMGhKhDrVk",
        "outputId": "aa34f7f4-af89-456f-ddd2-aade0aeac395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER SIXTEEN\n",
            "THROUGH THE TRAPDOOR\n",
            "In years to come, Harry would never quite remember how he had managed to get through his exams when he half expected Voldemort to come bursting through the door at any moment. Yet the days crept by, and there could be no doubt that Fluffy was still alive and well behind the locked door.\n",
            "It was sweltering hot, especially in the large classroom where they did their written papers. They had been given special, new quills for the exams, which had been bewitched with an Anti-Cheating spell.\n",
            "They had practical exams as well. Professor Flitwick called them one by one into his class to see if they could make a pineapple tap-dance across a desk. Professor McGonagall watched them turn a mouse into a snuffbox — points were given for how pretty the snuffbox was, but taken away if it had whiskers. Snape made them all nervous, breathing down their necks while they tried to remember how to make a Forgetfulness potion.\n",
            "Harry did the best he could, trying to ignore the stabbing pains in his forehead, which had been bothering him ever since his trip into the forest. Neville thought Harry had a bad case of exam nerves because Harry couldn’t sleep, but the truth was that Harry kept being woken by his old nightmare, except that it was now worse than ever because there was a hooded figure dripping blood in it.\n",
            "Maybe it was because they hadn’t seen what Harry had seen in the forest, or because they didn’t have scars burning on their foreheads, but Ron and Hermione didn’t seem as worried about the Stone as Harry. The idea of Voldemort certainly scared them, but he didn’t keep visiting them in dreams, and they were so busy with their studying they didn’t have much time to fret about what Snape or anyone else might be up to.\n",
            "Their very last exam was History of Magic. One hour of answering questions about batty old wizards who’d invented self-stirring cauldrons and they’d be free, free for a whole wonderful week until their exam results came out. When the ghost of Professor Binns told them to put down their quills and roll up their parchment, Harry couldn’t help cheering with the rest.\n",
            "“That was far easier than I thought it would be,” said Hermione as they joined the crowds flocking out onto the sunny grounds. “I needn’t have learned about the 1637 Werewolf Code of Conduct or the uprising of Elfric the Eager.”\n",
            "Hermione always liked to go through their exam papers afterward, but Ron said this made him feel ill, so they wandered down to the lake and flopped under a tree. The Weasley twins and Lee Jordan were tickling the tentacles of a giant squid, which was basking in the warm shallows.\n",
            "“No more studying,” Ron sighed happily, stretching out on the grass. “You could look more cheerful, Harry, we’ve got a week before we find out how badly we’ve done, there’s no need to worry yet.”\n",
            "Harry was rubbing his forehead.\n",
            "“I wish I knew what this means!” he burst out angrily. “My scar keeps hurting — it’s happened before, but never as often as this.”\n",
            "“Go to Madam Pomfrey,” Hermione suggested.\n",
            "“I’m not ill,” said Harry. “I think it’s a warning . . . it means danger’s coming. . . .”\n",
            "Ron couldn’t get worked up, it was too hot.\n",
            "“Harry, relax, Hermione’s right, the Stone’s safe as long as Dumbledore’s around. Anyway, we’ve never had any proof Snape found out how to get past Fluffy. He nearly had his leg ripped off once, he’s not going to try it again in a hurry. And Neville will play Quidditch for England before Hagrid lets Dumbledore down.”\n",
            "Harry nodded, but he couldn’t shake off a lurking feeling that there was something he’d forgotten to do, something important. When he tried to explain this, Hermione said, “That’s just the exams. I woke up last night and was halfway through my Transfiguration notes before I remembered we’d done that one.”\n",
            "Harry was quite sure the unsettled feeling didn’t have anything to do with work, though. He watched an owl flutter toward the school across the bright blue sky, a note clamped in its mouth. Hagrid was the only one who ever sent him letters. Hagrid would never betray Dumbledore. Hagrid would never tell anyone how to get past Fluffy . . . never . . . but —\n",
            "Harry suddenly jumped to his feet.\n",
            "“Where’re you going?” said Ron sleepily.\n",
            "“I’ve just thought of something,” said Harry. He had turned white. “We’ve got to go and see Hagrid, now.”\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text in chunk_text:\n",
        "    if 'Petrificus' in text:\n",
        "        print(text)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQjqH_SOEgPN",
        "outputId": "6dcf75d9-693a-4e89-c415-5420e428451e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“Neville,” she said, “I’m really, really sorry about this.”She raised her wand.\n",
            "“Petrificus Totalus!” she cried, pointing it at Neville.\n",
            "Neville’s arms snapped to his sides. His legs sprang together. His whole body rigid, he swayed where he stood and then fell flat on his face, stiff as a board.\n",
            "Hermione ran to turn him over. Neville’s jaws were jammed together so he couldn’t speak. Only his eyes were moving, looking at them in horror.\n",
            "“What’ve you done to him?” Harry whispered.\n",
            "“It’s the full Body-Bind,” said Hermione miserably. “Oh, Neville, I’m so sorry.”\n",
            "“We had to, Neville, no time to explain,” said Harry.\n",
            "“You’ll understand later, Neville,” said Ron as they stepped over him and pulled on the Invisibility Cloak.\n",
            "But leaving Neville lying motionless on the floor didn’t feel like a very good omen. In their nervous state, every statue’s shadow looked like Filch, every distant breath of wind sounded like Peeves swooping down on them.\n",
            "At the foot of the first set of stairs, they spotted Mrs. Norris skulking near the top.\n",
            "“Oh, let's kick her, just this once.” Ron whispered in Harry’s ear, but Harry shook his head. As they climbed carefully around her, Mrs. Norris turned her lamplike eyes on them, but didn’t do anything.\n",
            "They didn’t meet anyone else until they reached the staircase up to the third floor. Peeves was bobbing halfway up, loosening the carpet so that people would trip.\n",
            "“Who’s there?” he said suddenly as they climbed toward him. He narrowed his wicked black eyes. “Know you’re there, even if I can’t see you. Are you ghoulie or ghostie or wee student beastie?”\n",
            "He rose up in the air and floated there, squinting at them.\n",
            "“Should call Filch, I should, if something’s a-creeping around unseen.”\n",
            "Harry had a sudden idea.\n",
            "“Peeves,” he said, in a hoarse whisper, “the Bloody Baron has his own reasons for being invisible.”\n",
            "Peeves almost fell out of the air in shock. He caught himself in time and hovered about a foot off the stairs.\n",
            "“So sorry, your bloodiness, Mr. Baron, sir,” he said greasily. “My mistake, my mistake — I didn’t see you — of course I didn’t, you’re invisible — forgive old Peevsie his little joke, sir.”\n",
            "“I have business here, Peeves,” croaked Harry. “Stay away from this place tonight.”\n",
            "“I will, sir, I most certainly will,” said Peeves, rising up in the air again. “Hope your business goes well, Baron, I’ll not bother you.”\n",
            "And he scooted off.\n",
            "“Brilliant, Harry!” whispered Ron.\n",
            "A few seconds later, they were there, outside the third-floor corridor — and the door was already ajar.\n",
            "“Well, there you are,” Harry said quietly, “Snape’s already got past Fluffy.”\n",
            "Seeing the open door somehow seemed to impress upon all three of them what was facing them. Underneath the Cloak, Harry turned to the other two.\n",
            "“If you want to go back, I won’t blame you,” he said. “You can take the Cloak, I won’t need it now.”\n",
            "“Don’t be stupid,” said Ron.\n",
            "“We’re coming,” said Hermione.\n",
            "Harry pushed the door open.\n",
            "As the door creaked, low, rumbling growls met their ears. All three of the dog’s noses sniffed madly in their direction, even though it couldn’t see them.\n",
            "“What’s that at its feet?” Hermione whispered.\n",
            "“Looks like a harp,” said Ron. “Snape must have left it there.”\n",
            "“It must wake up the moment you stop playing,” said Harry. “Well, here goes . . .”\n",
            "He put Hagrid’s flute to his lips and blew. It wasn’t really a tune, but from the first note the beast’s eyes began to droop. Harry hardly drew breath. Slowly, the dog’s growls ceased — it tottered on its paws and fell to its knees, then it slumped to the ground, fast asleep.\n",
            "“Keep playing,” Ron warned Harry as they slipped out of the Cloak and crept toward the trapdoor. They could feel the dog’s hot, smelly breath as they approached the giant heads.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunk_text[14])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yjqbDcoJgHl",
        "outputId": "b0491285-80a5-4aa0-de1d-0f2a91afef36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“Where’s my letter?” said Harry, the moment Uncle Vernon had squeezed through the door. “Who’s writing to me?”“No one. It was addressed to you by mistake,” said Uncle Vernon shortly. “I have burned it.”\n",
            "“It was not a mistake,” said Harry angrily, “it had my cupboard on it.”\n",
            "“SILENCE!” yelled Uncle Vernon, and a couple of spiders fell from the ceiling. He took a few deep breaths and then forced his face into a smile, which looked quite painful.\n",
            "“Er — yes, Harry — about this cupboard. Your aunt and I have been thinking . . . you’re really getting a bit big for it . . . we think it might be nice if you moved into Dudley’s second bedroom.”\n",
            "“Why?” said Harry.\n",
            "“Don’t ask questions!” snapped his uncle. “Take this stuff upstairs, now.”\n",
            "The Dursleys’ house had four bedrooms: one for Uncle Vernon and Aunt Petunia, one for visitors (usually Uncle Vernon’s sister, Marge), one where Dudley slept, and one where Dudley kept all the toys and things that wouldn’t fit into his first bedroom. It only took Harry one trip upstairs to move everything he owned from the cupboard to this room. He sat down on the bed and stared around him. Nearly everything in here was broken. The month-old video camera was lying on top of a small, working tank Dudley had once driven over the next door neighbor’s dog; in the corner was Dudley’s first-ever television set, which he’d put his foot through when his favorite program had been canceled; there was a large birdcage, which had once held a parrot that Dudley had swapped at school for a real air rifle, which was up on a shelf with the end all bent because Dudley had sat on it. Other shelves were full of books. They were the only things in the room that looked as though they’d never been touched.\n",
            "From downstairs came the sound of Dudley bawling at his mother, “I don’t want him in there . . . I need that room . . . make him get out. . . .”\n",
            "Harry sighed and stretched out on the bed. Yesterday he’d have given anything to be up here. Today he’d rather be back in his cupboard with that letter than up here without it.\n",
            "Next morning at breakfast, everyone was rather quiet. Dudley was in shock. He’d screamed, whacked his father with his Smelting stick, been sick on purpose, kicked his mother, and thrown his tortoise through the greenhouse roof, and he still didn’t have his room back. Harry was thinking about this time yesterday and bitterly wishing he’d opened the letter in the hall. Uncle Vernon and Aunt Petunia kept looking at each other darkly.\n",
            "When the mail arrived, Uncle Vernon, who seemed to be trying to be nice to Harry, made Dudley go and get it. They heard him banging things with his Smelting stick all the way down the hall. Then he shouted, “There’s another one! ‘Mr. H. Potter, The Smallest Bedroom, 4 Privet Drive —’”\n",
            "With a strangled cry, Uncle Vernon leapt from his seat and ran down the hall, Harry right behind him. Uncle Vernon had to wrestle Dudley to the ground to get the letter from him, which was made difficult by the fact that Harry had grabbed Uncle Vernon around the neck from behind. After a minute of confused fighting, in which everyone got hit a lot by the Smelting stick, Uncle Vernon straightened up, gasping for breath, with Harry’s letter clutched in his hand.\n",
            "“Go to your cupboard — I mean, your bedroom,” he wheezed at Harry. “Dudley — go — just go.”\n",
            "Harry walked round and round his new room. Someone knew he had moved out of his cupboard and they seemed to know he hadn’t received his first letter. Surely that meant they’d try again? And this time he’d make sure they didn’t fail. He had a plan.\n",
            "The repaired alarm clock rang at six o’clock the next morning. Harry turned it off quickly and dressed silently. He mustn’t wake the Dursleys. He stole downstairs without turning on any of the lights.\n",
            "He was going to wait for the postman on the corner of Privet Drive and get the letters for number four first. His heart hammered as he crept across the dark hall toward the front door —\n",
            "“AAAAARRRGH!”\n",
            "Harry leapt into the air; he’d trodden on something big and squashy on the doormat — something alive!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "让我来改一下例子"
      ],
      "metadata": {
        "id": "MHvI-AkkD7Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 短的prompt\n",
        "\n",
        "schema = Object(\n",
        "    id=\"script\",\n",
        "    description=\"Adapted from the novel into script\",\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"role\",\n",
        "            description=\"The character who is speaking or performing an action, use context to predict the name of the role.\",\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"dialogue\",\n",
        "            description=\"The dialogue spoken by the characters in the sentence\",\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"action\",\n",
        "            description='''The actions performed by the characters in the text, A high-level summary of a character's behavior. action equals \"dialogue\" or \"monologue\" or \"spell to somebody\". if it's no dialogue, summarize role's behavior in sentence''',\n",
        "        )\n",
        "    ],\n",
        "    examples=[\n",
        "        (\n",
        "            '''“Harry, Let's Go to Madam Pomfrey” Hermione suggested.\n",
        "                “I’m not ill,” said him. “I think it’s a warning . . . it means danger’s coming. . . .”''',\n",
        "            [\n",
        "                {\"role\": \"Hermione\", \"dialogue\": \"Go to Madam Pomfrey,\",\"action\":\"dialogue\"},\n",
        "                {\"role\": \"Harry\", \"dialogue\": \"I’m not ill, I think it’s a warning . . . it means danger’s coming. . . .\",\"action\":\"dialogue\"},\n",
        "            ],\n",
        "        ),\n",
        "        (\n",
        "            '''“Petrificus Totalus!” Hermione cried, pointing it at Neville.\n",
        "Neville’s arms snapped to his sides. His legs sprang together. His whole body rigid, he swayed where he stood and then fell flat on his face, stiff as a board.\n",
        "“What’ve you done to him?” Harry whispered.''',\n",
        "            [\n",
        "                {\"role\": \"Hermione\", \"dialogue\": \"Petrificus Totalus!\",\"action\":\"spell to Neville\"},\n",
        "                {\"role\": \"Neville\", \"dialogue\": \"\",\"action\":\"legs sprang together. whole body rigid, stiff as a board\"},\n",
        "                {\"role\": \"Harry\", \"dialogue\": \"What’ve you done to him?\",\"action\":\"dialogue\"}\n",
        "            ],\n",
        "        )\n",
        "    ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "PF65Ox7BD6oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain(llm, schema)\n",
        "print(chain.prompt.format_prompt(text=\"[user input]\").to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-hew36eF8EG",
        "outputId": "30a2fd45-2152-41fb-bd7e-7fbc220d392c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
            "\n",
            "```TypeScript\n",
            "\n",
            "script: Array<{ // Adapted from the novel into script\n",
            " role: string // The character who is speaking or performing an action, use context to predict the name of the role.\n",
            " dialogue: string // The dialogue spoken by the characters in the sentence\n",
            " action: string // The actions performed by the characters in the text, A high-level summary of a character's behavior. action equals \"dialogue\" or \"monologue\" or \"spell to somebody\". if it's no dialogue, summarize role's behavior in sentence\n",
            "}>\n",
            "```\n",
            "\n",
            "\n",
            "Please output the extracted information in CSV format in Excel dialect. Please use a | as the delimiter. \n",
            " Do NOT add any clarifying information. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.\n",
            "\n",
            "\n",
            "\n",
            "Input: “Harry, Let's Go to Madam Pomfrey” Hermione suggested.\n",
            "                “I’m not ill,” said him. “I think it’s a warning . . . it means danger’s coming. . . .”\n",
            "Output: role|dialogue|action\n",
            "Hermione|Go to Madam Pomfrey,|dialogue\n",
            "Harry|I’m not ill, I think it’s a warning . . . it means danger’s coming. . . .|dialogue\n",
            "\n",
            "Input: “Petrificus Totalus!” Hermione cried, pointing it at Neville.\n",
            "Neville’s arms snapped to his sides. His legs sprang together. His whole body rigid, he swayed where he stood and then fell flat on his face, stiff as a board.\n",
            "“What’ve you done to him?” Harry whispered.\n",
            "Output: role|dialogue|action\n",
            "Hermione|Petrificus Totalus!|spell to Neville\n",
            "Neville||legs sprang together. whole body rigid, stiff as a board\n",
            "Harry|What’ve you done to him?|dialogue\n",
            "\n",
            "Input: [user input]\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZR37o24G2Sl",
        "outputId": "caa45007-7c73-4b9b-e22f-7b6e5f777c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/GPTData/harry_extract_again\"\n",
        "\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder)"
      ],
      "metadata": {
        "id": "Jkl_-MVeG7vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/GPTData/harry_extract_again\"\n",
        "\n",
        "for i in tqdm(range(0,len(chunk_text))):\n",
        "\n",
        "  save_name = os.path.join(save_folder, f\"{i}.txt\")\n",
        "\n",
        "  if os.path.exists(save_name):\n",
        "    continue\n",
        "\n",
        "  response = chain.run( chunk_text[i] )[\"data\"]\n",
        "\n",
        "  with open(save_name, 'w', encoding='utf-8') as f:\n",
        "\n",
        "    if 'script' not in response:\n",
        "        print('Error: response does not contain key \"script\"')\n",
        "    else:\n",
        "        for chat in response['script']:\n",
        "            json_str = json.dumps(chat, ensure_ascii=False)\n",
        "            f.write(json_str+\"\\n\")\n",
        "\n",
        "#   if i > 10:\n",
        "#     break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZeOiuTHATo",
        "outputId": "aa792116-0b87-4f38-d97d-91ebeaca7472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 7/1659 [01:44<6:29:43, 14.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 14/1659 [03:56<9:01:46, 19.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 32/1659 [08:25<6:07:48, 13.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 34/1659 [08:49<5:35:24, 12.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 51/1659 [12:46<6:42:55, 15.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 55/1659 [13:21<4:07:12,  9.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 66/1659 [16:10<7:27:07, 16.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 85/1659 [21:14<7:22:07, 16.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 91/1659 [22:38<6:48:17, 15.62s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            "  6%|▌         | 96/1659 [24:47<9:24:08, 21.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 98/1659 [25:29<9:17:37, 21.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 102/1659 [26:14<6:02:50, 13.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 115/1659 [30:03<9:52:48, 23.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 118/1659 [31:01<8:58:55, 20.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 155/1659 [39:34<6:22:19, 15.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 167/1659 [42:09<6:13:41, 15.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 177/1659 [44:56<6:25:08, 15.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 181/1659 [45:59<6:12:30, 15.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 184/1659 [46:42<6:03:50, 14.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 202/1659 [51:14<6:32:11, 16.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 227/1659 [58:12<6:52:17, 17.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 233/1659 [59:38<6:10:45, 15.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 234/1659 [59:48<5:28:57, 13.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 245/1659 [1:02:32<6:06:24, 15.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 272/1659 [1:10:35<7:06:54, 18.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 286/1659 [1:14:22<5:42:38, 14.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▊        | 311/1659 [1:19:49<4:08:32, 11.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 313/1659 [1:20:17<4:40:43, 12.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 325/1659 [1:23:41<7:46:06, 20.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 330/1659 [1:25:00<5:54:25, 16.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 335/1659 [1:26:41<7:18:54, 19.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 340/1659 [1:27:55<6:18:38, 17.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 374/1659 [1:35:48<5:26:09, 15.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 383/1659 [1:37:25<3:31:24,  9.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 394/1659 [1:40:37<7:07:12, 20.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 402/1659 [1:43:33<8:41:55, 24.91s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 412/1659 [1:46:35<5:56:38, 17.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 414/1659 [1:46:57<5:04:58, 14.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 423/1659 [1:50:06<7:19:55, 21.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 446/1659 [1:56:24<4:51:26, 14.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 449/1659 [1:57:12<5:18:39, 15.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 451/1659 [1:57:28<4:03:09, 12.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 469/1659 [2:02:45<9:14:25, 27.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 480/1659 [2:05:23<4:40:29, 14.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 490/1659 [2:08:12<4:29:46, 13.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 509/1659 [2:13:06<5:17:51, 16.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 513/1659 [2:13:42<4:07:56, 12.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███▏      | 521/1659 [2:15:49<4:40:01, 14.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 535/1659 [2:19:26<5:05:18, 16.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 537/1659 [2:20:11<6:09:48, 19.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 555/1659 [2:24:45<3:16:04, 10.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 563/1659 [2:27:14<5:37:00, 18.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 584/1659 [2:32:41<4:53:33, 16.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 587/1659 [2:33:25<4:53:55, 16.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 590/1659 [2:34:19<5:09:55, 17.40s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sun, 30 Jul 2023 04:01:23 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7eeaab65eef70b85-AMS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 36%|███▌      | 592/1659 [2:40:16<25:22:09, 85.59s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 604/1659 [2:43:39<5:38:33, 19.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 607/1659 [2:44:24<4:39:26, 15.94s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sun, 30 Jul 2023 04:11:29 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7eeaba2bfb731c8a-AMS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 37%|███▋      | 615/1659 [2:51:45<7:13:15, 24.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 627/1659 [2:55:03<5:10:14, 18.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 635/1659 [2:56:58<3:58:26, 13.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 645/1659 [2:59:29<4:05:12, 14.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 653/1659 [3:01:30<3:50:58, 13.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 656/1659 [3:02:42<5:42:06, 20.47s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sun, 30 Jul 2023 04:29:55 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7eead4faacec0bc6-AMS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 40%|████      | 671/1659 [3:12:57<5:48:50, 21.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 675/1659 [3:13:49<3:43:53, 13.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 692/1659 [3:18:44<4:04:04, 15.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 693/1659 [3:18:56<3:52:55, 14.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 702/1659 [3:21:40<4:10:56, 15.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 725/1659 [3:28:29<5:08:16, 19.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 732/1659 [3:30:18<4:37:39, 17.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 734/1659 [3:30:48<4:09:37, 16.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 735/1659 [3:31:03<4:03:35, 15.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 746/1659 [3:33:51<4:47:45, 18.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▋     | 771/1659 [3:40:28<3:51:58, 15.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 772/1659 [3:40:45<3:58:02, 16.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 793/1659 [3:45:54<3:00:10, 12.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 799/1659 [3:47:26<3:12:58, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 816/1659 [3:51:06<3:39:11, 15.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 824/1659 [3:53:15<3:24:11, 14.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 830/1659 [3:54:43<3:26:43, 14.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 891/1659 [4:12:27<3:57:25, 18.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 898/1659 [4:14:41<4:08:13, 19.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 901/1659 [4:15:54<4:47:48, 22.78s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sun, 30 Jul 2023 05:43:05 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7eeb40398915b7ae-AMS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 55%|█████▍    | 907/1659 [4:23:01<7:22:50, 35.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 911/1659 [4:24:06<4:28:04, 21.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 914/1659 [4:24:34<2:47:44, 13.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 915/1659 [4:24:57<3:24:18, 16.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 931/1659 [4:29:26<3:49:22, 18.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 944/1659 [4:32:32<2:13:07, 11.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 953/1659 [4:34:33<2:33:17, 13.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 976/1659 [4:39:28<2:08:32, 11.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 992/1659 [4:43:19<2:31:29, 13.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 1039/1659 [4:56:58<2:49:44, 16.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 1050/1659 [4:59:04<1:39:26,  9.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 1059/1659 [5:00:38<1:29:42,  8.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 1070/1659 [5:03:34<3:20:40, 20.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 1076/1659 [5:04:41<2:15:18, 13.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 1088/1659 [5:08:45<3:20:32, 21.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 1093/1659 [5:10:23<3:06:31, 19.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 1113/1659 [5:17:09<3:31:09, 23.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 1116/1659 [5:19:01<5:40:31, 37.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 1124/1659 [5:21:16<2:43:16, 18.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 1129/1659 [5:22:42<2:38:52, 17.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 1145/1659 [5:28:03<2:59:56, 21.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 1151/1659 [5:29:30<2:16:06, 16.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 1164/1659 [5:33:33<2:32:42, 18.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 1168/1659 [5:34:32<2:19:11, 17.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 1197/1659 [5:44:19<3:24:38, 26.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 1231/1659 [5:54:41<2:31:53, 21.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 1232/1659 [5:55:00<2:26:06, 20.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 1236/1659 [5:56:08<2:08:45, 18.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 1243/1659 [5:58:05<2:26:20, 21.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 1245/1659 [5:58:44<2:19:23, 20.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 1260/1659 [6:03:32<2:41:42, 24.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 1264/1659 [6:05:12<2:36:33, 23.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 1275/1659 [6:08:08<1:59:12, 18.63s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sun, 30 Jul 2023 07:35:24 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7eebe49e28b7b785-AMS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 77%|███████▋  | 1278/1659 [6:14:31<6:58:03, 65.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 1298/1659 [6:21:06<1:48:06, 17.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 1313/1659 [6:26:05<1:37:12, 16.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 1359/1659 [6:42:31<2:01:34, 24.31s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sun, 30 Jul 2023 08:09:38 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7eec16fe6ad60b8c-AMS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 83%|████████▎ | 1369/1659 [6:51:14<2:04:25, 25.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 1380/1659 [6:54:50<1:34:55, 20.42s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sun, 30 Jul 2023 08:22:03 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7eec29076baf286b-AMS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 85%|████████▍ | 1402/1659 [7:09:45<1:49:33, 25.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 1406/1659 [7:10:58<1:26:24, 20.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 1408/1659 [7:11:28<1:16:08, 18.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 1421/1659 [7:15:24<1:21:12, 20.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 1426/1659 [7:17:03<1:20:42, 20.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1427/1659 [7:17:34<1:31:41, 23.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1428/1659 [7:18:01<1:35:44, 24.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 1431/1659 [7:19:06<1:22:35, 21.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 1444/1659 [7:23:51<1:21:12, 22.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 1447/1659 [7:24:37<1:08:21, 19.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1453/1659 [7:26:22<1:04:42, 18.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1455/1659 [7:27:01<1:06:30, 19.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1457/1659 [7:27:26<54:02, 16.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1465/1659 [7:29:54<46:39, 14.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 1473/1659 [7:33:23<1:19:38, 25.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 1481/1659 [7:36:23<1:05:05, 21.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 1490/1659 [7:39:02<39:46, 14.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 1507/1659 [7:45:13<1:11:22, 28.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1534/1659 [7:54:13<54:29, 26.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 1540/1659 [7:56:05<36:40, 18.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 1547/1659 [7:57:31<21:05, 11.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▎| 1552/1659 [7:59:00<36:23, 20.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 1559/1659 [8:01:35<37:33, 22.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 1581/1659 [8:08:07<27:34, 21.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1593/1659 [8:11:55<17:58, 16.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1594/1659 [8:12:23<21:25, 19.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1596/1659 [8:13:20<24:32, 23.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 1607/1659 [8:16:21<16:14, 18.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 1630/1659 [8:22:41<11:44, 24.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1631/1659 [8:23:09<11:49, 25.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1659/1659 [8:33:52<00:00, 18.59s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 抽取天龙八部"
      ],
      "metadata": {
        "id": "af2sTDIYKFwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain openai google-search-results tiktoken\n",
        "!pip -q install kor markdownify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egm_U3FEJ6jz",
        "outputId": "8f43af60-f34b-41c9-abd8-d53bc497620b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-UfivP\""
      ],
      "metadata": {
        "id": "0wfqH_JvKeo8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kor.extraction import create_extraction_chain\n",
        "from kor.nodes import Object, Text, Number\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "KK_WVip5Km-V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/zhenghaoz/7ad0948d5835468844abd2db8f67faff/raw/98bd7a3ca7ef308b031a20a0c671b2d2da23ea3e/%25E5%25A4%25A9%25E9%25BE%2599%25E5%2585%25AB%25E9%2583%25A8.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlTeKU6pKs5X",
        "outputId": "fdee8d51-6aa1-476b-d7c7-a24f7fab6f89"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-31 08:59:17--  https://gist.githubusercontent.com/zhenghaoz/7ad0948d5835468844abd2db8f67faff/raw/98bd7a3ca7ef308b031a20a0c671b2d2da23ea3e/%25E5%25A4%25A9%25E9%25BE%2599%25E5%2585%25AB%25E9%2583%25A8.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3655023 (3.5M) [text/plain]\n",
            "Saving to: ‘天龙八部.txt’\n",
            "\n",
            "天龙八部.txt        100%[===================>]   3.49M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-07-31 08:59:18 (27.2 MB/s) - ‘天龙八部.txt’ saved [3655023/3655023]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "raw_text = open('/content/天龙八部.txt', encoding='utf-8').read()\n",
        "\n",
        "chapters = []\n",
        "for match in re.finditer(r'\\n第.+?章(.+?)\\n', raw_text):\n",
        "    title = match.group(1)\n",
        "    start = match.start()\n",
        "    end = raw_text.find('\\n第', start+1)\n",
        "    chapters.append(raw_text[start:end])"
      ],
      "metadata": {
        "id": "hXkDw4iBLGrl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")"
      ],
      "metadata": {
        "id": "QJLEkel0LwUS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_str(s, sep=['\\n', '.', '。']):\n",
        "    mid_len = len(s) // 2  # 中心点位置\n",
        "    best_sep_pos = len(s) + 1  # 最接近中心点的分隔符位置\n",
        "    best_sep = None  # 最接近中心点的分隔符\n",
        "    for curr_sep in sep:\n",
        "        sep_pos = s.rfind(curr_sep, 0, mid_len)  # 从中心点往左找分隔符\n",
        "        if sep_pos > 0 and abs(sep_pos - mid_len) < abs(best_sep_pos -\n",
        "                                                        mid_len):\n",
        "            best_sep_pos = sep_pos\n",
        "            best_sep = curr_sep\n",
        "    if not best_sep:  # 没有找到分隔符\n",
        "        return s, ''\n",
        "    return s[:best_sep_pos + 1], s[best_sep_pos + 1:]\n",
        "\n",
        "\n",
        "def strong_divide(s):\n",
        "    left, right = divide_str(s)\n",
        "\n",
        "    if right != '':\n",
        "        return left, right\n",
        "\n",
        "    whole_sep = ['\\n', '.', '，', '、', ';', ',', '；',\\\n",
        "                 '：', '！', '？', '(', ')', '”', '“', \\\n",
        "                 '’', '‘', '[', ']', '{', '}', '<', '>', \\\n",
        "                 '/', '''\\''', '|', '-', '=', '+', '*', '%', \\\n",
        "               '$', '''#''', '@', '&', '^', '_', '`', '~',\\\n",
        "                 '·', '…']\n",
        "    left, right = divide_str(s, sep=whole_sep)\n",
        "\n",
        "    if right != '':\n",
        "        return left, right\n",
        "\n",
        "    mid_len = len(s) // 2\n",
        "    return s[:mid_len], s[mid_len:]\n"
      ],
      "metadata": {
        "id": "X5wrWDE1MUVY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for chapter in chapters:\n",
        "\n",
        "        print(count)\n",
        "        break\n",
        "    count = count + 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYfjCOzROlo7",
        "outputId": "33b9c116-30f5-45d9-ab27-f9293dbd11c6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_sentence = \"你们也从来没见到过？”\"\n",
        "offset_id = 801"
      ],
      "metadata": {
        "id": "ETDb0fdZPKFE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_token_len = 1500\n",
        "chunk_text = []\n",
        "\n",
        "for i in range(offset_id):\n",
        "    chunk_text.append('')\n",
        "\n",
        "flag = True\n",
        "\n",
        "for chapter in chapters:\n",
        "\n",
        "    if flag:\n",
        "        if chapter.find(last_sentence,1)<=0:\n",
        "            continue\n",
        "        else:\n",
        "            flag = False\n",
        "            id = chapter.find(last_sentence,1)\n",
        "            rest_chapter = chapter[id + len(last_sentence):]\n",
        "            split_text = rest_chapter.split('\\n')\n",
        "    else:\n",
        "        split_text = chapter.split('\\n')\n",
        "\n",
        "    curr_len = 0\n",
        "    curr_chunk = ''\n",
        "\n",
        "    tmp = []\n",
        "\n",
        "    for line in split_text:\n",
        "        line_len = len(enc.encode( line ))\n",
        "\n",
        "        if line_len <= max_token_len - 5:\n",
        "            tmp.append(line)\n",
        "        else:\n",
        "            path = [line]\n",
        "            tmp_res = []\n",
        "\n",
        "            while path:\n",
        "                my_str = path.pop()\n",
        "                left, right = strong_divide(my_str)\n",
        "\n",
        "                if len(left) > max_token_len - 5:\n",
        "                    path.append(left)\n",
        "                else:\n",
        "                    tmp_res.append(left)\n",
        "\n",
        "                if len(right) > max_token_len - 5:\n",
        "                    path.append(right)\n",
        "                else:\n",
        "                    tmp_res.append(right)\n",
        "\n",
        "    split_text = tmp\n",
        "\n",
        "    for line in split_text:\n",
        "        line_len = len(enc.encode( line ))\n",
        "\n",
        "        if line_len > max_token_len:\n",
        "            print('warning line_len = ', line_len)\n",
        "\n",
        "        if curr_len + line_len <= max_token_len:\n",
        "            curr_chunk += line\n",
        "            curr_chunk += '\\n'\n",
        "            curr_len += line_len\n",
        "            curr_len += 1\n",
        "        else:\n",
        "            chunk_text.append(curr_chunk)\n",
        "            curr_chunk = line\n",
        "            curr_len = line_len\n",
        "\n",
        "    if curr_chunk:\n",
        "        chunk_text.append(curr_chunk)\n",
        "\n",
        "    # break\n",
        "\n",
        "print(len(chunk_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6mkgNqULXSb",
        "outputId": "4e4fa556-a2fc-4ddf-e66f-193a2cd3d61c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunk_text[801])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZusUzGsQG2T",
        "outputId": "0b2dfa7f-551c-4068-8400-3813813768de"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    乌老大叹了口气，道：“倒也有人见到过的。只是见到她的人可就惨了。那是在二十三年之前，有人大着胆子，偷偷拉开蒙眼的黑布，向那老贼婆望了一眼，还没来得及将黑布盖上眼去，便给老贼婆刺瞎了双眼，又割去了舌头，斩断了双臂。”慕容复道：“刺瞎眼睛，那也罢了，割舌断臂，却又如何？”乌老大道：“想是不许他向人泄漏这老贼婆的形相，割舌叫他不能说话，断臂叫他不能写字。”\n",
            "    包不同伸了伸舌头，道：“浑蛋，浑蛋！厉害，厉害！”乌老大道：“我和安洞主、钦岛主等上缥缈峰之时，九个人心里都是怕得要命。老贼婆三年前嘱咐要齐备的药物，实在有几样太是难得，像三百年海龟的龟蛋，五尺长的鹿角，说什么也找不到。我们未能完全依照嘱咐备妥，料想这一次责罚必重。哪知道九个人战战兢兢的缴了物品，老贼婆派人传话出来，说道：‘采购的物品也还罢了，九个孙子王八蛋，快快给我夹了尾巴，滚下峰去罢。’我们便如遇到皇恩大赦，当真是大喜过望，立即下峰，都想早走一刻好一刻，别要老贼婆发觉物品不对，追究起来，这罪可就受得大了。九个人来到缥缈峰下，拉开蒙眼的黑布，只见山峰下死了三个人。其中一个，安洞主识得是西夏国一品堂中的高手，名叫九翼道人。”不平道人“哦”了一声，道：“九翼道人原来是被老贼婆所杀，江湖上传言纷纷，都说是姑苏慕容氏下的毒手呢。”包不同道：“放屁，放屁！什么八尾和尚、九翼道人，我们见都没见过，这笔帐又算在我们头上了。”他大骂“放屁”，指的是“江湖上传言纷纷”，并非骂不平道人放屁，但旁人听来，总不免刺耳。不平道人也不生气，微笑道：“树大招风，众望所归！”包不同喝道：“放……”斜眼向慕容复望了望，下面的话便收住了。不平道人道：“包兄怎地把下面这个字吃进肚里了。”包不同一转念间，登时大怒，喝道：“什么？你骂我吃屁么？”不平道人笑道：“不敢！包兄爱吃什么，便吃什么。”包不同还待和他争辩，慕容复道：“世间不虞之誉，求全之毁，原也平常得紧，包三哥何必多辩？听说九翼道人轻功极高，一手雷公挡功夫，生平少逢敌手，别说他和在下全无过节可言，就算真有怨仇，在下也未必胜得过这位号称‘雷动于九天之上’的九翼道长。”\n",
            "    不平道人微笑道：“慕容公子却又太谦了。九翼道人‘雷动于九天之上’的功夫虽然了得，但若慕容公子还他一个‘雷动于九天之上’，他也只好束手待毙了。”\n",
            "    乌老大道：“九翼道人身上共有两处伤痕，都是剑伤。因此江湖上传说他是死于姑苏慕容之手，那全是胡说八道。在下亲眼目睹，岂有假的？倘若是慕容公子取他性命，自当以九翼道人的雷公挡伤他了。”\n",
            "    不平道人接口道：“两处剑伤？你说是两处伤痕？这就奇了。”乌老大伸手一拍大腿，说道：“不平道长果然了得，一听之下，便知其中有了蹊跷。九翼道人死于缥缈峰下，身上却有两处剑伤，这事可不对头啊。”\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(chunk_text))\n",
        "\n",
        "for chunk,id in zip(chunk_text,range(0,len(chunk_text))):\n",
        "    if chunk.find(\"将左袖的劲力抵消\",1) > 0:\n",
        "        print('id = ', id)\n",
        "        print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PElJ4kCxMXQg",
        "outputId": "a2ebe764-3097-409b-9da1-2e69bd8e444c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1170\n",
            "id =  768\n",
            "    忽听得慕容复叫道：“在这里了！”左手衣袖挥出，向一块岩石卷去，原来这块岩石模样的东西，却是桑土公的背脊。这人古里古怪，惑人耳目的伎俩花样百出，若不是慕容复眼尖，还真不易发见。桑土公被雄劲的袖风卷起，肉球般的身子飞向半空。他自中了慕容复一掌之后，受伤已然不轻，这时殊无抗御之力，大声叫道：“休下毒手，我给你解药便了！”    慕容复哈哈一笑，右袖拂出，将左袖的劲力抵消，同时生出一股力道，托住桑土公的身子，轻轻放了下来。忽听得远处一人叫道：“姑苏慕容，名不虚传！”慕容复举手道：“贻笑方家，愧不敢当！”便在此时，一道金光、一道银光从左首电也似的射来，破空声甚是凌厉。慕容复不敢怠慢，双袖鼓风，迎了上去，砰的一声巨响，金光银光倒卷了回去。这时方才看清，却是两条长长的带子，一条金色，一条银色。带子尽头处站着二人，都是老翁，使金带的身穿银袍，使银带的身穿金袍。金银之色闪耀灿烂，华丽之极，这等金银色的袍子常人决不穿着，倒像是戏台上的人物一般。穿银袍的老人说道：“佩服，佩服，再接咱兄弟一招！”金光闪动，金带自左方游动而至，银带却一抖向天，再从上空落下，径袭慕容复的上盘。慕容复道：“两位前辈……”他只说了四个字，突然间呼呼声响，三柄长刀着地卷来。三人使动地堂刀功夫，袭向慕容复下盘。慕容复上方、前方、左侧同时三处受攻，心想：“对方号称是三十六洞洞主、七十二岛岛主，人多势众，混战下去，若不让他们知道厉害，如何方了？”眼见三柄长刀着地掠来，当即踢出三脚，每一脚都正中敌人手腕，白光闪动，三柄刀都飞了上天。慕容复身形略侧，右手一掠，使出“斗转星移”功夫，拨动金带带头，拍的一声响，金带和银带已缠在一起。使地堂刀的三人单刀脱手，更不退后，荷荷发喊，张臂便来抱慕容复的双腿。慕容复足尖起处，势如飘风般接连踢中了三人胸口穴道。蓦地里一个长臂长腿的黑衣人越众而前，张开蒲扇般的大手，一把将桑土公抓了起来。此人手掌也不知是天生厚皮，还是戴了金属丝所织的手套，竟然不怕桑土公满身倒刺，一抓到人，便直腿向后一跃，退开丈余。慕容复见这人身手沉稳老辣，武功比其余诸人高强得多，心下暗惊：“桑土公若被此人救去，再取解药可就不易了。”心念微动，已然跃起，越过横卧地下的三人，右掌拍出，径袭黑衣人。那人一声冷笑，横刀当胸，身前绿光闪闪，竟是一柄厚背薄刃、锋锐异常的鬼头刀，刀口向外。慕容复这掌拍落，那是硬生生将自己手腕切断了。他径不收招，待手掌离刃口约有二吋，突然改拍为掠，手掌顺着刃口一抹而下，径削黑衣人抓着刀柄的手指。\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunk_text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozdnyESpNBhq",
        "outputId": "2f462a99-0e4e-4f68-8358-622b6bda1d9f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "第二章 玉壁月华明\n",
            "\n",
            "折腾了这久，月亮已渐到中天，段誉迳向西行，他虽不会武功，但年轻力壮，脚下也甚迅捷，走出十余里，已经到无量山峰的后山，只听得水声淙淙，前面有条山溪。他正感口渴，寻声来到溪旁，月光下溪水清澈异常，刚伸手入溪，忽听得远处地下枯枝格的一响，跟着有两人的脚步之声，段誉忙俯伏溪边，不敢稍动。\n",
            "    只听得一人道：“这里有溪水，喝些水再走吧。”声音有些熟悉，随即想起，便是左子穆的弟子干光豪，段誉更加不敢动弹。只听两人走到溪水上游，跟着便有掬水和饮水之声。过了一会，干光豪道：“葛师妹，咱们已脱险境，你走得累了，咱们歇一会儿再赶路。”一个女子声音嗯了一声。溪边悉率有声，想是二人坐了下来。\n",
            "    只听那女子道：“你料得定神农帮不会派人守在这里吗？”语音微微发颤，显得甚是害怕。干光豪安慰道：“你放心。这条山道再也隐僻不过，连我们东宗弟子来过的人也不多，神农帮决计不会知道。”那女子道：“你怎么知道这条小路？”干光豪道：“师父每隔五天，便带众弟子来钻研‘无量玉壁’上的秘奥，这么多年下来，大伙儿尽是呆呆瞪着这块大石头，什么也瞧不出来。师父老是说什么‘成大功者，须得有恒心毅力’，又说什么‘有志者事竟成’。可是我实在瞧得忒腻了，有时假装要大解，便出来到处乱走，才发见了这条小路。”\n",
            "    那女子轻轻一笑，道：“原来你不用功，偷懒逃学。你众同门之中，该算你最没恒心毅力了。”干光豪笑道：“葛师妹，五年前剑湖宫比剑，我败在你剑下之后……”那女子道：“别再说你败在我剑下。当时你假装内力不济，故意让我，别人虽然瞧不出来，难道我自己也不知道？”\n",
            "    段誉听到这里，心道：“原来这女子是无量剑西宗的。”\n",
            "    只听干光豪道：“我一见你面，心里就发下了重誓，说什么也要跟你终身厮守。幸好今日碰上了千载难逢的良机，神农帮突然来攻，又有两个小狗男女带了一只毒貂来，闹得剑湖宫中人人手忙脚乱，咱们便乘机逃了出来，这不是有志者事竟成吗？”那女子轻轻一笑，柔声道：“我也是有志者事竟成。”干光豪道：“葛师妹，你待我这样，我一生一世，永远听你的话。”从语音中显得喜不自胜。\n",
            "    那女子叹了口气，说道：“咱们这番背师私逃，武林中是再也不能立足了，该当逃得越远越好，总得找个十分隐僻的所在，悄悄躲将起来，别让咱们师父与同门发见了踪迹才好。想起来我实在害怕。”干光豪道：“那也不用担心了。我瞧这次神农帮有备而来，咱们东西两宗，除了咱二人之外，只怕谁也难逃毒手。”那女子又叹了口气，道：“但愿如此。”\n",
            "    段誉只听得气往上冲，寻思：“你们要结为夫妇，见师门有难，乘机自行逃走，那也罢了，怎地反盼望自己师长同门尽遭毒手，用心忒也狠毒。”想到他二人如此险狠，自己若给他们发觉，必定会给杀了灭口，当下更是连大气也不敢喘上一口。\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p1MHzEQDQRTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 短的prompt\n",
        "\n",
        "schema = Object(\n",
        "    id=\"script\",\n",
        "    description=\"Adapted from the novel into script\",\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"role\",\n",
        "            description=\"The character who is speaking or acting, predict the role name from context.\",\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"action\",\n",
        "            description='''If a role is speaking, action equals \"说\" or \"想\"; otherwise, highly summarize character's behavior.''',\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"dialogue\",\n",
        "            description=\"The dialogue spoken by the characters in the sentence\",\n",
        "        )\n",
        "    ],\n",
        "    examples=[\n",
        "        (\n",
        "            '''``干光豪笑道：“葛师妹，我败在你剑下之后……”那女子道：“别再说你败在我剑下。” 段誉听到这里，心道：“原来这女子是无量剑宗的。”``''',\n",
        "            [\n",
        "                {\"role\": \"干光豪\",\"action\":\"说\", \"dialogue\": \"葛师妹，我败在你剑下之后……\"},\n",
        "                {\"role\": \"葛师妹\",\"action\":\"说\", \"dialogue\": \"别再说你败在我剑下。\"},\n",
        "                {\"role\": \"段誉\",\"action\":\"想\", \"dialogue\": \"原来这女子是无量剑宗的。\"}\n",
        "            ],\n",
        "        ),\n",
        "        (\n",
        "            '''``桑土公被雄劲的袖风卷起，肉球般的身子飞向半空。他自中了慕容复一掌之后，受伤已然不轻，这时殊无抗御之力，大声叫道：“休下毒手，我给你解药！”``''',\n",
        "            [\n",
        "                {\"role\": \"桑土公\", \"action\":\"被风卷起, 飞向半空, 受伤不轻, 无抗御之力\", \"dialogue\":\"\"},\n",
        "                {\"role\": \"桑土公\", \"action\": \"说\",\"dialogue\":\"休下毒手，我给你解药！\"},\n",
        "            ],\n",
        "        )\n",
        "    ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "krini6V0M75K"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNEDCGL4RHW7",
        "outputId": "5ce59753-ad14-4c73-86e7-d6e7ef786b91"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/GPTData/tianlongbabu_extract\"\n",
        "\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder)"
      ],
      "metadata": {
        "id": "xMyOHMHmQS01"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/GPTData/tianlongbabu_extract/*88.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPdjOOoxQxyK",
        "outputId": "8b899ef3-8e12-4040-a570-e2ee0881571a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GPTData/tianlongbabu_extract/188.txt\n",
            "/content/drive/MyDrive/GPTData/tianlongbabu_extract/288.txt\n",
            "/content/drive/MyDrive/GPTData/tianlongbabu_extract/388.txt\n",
            "/content/drive/MyDrive/GPTData/tianlongbabu_extract/488.txt\n",
            "/content/drive/MyDrive/GPTData/tianlongbabu_extract/588.txt\n",
            "/content/drive/MyDrive/GPTData/tianlongbabu_extract/688.txt\n",
            "/content/drive/MyDrive/GPTData/tianlongbabu_extract/788.txt\n",
            "/content/drive/MyDrive/GPTData/tianlongbabu_extract/88.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain(llm, schema)\n",
        "print(chain.prompt.format_prompt(text=\"[user input]\").to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzy4ZFpVQqqH",
        "outputId": "fd4c7116-2c60-478d-bfb9-28aaa46481e2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
            "\n",
            "```TypeScript\n",
            "\n",
            "script: Array<{ // Adapted from the novel into script\n",
            " role: string // The character who is speaking or acting, predict the role name from context.\n",
            " action: string // If a role is speaking, action equals \"说\" or \"想\"; otherwise, highly summarize character's behavior.\n",
            " dialogue: string // The dialogue spoken by the characters in the sentence\n",
            "}>\n",
            "```\n",
            "\n",
            "\n",
            "Please output the extracted information in CSV format in Excel dialect. Please use a | as the delimiter. \n",
            " Do NOT add any clarifying information. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.\n",
            "\n",
            "\n",
            "\n",
            "Input: ``干光豪笑道：“葛师妹，我败在你剑下之后……”那女子道：“别再说你败在我剑下。” 段誉听到这里，心道：“原来这女子是无量剑宗的。”``\n",
            "Output: role|action|dialogue\n",
            "干光豪|说|葛师妹，我败在你剑下之后……\n",
            "葛师妹|说|别再说你败在我剑下。\n",
            "段誉|想|原来这女子是无量剑宗的。\n",
            "\n",
            "Input: ``桑土公被雄劲的袖风卷起，肉球般的身子飞向半空。他自中了慕容复一掌之后，受伤已然不轻，这时殊无抗御之力，大声叫道：“休下毒手，我给你解药！”``\n",
            "Output: role|action|dialogue\n",
            "桑土公|被风卷起, 飞向半空, 受伤不轻, 无抗御之力|\n",
            "桑土公|说|休下毒手，我给你解药！\n",
            "\n",
            "Input: [user input]\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# save_folder = \"/content/drive/MyDrive/GPTData/weixiaobao_extract\"\n",
        "\n",
        "for i in tqdm(range(801,len(chunk_text))):\n",
        "\n",
        "  save_name = os.path.join(save_folder, f\"{i}.txt\")\n",
        "\n",
        "  if os.path.exists(save_name):\n",
        "    continue\n",
        "  query_text = f\"``{chunk_text[i]}``\"\n",
        "  response = chain.run( query_text )[\"data\"]\n",
        "\n",
        "  with open(save_name, 'w', encoding='utf-8') as f:\n",
        "\n",
        "    if 'script' not in response:\n",
        "        print('Error: response does not contain key \"script\"')\n",
        "    else:\n",
        "        for chat in response['script']:\n",
        "            json_str = json.dumps(chat, ensure_ascii=False)\n",
        "            f.write(json_str+\"\\n\")\n",
        "\n",
        "\n",
        "#   break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDEiY9_OQXis",
        "outputId": "a337bfc7-71b0-499b-dc80-299d2090987e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 60/384 [30:04<2:13:36, 24.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 221/384 [1:56:10<2:29:42, 55.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 253/384 [2:12:51<1:09:14, 31.72s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: HTTP code 502 from API (<html>\n",
            "<head><title>502 Bad Gateway</title></head>\n",
            "<body>\n",
            "<center><h1>502 Bad Gateway</h1></center>\n",
            "<hr><center>cloudflare</center>\n",
            "</body>\n",
            "</html>\n",
            ").\n",
            " 68%|██████▊   | 262/384 [2:19:50<1:11:56, 35.38s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 72%|███████▏  | 278/384 [2:27:51<45:04, 25.52s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 73%|███████▎  | 281/384 [2:29:27<49:19, 28.73s/it]WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 31 Jul 2023 12:02:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7ef5a952fc664588-ATL', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            " 78%|███████▊  | 299/384 [2:42:56<39:07, 27.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 303/384 [2:44:49<38:06, 28.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
            " 96%|█████████▌| 368/384 [3:21:21<07:15, 27.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 378/384 [3:25:59<02:42, 27.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 381/384 [3:27:36<01:29, 29.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: response does not contain key \"script\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 384/384 [3:29:05<00:00, 32.67s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kor Basics\n",
        "\n",
        "The basic workflow is the following:\n",
        "\n",
        "1. Load the document\n",
        "2. Clean up the document (optional)\n",
        "3. Split the document into chunks\n",
        "4. Define a schema for extraction\n",
        "5. Extract from every chunk of text"
      ],
      "metadata": {
        "id": "9M-CROtIBixD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from kor.extraction import create_extraction_chain\n",
        "from kor.nodes import Object, Text, Number\n",
        "\n",
        "import pandas as pd\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from kor import extract_from_documents, from_pydantic, create_extraction_chain\n",
        "\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
      ],
      "metadata": {
        "id": "Kk3c8z0PBgeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple examples"
      ],
      "metadata": {
        "id": "29nRABvafCEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        ")"
      ],
      "metadata": {
        "id": "sJiJwJ5UfER6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = Object(\n",
        "    id=\"personal_info\",\n",
        "    description=\"Personal information about a given person.\",\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"first_name\",\n",
        "            description=\"The first name of the person\",\n",
        "            examples=[(\"John Smith went to the store\", \"John\")],\n",
        "        ),\n",
        "        Text(\n",
        "            id=\"last_name\",\n",
        "            description=\"The last name of the person\",\n",
        "            examples=[(\"John Smith went to the store\", \"Smith\")],\n",
        "        ),\n",
        "        Number(\n",
        "            id=\"age\",\n",
        "            description=\"The age of the person in years.\",\n",
        "            examples=[(\"23 years old\", \"23\"), (\"I turned three on sunday\", \"3\")],\n",
        "        ),\n",
        "    ],\n",
        "    examples=[\n",
        "        (\n",
        "            \"John Smith was 23 years old. He was very tall. He knew Jane Doe. She was 5 years old.\",\n",
        "            [\n",
        "                {\"first_name\": \"John\", \"last_name\": \"Smith\", \"age\": 23},\n",
        "                {\"first_name\": \"Jane\", \"last_name\": \"Doe\", \"age\": 5},\n",
        "            ],\n",
        "        )\n",
        "    ],\n",
        "    many=True,\n",
        ")\n",
        "\n",
        "\n",
        "chain = create_extraction_chain(llm, schema)"
      ],
      "metadata": {
        "id": "LDXQgLLVfd73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.prompt.format_prompt(text=\"[user input]\").to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWTguilQfkTM",
        "outputId": "d1d35d88-4086-4f73-9592-e32984b5ece1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
            "\n",
            "```TypeScript\n",
            "\n",
            "personal_info: Array<{ // Personal information about a given person.\n",
            " first_name: string // The first name of the person\n",
            " last_name: string // The last name of the person\n",
            " age: number // The age of the person in years.\n",
            "}>\n",
            "```\n",
            "\n",
            "\n",
            "Please output the extracted information in CSV format in Excel dialect. Please use a | as the delimiter. \n",
            " Do NOT add any clarifying information. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.\n",
            "\n",
            "\n",
            "\n",
            "Input: John Smith was 23 years old. He was very tall. He knew Jane Doe. She was 5 years old.\n",
            "Output: first_name|last_name|age\n",
            "John|Smith|23\n",
            "Jane|Doe|5\n",
            "\n",
            "Input: John Smith went to the store\n",
            "Output: first_name|last_name|age\n",
            "John||\n",
            "\n",
            "Input: John Smith went to the store\n",
            "Output: first_name|last_name|age\n",
            "|Smith|\n",
            "\n",
            "Input: 23 years old\n",
            "Output: first_name|last_name|age\n",
            "||23\n",
            "\n",
            "Input: I turned three on sunday\n",
            "Output: first_name|last_name|age\n",
            "||3\n",
            "\n",
            "Input: [user input]\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.predict_and_parse(text=\"David Jones was 34 years old a long time ago.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "4PjSryvAfwXE",
        "outputId": "37533634-bbcf-436f-c9c0-84499314c026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f5adf3ed0ef7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_and_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"David Jones was 34 years old a long time ago.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict_and_parse\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kor/extraction/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;34m\"\"\"Parse the text.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"errors\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validated_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kor/encoders/csv_data.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtable_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     df = pd.read_csv(\n",
            "\u001b[0;31mTypeError\u001b[0m: initial_value must be str or None, not dict"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nested Objects and JSON"
      ],
      "metadata": {
        "id": "dz9gWTk4TGd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from_address = Object(\n",
        "    id=\"from_address\",\n",
        "    description=\"Person moved away from this address\",\n",
        "    attributes=[\n",
        "        Text(id=\"street\"),\n",
        "        Text(id=\"city\"),\n",
        "        Text(id=\"state\"),\n",
        "        Text(id=\"zipcode\"),\n",
        "        Text(id=\"country\", description=\"A country in the world; e.g., France.\"),\n",
        "    ],\n",
        "    examples=[\n",
        "        (\n",
        "            \"100 Main St, Boston, MA, 23232, USA\",\n",
        "            {\n",
        "                \"street\": \"100 Marlo St\",\n",
        "                \"city\": \"Boston\",\n",
        "                \"state\": \"MA\",\n",
        "                \"zipcode\": \"23232\",\n",
        "                \"country\": \"USA\",\n",
        "            },\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "to_address = from_address.replace(\n",
        "    id=\"to_address\", description=\"Address to which the person is moving\"\n",
        ")\n",
        "\n",
        "schema = Object(\n",
        "    id=\"information\",\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"person_name\",\n",
        "            description=\"The full name of the person or partial name\",\n",
        "            examples=[(\"John Smith was here\", \"John Smith\")],\n",
        "        ),\n",
        "        from_address,\n",
        "        to_address,\n",
        "    ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "LOOSR4DyYX-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON encoding\n",
        "To use nested objects, at least for now we have to swap to the JSON encoder."
      ],
      "metadata": {
        "id": "f37I2uk5ezfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain(\n",
        "    llm, schema, encoder_or_encoder_class=\"json\", input_formatter=None\n",
        ")"
      ],
      "metadata": {
        "id": "UpcrZoeje1Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.prompt.format_prompt(text=\"[user input]\").to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-7Pox8hulAX",
        "outputId": "7520ccf5-d6f7-43f8-f7fc-832d1fb4a024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
            "\n",
            "```TypeScript\n",
            "\n",
            "information: Array<{ // \n",
            " person_name: string // The full name of the person or partial name\n",
            " to_address: { // Address to which the person is moving\n",
            "  street: string // \n",
            "  city: string // \n",
            "  state: string // \n",
            "  zipcode: string // \n",
            "  country: string // A country in the world; e.g., France.\n",
            " }\n",
            " to_address: { // Address to which the person is moving\n",
            "  street: string // \n",
            "  city: string // \n",
            "  state: string // \n",
            "  zipcode: string // \n",
            "  country: string // A country in the world; e.g., France.\n",
            " }\n",
            "}>\n",
            "```\n",
            "\n",
            "\n",
            "Please output the extracted information in JSON format. Do not output anything except for the extracted information. Do not add any clarifying information. Do not add any fields that are not in the schema. If the text contains attributes that do not appear in the schema, please ignore them. All output must be in JSON format and follow the schema specified above. Wrap the JSON in <json> tags.\n",
            "\n",
            "\n",
            "\n",
            "Input: John Smith was here\n",
            "Output: <json>{\"information\": [{\"person_name\": \"John Smith\"}]}</json>\n",
            "Input: 100 Main St, Boston, MA, 23232, USA\n",
            "Output: <json>{\"information\": [{\"to_address\": {\"street\": \"100 Marlo St\", \"city\": \"Boston\", \"state\": \"MA\", \"zipcode\": \"23232\", \"country\": \"USA\"}}]}</json>\n",
            "Input: 100 Main St, Boston, MA, 23232, USA\n",
            "Output: <json>{\"information\": [{\"to_address\": {\"street\": \"100 Marlo St\", \"city\": \"Boston\", \"state\": \"MA\", \"zipcode\": \"23232\", \"country\": \"USA\"}}]}</json>\n",
            "Input: [user input]\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.predict_and_parse(\n",
        "    text=\"Alice Doe moved from New York to Boston, MA while Bob Smith did the opposite.\"\n",
        ")[\"data\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "Pa4Jdj89khtD",
        "outputId": "a9f2acb0-1252-469a-c830-f53bc09ee5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-295d54d87229>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m chain.predict_and_parse(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Alice Doe moved from New York to Boston, MA while Bob Smith did the opposite.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )[\"data\"]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict_and_parse\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kor/extraction/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;34m\"\"\"Parse the text.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"errors\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validated_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kor/encoders/json_data.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \"\"\"\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kor/encoders/utils.py\u001b[0m in \u001b[0;36munwrap_tag\u001b[0;34m(tag_name, text)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"<{tag_name}>(.*?)</{tag_name}>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Pydantic and validation"
      ],
      "metadata": {
        "id": "jZRRn5mxQPDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.dropbox.com/s/gekyuep86zibhl1/conversation-025722052023.txt"
      ],
      "metadata": {
        "id": "6s4_vP1DfSd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the document"
      ],
      "metadata": {
        "id": "9PX7S0ykCJ9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_conversation(filename):\n",
        "\n",
        "    with open(filename, 'r') as f:\n",
        "        conversation = f.read()\n",
        "\n",
        "    return conversation\n"
      ],
      "metadata": {
        "id": "2EpriZKOhbHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = load_conversation('/content/conversation-025722052023.txt')\n",
        "\n",
        "len(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yJMEUnQt9id",
        "outputId": "d21d42d4-fdc3-47aa-aa16-730c763cf42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9456"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "B7TLMT90rMdo",
        "outputId": "4b4d81f3-de36-4ffa-d726-d029a28aa52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Food lover 2: Instruction: Please describe your first most unforgettable meal, including the location, ambiance, taste, and any unique experiences.\\nInput: My first most unforgettable meal was at a restaurant called El Celler de Can Roca in Girona, Spain. The ambiance was elegant and modern, and the food was a creative and delicious 18-course tasting menu. One unique experience was when they brought out a dish that was inspired by the smells of the forest.\\n\\nFood lover 1: My response: That sounds amazing! The forest-inspired dish must have been a unique experience. My first most unforgettable meal was at a restaurant called Noma in Copenhagen, Denmark. The location was in an old warehouse by the waterfront, and the ambiance was rustic and cozy. The food was presented in a simple and natural way, with many of the ingredients sourced from the surrounding Nordic region. One of the most memorable dishes was a dessert made with fermented berries and ants, which added a surprising and delicious crunch. Overall, it was a truly unforgettable dining experience that showcased the beauty and flavors of Nordic cuisine. Next question.\\n\\nFood lover 2: Instruction: Please describe your second most unforgettable meal, including the location, ambiance, taste, and any unique experiences.\\nInput: My second most unforgettable meal was at a small family-owned restaurant called La Cava del Tequila in Mexico City. The ambiance was cozy and intimate, with dim lighting and traditional Mexican decor. The food was authentic and flavorful, with a focus on regional specialties. One unique experience was when the owner came to our table and gave us a tequila tasting, explaining the different types and flavors. The standout dish for me was the mole, which had a complex and rich flavor that I had never tasted before.\\n\\nFood lover 1: My response: That sounds like a wonderful experience! My second most unforgettable meal was at a restaurant called Gaggan in Bangkok, Thailand. The location was in a beautiful colonial-style house, and the ambiance was modern and chic. The food was a creative and playful take on Indian cuisine, with each dish presented in a unique and artistic way. One unique experience was when they brought out a dish that was meant to be eaten with your hands, and it was served on a miniature replica of a tree. The standout dish for me was the \"Lick It Up\" course, which was a deconstructed version of a traditional Indian street food dish. Overall, it was an unforgettable dining experience that showcased the creativity and innovation of modern Indian cuisine. Next question.\\n\\nFood lover 2: Instruction: Please describe your third most unforgettable meal, including the location, ambiance, taste, and any unique experiences.\\nInput: My third most unforgettable meal was at a restaurant called Osteria Francescana in Modena, Italy. The location was in a historic building in the heart of the city, and the ambiance was elegant and refined. The food was a modern take on traditional Italian cuisine, with a focus on local and seasonal ingredients. One unique experience was when they brought out a dish that was inspired by the childhood memories of the chef, Massimo Bottura. The standout dish for me was the \"Oops! I Dropped the Lemon Tart,\" which was a deconstructed version of a lemon tart that was presented in a playful and unexpected way. Overall, it was an unforgettable dining experience that showcased the creativity and passion of Italian cuisine.\\n\\nFood lover 1: My response: That\\'s a great choice! My third most unforgettable meal was at a restaurant called Attica in Melbourne, Australia. The location was in a converted warehouse, and the ambiance was modern and minimalist. The food was a creative and innovative take on Australian cuisine, with a focus on native ingredients and flavors. One unique experience was when they brought out a dish that was meant to be eaten with your hands, and it was served on a bed of eucalyptus leaves. The standout dish for me was the \"Potato cooked in the earth it was grown,\" which was a simple yet delicious dish that showcased the natural flavors of the potato. Overall, it was an unforgettable dining experience that showcased the beauty and diversity of Australian cuisine. Next question.\\n\\nFood lover 2: Instruction: Please rate my first meal based on originality, presentation, and overall satisfaction.\\nInput: I would rate your first meal very highly based on originality, presentation, and overall satisfaction. The forest-inspired dish sounds like a unique and creative concept, and the elegant and modern ambiance of the restaurant must have added to the overall experience. The 18-course tasting menu also shows a high level of creativity and attention to detail. Overall, it sounds like a truly unforgettable dining experience.\\n\\nFood lover 1: My response: I completely agree with your assessment. Your first meal sounds like it was a truly unforgettable dining experience, with a high level of originality, presentation, and overall satisfaction. The attention to detail and creativity in the dishes, as well as the elegant and modern ambiance of the restaurant, must have made for a truly memorable experience. I would rate your first meal very highly based on these factors. Next question.\\n\\nFood lover 2: Instruction: Please rate my second meal based on originality, presentation, and overall satisfaction.\\nInput: I would rate your second meal very highly based on originality, presentation, and overall satisfaction. The cozy and intimate ambiance of the restaurant, along with the authentic and flavorful Mexican cuisine, must have made for a truly memorable experience. The tequila tasting and focus on regional specialties also show a high level of attention to detail and passion for the cuisine. Overall, it sounds like a wonderful dining experience.\\n\\nFood lover 1: My response: I completely agree with your assessment. Your second meal sounds like it was a wonderful dining experience, with a high level of originality, presentation, and overall satisfaction. The cozy and intimate ambiance of the restaurant, along with the authentic and flavorful Mexican cuisine, must have made for a truly memorable experience. The tequila tasting and focus on regional specialties also show a high level of attention to detail and passion for the cuisine. I would rate your second meal very highly based on these factors. Next question.\\n\\nFood lover 2: Instruction: Please rate my third meal based on originality, presentation, and overall satisfaction.\\nInput: I would rate your third meal very highly based on originality, presentation, and overall satisfaction. The elegant and refined ambiance of the restaurant, along with the modern take on traditional Italian cuisine, must have made for a truly unforgettable dining experience. The dish inspired by the childhood memories of the chef, as well as the deconstructed lemon tart, show a high level of creativity and attention to detail. Overall, it sounds like a truly exceptional dining experience.\\n\\nFood lover 1: My response: I completely agree with your assessment. Your third meal sounds like it was a truly exceptional dining experience, with a high level of originality, presentation, and overall satisfaction. The elegant and refined ambiance of the restaurant, along with the modern take on traditional Italian cuisine, must have made for a truly unforgettable dining experience. The dish inspired by the childhood memories of the chef, as well as the deconstructed lemon tart, show a high level of creativity and attention to detail. I would rate your third meal very highly based on these factors. Next question.\\n\\nFood lover 2: Instruction: Based on our descriptions and ratings of each other\\'s meals, which meal would you be most interested in trying and why?\\nInput: Based on our descriptions and ratings of each other\\'s meals, I would be most interested in trying your second meal at Noma in Copenhagen, Denmark. The rustic and cozy ambiance of the restaurant, along with the creative and playful take on Nordic cuisine, sounds like a truly unique and memorable dining experience. The dessert made with fermented berries and ants also sounds like a fascinating and delicious dish to try. Overall, I would love to experience the beauty and flavors of Nordic cuisine at Noma.\\n\\nFood lover 1: My response: That\\'s a great choice! Based on our descriptions and ratings of each other\\'s meals, I would be most interested in trying your first meal at Osteria Francescana in Modena, Italy. The elegant and modern ambiance of the restaurant, along with the creative and artistic presentation of the dishes, sounds like a truly unforgettable dining experience. The \"Oops! I Dropped the Lemon Tart\" dessert also sounds like a playful and unexpected dish that would be a delight to try. Overall, I would love to experience the creativity and passion of Italian cuisine at Osteria Francescana.\\n\\nFood lover 2: Instruction: It seems like we both have a great choice in mind. Thank you for sharing your unforgettable meals with me. <TASK_DONE>\\n\\nFood lover 1: My response: You\\'re welcome! It was a pleasure sharing our unforgettable meals with each other. I look forward to collaborating with you on future tasks. <TASK_DONE>\\n\\nFood lover 2: Great! Looking forward to working with you again. <TASK_DONE>\\n\\nFood lover 1: Likewise! Have a great day. <TASK_DONE>\\n\\nFood lover 2: You too! <TASK_DONE>\\n\\nFood lover 1: Thank you! <TASK_DONE>\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split the text into docs"
      ],
      "metadata": {
        "id": "FPcmGiUQiVdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = Document(page_content=conversation)"
      ],
      "metadata": {
        "id": "4XKVN0TOHJo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_docs = RecursiveCharacterTextSplitter().split_documents([doc])"
      ],
      "metadata": {
        "id": "A0c_8-qqHAXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extract Restaurant Info\n"
      ],
      "metadata": {
        "id": "OubDxc9VCh6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(\n",
        "     model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        ")"
      ],
      "metadata": {
        "id": "S9RZ9RZHCrPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Restaurant(BaseModel):\n",
        "    name: str = Field(\n",
        "        description=\"The name of the restaurant\",\n",
        "    )\n",
        "    location: Optional[str] = Field(\n",
        "        description=\"City and or country, the place where the restaurant is\",\n",
        "    )\n",
        "    style: Optional[str] = Field(\n",
        "        description=\"The types of cusine that is served at the restaurant\",\n",
        "    )\n",
        "    top_dish: Optional[str] = Field(\n",
        "        description=\"The top dish that people love the most\",\n",
        "    )\n",
        "\n",
        "    @validator(\"name\")\n",
        "    def name_must_not_be_empty(cls, v):\n",
        "        if not v:\n",
        "            raise ValueError(\"Name must not be empty\")\n",
        "        return v\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6_Wof-S4EKMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema, extraction_validator = from_pydantic(\n",
        "    Restaurant,\n",
        "    description=\"Extract information about restaurants including their name, location, style and dishes.\",\n",
        "    examples=[\n",
        "        (\n",
        "            \"My first fav meal was at a restaurant called Burnt Ends in Singapore.\",\n",
        "            {\"name\": \"Burnt Ends\", \"location\": \"Singapore\"},\n",
        "        )\n",
        "    ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "wKJ6J7Ze0xhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain(\n",
        "    llm,\n",
        "    schema,\n",
        "    encoder_or_encoder_class=\"csv\",\n",
        "    validator=extraction_validator,\n",
        "    input_formatter=\"triple_quotes\",\n",
        ")"
      ],
      "metadata": {
        "id": "TCYXBYvSFYEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.prompt.format_prompt(text=\"[user input]\").to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57McFWe6uTnu",
        "outputId": "c5c6d7c2-509f-4ee2-8753-2d6217f82d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
            "\n",
            "```TypeScript\n",
            "\n",
            "restaurant: Array<{ // Extract information about restaurants including their name, location, style and dishes.\n",
            " name: string // The name of the restaurant\n",
            " location: string // City and or country, the place where the restaurant is\n",
            " style: string // The types of cusine that is served at the restaurant\n",
            " top_dish: string // The top dish that people love the most\n",
            "}>\n",
            "```\n",
            "\n",
            "\n",
            "Please output the extracted information in CSV format in Excel dialect. Please use a | as the delimiter. \n",
            " Do NOT add any clarifying information. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.\n",
            "\n",
            "\n",
            "\n",
            "Input: \"\"\"\n",
            "My first fav meal was at a restaurant called Burnt Ends in Singapore.\n",
            "\"\"\"\n",
            "Output: name|location|style|top_dish\n",
            "Burnt Ends|Singapore||\n",
            "\n",
            "Input: \"\"\"\n",
            "[user input]\n",
            "\"\"\"\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    document_extraction_results = await extract_from_documents(\n",
        "        chain, split_docs, max_concurrency=5, use_uid=False, return_exceptions=True\n",
        "    )\n",
        "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
        "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
        "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
        "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
        "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLdZLuJ1GlgO",
        "outputId": "a6281a2e-2920-4f02-f7fa-e55b00a444c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tokens: 2745\n",
            "Prompt Tokens: 2583\n",
            "Completion Tokens: 162\n",
            "Successful Requests: 3\n",
            "Total Cost (USD): $0.00549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_extraction_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCAH5bPUGlj6",
        "outputId": "5a1fd306-4891-412a-83d0-14b2d996ca67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'uid': '0',\n",
              "  'source_uid': '0',\n",
              "  'data': {'restaurant': [{'name': 'El Celler de Can Roca',\n",
              "     'location': 'Girona, Spain',\n",
              "     'style': '',\n",
              "     'top_dish': 'forest-inspired dish'},\n",
              "    {'name': 'Noma',\n",
              "     'location': 'Copenhagen, Denmark',\n",
              "     'style': 'Nordic cuisine',\n",
              "     'top_dish': 'fermented berries and ants dessert'},\n",
              "    {'name': 'La Cava del Tequila',\n",
              "     'location': 'Mexico City, Mexico',\n",
              "     'style': 'Mexican',\n",
              "     'top_dish': 'mole'},\n",
              "    {'name': 'Gaggan',\n",
              "     'location': 'Bangkok, Thailand',\n",
              "     'style': 'modern Indian cuisine',\n",
              "     'top_dish': 'Lick It Up course'},\n",
              "    {'name': 'Osteria Francescana',\n",
              "     'location': 'Modena, Italy',\n",
              "     'style': 'modern Italian cuisine',\n",
              "     'top_dish': 'Oops! I Dropped the Lemon Tart'}]},\n",
              "  'raw': 'name|location|style|top_dish\\nEl Celler de Can Roca|Girona, Spain||forest-inspired dish\\nNoma|Copenhagen, Denmark|Nordic cuisine|fermented berries and ants dessert\\nLa Cava del Tequila|Mexico City, Mexico|Mexican|mole\\nGaggan|Bangkok, Thailand|modern Indian cuisine|\"Lick It Up\" course\\nOsteria Francescana|Modena, Italy|modern Italian cuisine|\"Oops! I Dropped the Lemon Tart\"',\n",
              "  'validated_data': [Restaurant(name='El Celler de Can Roca', location='Girona, Spain', style='', top_dish='forest-inspired dish'),\n",
              "   Restaurant(name='Noma', location='Copenhagen, Denmark', style='Nordic cuisine', top_dish='fermented berries and ants dessert'),\n",
              "   Restaurant(name='La Cava del Tequila', location='Mexico City, Mexico', style='Mexican', top_dish='mole'),\n",
              "   Restaurant(name='Gaggan', location='Bangkok, Thailand', style='modern Indian cuisine', top_dish='Lick It Up course'),\n",
              "   Restaurant(name='Osteria Francescana', location='Modena, Italy', style='modern Italian cuisine', top_dish='Oops! I Dropped the Lemon Tart')],\n",
              "  'errors': []},\n",
              " {'uid': '1',\n",
              "  'source_uid': '1',\n",
              "  'data': {'restaurant': [{'name': 'Attica',\n",
              "     'location': 'Melbourne, Australia',\n",
              "     'style': 'Australian cuisine',\n",
              "     'top_dish': 'Potato cooked in the earth it was grown'}]},\n",
              "  'raw': 'name|location|style|top_dish\\nAttica|Melbourne, Australia|Australian cuisine|Potato cooked in the earth it was grown',\n",
              "  'validated_data': [Restaurant(name='Attica', location='Melbourne, Australia', style='Australian cuisine', top_dish='Potato cooked in the earth it was grown')],\n",
              "  'errors': []},\n",
              " {'uid': '2',\n",
              "  'source_uid': '2',\n",
              "  'data': {'restaurant': []},\n",
              "  'raw': 'No structured information about restaurants is provided in this conversation. Therefore, I cannot extract any information about restaurants.',\n",
              "  'validated_data': [],\n",
              "  'errors': []}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's put it in a human readable format"
      ],
      "metadata": {
        "id": "8cc9_YenLuUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def extract_restaurant_info(json_data):\n",
        "    for record in json_data:\n",
        "        restaurant_list = record.get('data', {}).get('restaurant', [])\n",
        "        for restaurant in restaurant_list:\n",
        "            name = restaurant.get('name', '')\n",
        "            location = restaurant.get('location', '')\n",
        "            style = restaurant.get('style', '')\n",
        "            top_dish = restaurant.get('top_dish', '')\n",
        "\n",
        "            # If style is not specified, we'll just say \"Cuisine not specified\"\n",
        "            style = style if style else 'Cuisine not specified'\n",
        "\n",
        "            print(f'Restaurant Name: {name}\\nLocation: {location}\\nStyle: {style}\\nTop Dish: {top_dish}\\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "IGAiZqjvGlm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "extract_restaurant_info(document_extraction_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MUbvaicJL8W",
        "outputId": "7230af85-6eb8-40cd-8cd2-033817db1cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restaurant Name: El Celler de Can Roca\n",
            "Location: Girona, Spain\n",
            "Style: Cuisine not specified\n",
            "Top Dish: forest-inspired dish\n",
            "\n",
            "Restaurant Name: Noma\n",
            "Location: Copenhagen, Denmark\n",
            "Style: Nordic cuisine\n",
            "Top Dish: fermented berries and ants dessert\n",
            "\n",
            "Restaurant Name: La Cava del Tequila\n",
            "Location: Mexico City, Mexico\n",
            "Style: Mexican\n",
            "Top Dish: mole\n",
            "\n",
            "Restaurant Name: Gaggan\n",
            "Location: Bangkok, Thailand\n",
            "Style: modern Indian cuisine\n",
            "Top Dish: Lick It Up course\n",
            "\n",
            "Restaurant Name: Osteria Francescana\n",
            "Location: Modena, Italy\n",
            "Style: modern Italian cuisine\n",
            "Top Dish: Oops! I Dropped the Lemon Tart\n",
            "\n",
            "Restaurant Name: Attica\n",
            "Location: Melbourne, Australia\n",
            "Style: Australian cuisine\n",
            "Top Dish: Potato cooked in the earth it was grown\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lets put it in a structured DataFrame"
      ],
      "metadata": {
        "id": "UHWoSa6NLpXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def generate_dataframe(json_data):\n",
        "    # Prepare an empty list to store all restaurant data\n",
        "    data = []\n",
        "\n",
        "    for record in json_data:\n",
        "        restaurant_list = record.get('data', {}).get('restaurant', [])\n",
        "        for restaurant in restaurant_list:\n",
        "            # Get details for each restaurant and append it to data\n",
        "            data.append([\n",
        "                restaurant.get('name', ''),\n",
        "                restaurant.get('location', ''),\n",
        "                restaurant.get('style', '') if restaurant.get('style', '') else 'Cuisine not specified',\n",
        "                restaurant.get('top_dish', '')\n",
        "            ])\n",
        "\n",
        "    # Convert the list into a DataFrame\n",
        "    df = pd.DataFrame(data, columns=['Name', 'Location', 'Style', 'Top Dish'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Usage:\n",
        "df = generate_dataframe(document_extraction_results)\n"
      ],
      "metadata": {
        "id": "Xel0E62FJL-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "aul5vTtbJMDr",
        "outputId": "1d54a7f0-5437-4c7e-85bb-e53ae13263dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Name              Location                   Style  \\\n",
              "0  El Celler de Can Roca         Girona, Spain   Cuisine not specified   \n",
              "1                   Noma   Copenhagen, Denmark          Nordic cuisine   \n",
              "2    La Cava del Tequila   Mexico City, Mexico                 Mexican   \n",
              "3                 Gaggan     Bangkok, Thailand   modern Indian cuisine   \n",
              "4    Osteria Francescana         Modena, Italy  modern Italian cuisine   \n",
              "5                 Attica  Melbourne, Australia      Australian cuisine   \n",
              "\n",
              "                                  Top Dish  \n",
              "0                     forest-inspired dish  \n",
              "1       fermented berries and ants dessert  \n",
              "2                                     mole  \n",
              "3                        Lick It Up course  \n",
              "4           Oops! I Dropped the Lemon Tart  \n",
              "5  Potato cooked in the earth it was grown  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-321e5ede-152a-486b-936f-2ccd34d158da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Location</th>\n",
              "      <th>Style</th>\n",
              "      <th>Top Dish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>El Celler de Can Roca</td>\n",
              "      <td>Girona, Spain</td>\n",
              "      <td>Cuisine not specified</td>\n",
              "      <td>forest-inspired dish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Noma</td>\n",
              "      <td>Copenhagen, Denmark</td>\n",
              "      <td>Nordic cuisine</td>\n",
              "      <td>fermented berries and ants dessert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La Cava del Tequila</td>\n",
              "      <td>Mexico City, Mexico</td>\n",
              "      <td>Mexican</td>\n",
              "      <td>mole</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gaggan</td>\n",
              "      <td>Bangkok, Thailand</td>\n",
              "      <td>modern Indian cuisine</td>\n",
              "      <td>Lick It Up course</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Osteria Francescana</td>\n",
              "      <td>Modena, Italy</td>\n",
              "      <td>modern Italian cuisine</td>\n",
              "      <td>Oops! I Dropped the Lemon Tart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Attica</td>\n",
              "      <td>Melbourne, Australia</td>\n",
              "      <td>Australian cuisine</td>\n",
              "      <td>Potato cooked in the earth it was grown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-321e5ede-152a-486b-936f-2ccd34d158da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-321e5ede-152a-486b-936f-2ccd34d158da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-321e5ede-152a-486b-936f-2ccd34d158da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXMNJquwJMHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema, validator = from_pydantic(Restaurant)"
      ],
      "metadata": {
        "id": "cSwBpVV2JMJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain(\n",
        "    llm,\n",
        "    schema,\n",
        "    encoder_or_encoder_class=\"csv\",\n",
        "    validator=validator,\n",
        "    input_formatter=\"triple_quotes\",\n",
        ")"
      ],
      "metadata": {
        "id": "jOqsDAq34hne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    document_extraction_results = await extract_from_documents(\n",
        "        chain, split_docs, max_concurrency=5, use_uid=False, return_exceptions=True\n",
        "    )\n",
        "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
        "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
        "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
        "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
        "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6c1bfc-ed5f-4d3c-cb00-8a3a540617c2",
        "id": "a1Ch17pW4hnq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tokens: 2666\n",
            "Prompt Tokens: 2412\n",
            "Completion Tokens: 254\n",
            "Successful Requests: 3\n",
            "Total Cost (USD): $0.005332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_extraction_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34925efd-0c81-4845-d591-64cb52c2242b",
        "id": "oHeuZQAj4hnq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'uid': '0',\n",
              "  'source_uid': '0',\n",
              "  'data': {'restaurant': [{'name': '-',\n",
              "     'location': '-',\n",
              "     'style': '-',\n",
              "     'top_dish': '-'},\n",
              "    {'name': 'El Celler de Can Roca',\n",
              "     'location': 'Girona, Spain',\n",
              "     'style': 'Creative and delicious',\n",
              "     'top_dish': 'Forest-inspired dish'},\n",
              "    {'name': 'Noma',\n",
              "     'location': 'Copenhagen, Denmark',\n",
              "     'style': 'Simple and natural Nordic cuisine',\n",
              "     'top_dish': 'Dessert made with fermented berries and ants'},\n",
              "    {'name': 'La Cava del Tequila',\n",
              "     'location': 'Mexico City',\n",
              "     'style': 'Authentic and flavorful regional specialties',\n",
              "     'top_dish': 'Mole'},\n",
              "    {'name': 'Gaggan',\n",
              "     'location': 'Bangkok, Thailand',\n",
              "     'style': 'Creative and playful Indian cuisine',\n",
              "     'top_dish': 'Lick It Up course'},\n",
              "    {'name': 'Osteria Francescana',\n",
              "     'location': 'Modena, Italy',\n",
              "     'style': 'Modern take on traditional Italian cuisine',\n",
              "     'top_dish': 'Oops! I Dropped the Lemon Tart'}]},\n",
              "  'raw': 'name|location|style|top_dish\\n-|-|-|-\\nEl Celler de Can Roca|Girona, Spain|Creative and delicious|Forest-inspired dish\\nNoma|Copenhagen, Denmark|Simple and natural Nordic cuisine|Dessert made with fermented berries and ants\\nLa Cava del Tequila|Mexico City|Authentic and flavorful regional specialties|Mole\\nGaggan|Bangkok, Thailand|Creative and playful Indian cuisine|\"Lick It Up\" course\\nOsteria Francescana|Modena, Italy|Modern take on traditional Italian cuisine|\"Oops! I Dropped the Lemon Tart\"',\n",
              "  'validated_data': None,\n",
              "  'errors': [ValidationError(model='Restaurant', errors=[{'loc': ('__root__',), 'msg': 'Restaurant expected dict not list', 'type': 'type_error'}])]},\n",
              " {'uid': '1',\n",
              "  'source_uid': '1',\n",
              "  'data': {'restaurant': [{'restaurant_name': '---',\n",
              "     'location': '---',\n",
              "     'style': '---',\n",
              "     'top_dish': '---'},\n",
              "    {'restaurant_name': 'Attica',\n",
              "     'location': 'Melbourne, Australia',\n",
              "     'style': 'Australian',\n",
              "     'top_dish': 'Potato cooked in the earth it was grown'},\n",
              "    {'restaurant_name': 'N/A',\n",
              "     'location': 'N/A',\n",
              "     'style': 'Mexican',\n",
              "     'top_dish': 'N/A'},\n",
              "    {'restaurant_name': 'N/A',\n",
              "     'location': 'N/A',\n",
              "     'style': 'Italian',\n",
              "     'top_dish': 'deconstructed lemon tart'}]},\n",
              "  'raw': 'restaurant_name|location|style|top_dish\\n---|---|---|---\\nAttica|Melbourne, Australia|Australian|Potato cooked in the earth it was grown\\nN/A|N/A|Mexican|N/A\\nN/A|N/A|Italian|deconstructed lemon tart',\n",
              "  'validated_data': None,\n",
              "  'errors': [ValidationError(model='Restaurant', errors=[{'loc': ('__root__',), 'msg': 'Restaurant expected dict not list', 'type': 'type_error'}])]},\n",
              " {'uid': '2',\n",
              "  'source_uid': '2',\n",
              "  'data': {'restaurant': [{'restaurant_name': '---',\n",
              "     'location': '---',\n",
              "     'style': '---',\n",
              "     'top_dish': '---'},\n",
              "    {'restaurant_name': 'Osteria Francescana',\n",
              "     'location': 'Modena, Italy',\n",
              "     'style': 'Italian',\n",
              "     'top_dish': 'Oops! I Dropped the Lemon Tart'},\n",
              "    {'restaurant_name': 'Noma',\n",
              "     'location': 'Copenhagen, Denmark',\n",
              "     'style': 'Nordic',\n",
              "     'top_dish': 'Dessert made with fermented berries and ants'}]},\n",
              "  'raw': 'restaurant_name|location|style|top_dish\\n---|---|---|---\\nOsteria Francescana|Modena, Italy|Italian|Oops! I Dropped the Lemon Tart\\nNoma|Copenhagen, Denmark|Nordic|Dessert made with fermented berries and ants',\n",
              "  'validated_data': None,\n",
              "  'errors': [ValidationError(model='Restaurant', errors=[{'loc': ('__root__',), 'msg': 'Restaurant expected dict not list', 'type': 'type_error'}])]}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "extract_restaurant_info(document_extraction_results)"
      ],
      "metadata": {
        "id": "F6ayES-fJMMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6957e71e-e479-432a-bca8-c1906c4c2d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restaurant Name: -\n",
            "Location: -\n",
            "Style: -\n",
            "Top Dish: -\n",
            "\n",
            "Restaurant Name: El Celler de Can Roca\n",
            "Location: Girona, Spain\n",
            "Style: Creative and delicious\n",
            "Top Dish: Forest-inspired dish\n",
            "\n",
            "Restaurant Name: Noma\n",
            "Location: Copenhagen, Denmark\n",
            "Style: Simple and natural Nordic cuisine\n",
            "Top Dish: Dessert made with fermented berries and ants\n",
            "\n",
            "Restaurant Name: La Cava del Tequila\n",
            "Location: Mexico City\n",
            "Style: Authentic and flavorful regional specialties\n",
            "Top Dish: Mole\n",
            "\n",
            "Restaurant Name: Gaggan\n",
            "Location: Bangkok, Thailand\n",
            "Style: Creative and playful Indian cuisine\n",
            "Top Dish: Lick It Up course\n",
            "\n",
            "Restaurant Name: Osteria Francescana\n",
            "Location: Modena, Italy\n",
            "Style: Modern take on traditional Italian cuisine\n",
            "Top Dish: Oops! I Dropped the Lemon Tart\n",
            "\n",
            "Restaurant Name: \n",
            "Location: ---\n",
            "Style: ---\n",
            "Top Dish: ---\n",
            "\n",
            "Restaurant Name: \n",
            "Location: Melbourne, Australia\n",
            "Style: Australian\n",
            "Top Dish: Potato cooked in the earth it was grown\n",
            "\n",
            "Restaurant Name: \n",
            "Location: N/A\n",
            "Style: Mexican\n",
            "Top Dish: N/A\n",
            "\n",
            "Restaurant Name: \n",
            "Location: N/A\n",
            "Style: Italian\n",
            "Top Dish: deconstructed lemon tart\n",
            "\n",
            "Restaurant Name: \n",
            "Location: ---\n",
            "Style: ---\n",
            "Top Dish: ---\n",
            "\n",
            "Restaurant Name: \n",
            "Location: Modena, Italy\n",
            "Style: Italian\n",
            "Top Dish: Oops! I Dropped the Lemon Tart\n",
            "\n",
            "Restaurant Name: \n",
            "Location: Copenhagen, Denmark\n",
            "Style: Nordic\n",
            "Top Dish: Dessert made with fermented berries and ants\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wtpxoHWqrhxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VeyDe3YYrh2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MmRdOHM1rh5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pTBeKTe6rh85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtqjVbnyrh_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_RqAoNxriB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zY6NmWBari-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDAgdes_rjBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W57jeVugrjEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPW-Gfm6rjGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extraction_chain = create_extraction_chain(llm, restaurant_schema)"
      ],
      "metadata": {
        "id": "6oplQu-FDHks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sections[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "891192db-56cd-4865-b3e9-fa8b73f27a67",
        "id": "TmhWuWPSDHkt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Food lover 2: Instruction: Please describe your first most unforgettable meal, including the location, ambiance, taste, and any unique experiences.\\nInput: My first most unforgettable meal was at a restaurant called El Celler de Can Roca in Girona, Spain. The ambiance was elegant and modern, and the food was a creative and delicious 18-course tasting menu. One unique experience was when they brought out a dish that was inspired by the smells of the forest.\\n\\nFood lover 1: My response: That sounds amazing! The forest-inspired dish must have been a unique experience. My first most unforgettable meal was at a restaurant called Noma in Copenhagen, Denmark. The location was in an old warehouse by the waterfront, and the ambiance was rustic and cozy. The food was presented in a simple and natural way, with many of the ingredients sourced from the surrounding Nordic region. One of the most memorable dishes was a dessert made with fermented berries and ants, which added a surprising and delicious crunch. Overall, it was a truly unforgettable dining experience that showcased the beauty and flavors of Nordic cuisine. Next question.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = sections[0]\n",
        "\n",
        "extracted = extraction_chain.predict_and_parse(text=(text))[\"data\"]\n",
        "\n",
        "print(extracted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b83ca1-8d0c-4265-8c03-9c5784032ee9",
        "id": "oDJcwe0MDHkt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'restaurant': [{'name': 'El Celler de Can Roca'}, {'name': 'location'}, {'name': 'Girona, Spain'}, {'name': 'ambiance'}, {'name': 'elegant and modern'}, {'name': 'taste'}, {'name': 'creative and delicious 18-course tasting menu'}, {'name': 'unique experience'}, {'name': 'forest-inspired dish'}, {'name': 'name'}, {'name': 'Noma'}, {'name': 'location'}, {'name': 'Copenhagen, Denmark'}, {'name': 'ambiance'}, {'name': 'rustic and cozy'}, {'name': 'taste'}, {'name': 'simple and natural'}, {'name': 'unique experience'}, {'name': 'dessert made with fermented berries and ants'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xofp61TBghC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r5-4Q5vWBgkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jGf3Y_KPBgm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJioaZxYBgqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_conversation(filename, max_tokens=1024):\n",
        "    \"\"\"\n",
        "    Load a conversation from a file and split it into sections of approximately 2048 tokens.\n",
        "\n",
        "    Parameters:\n",
        "    filename (str): The name of the file to read the conversation from.\n",
        "    max_tokens (int): The maximum number of tokens per section.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of strings, where each string is a section of the conversation.\n",
        "    \"\"\"\n",
        "    with open(filename, 'r') as f:\n",
        "        conversation = f.read()\n",
        "\n",
        "    # Split the conversation into turns\n",
        "    turns = conversation.split(\"\\n\\n\")\n",
        "\n",
        "    sections = []\n",
        "    section = \"\"\n",
        "\n",
        "    for turn in turns:\n",
        "        # If adding the next turn would exceed the maximum number of tokens,\n",
        "        # add the current section to the list and start a new section\n",
        "        if len(section.split()) + len(turn.split()) > max_tokens:\n",
        "            sections.append(section.strip())\n",
        "            section = \"\"\n",
        "\n",
        "        # Add the turn to the current section\n",
        "        section += f\"{turn}\\n\\n\"\n",
        "\n",
        "    # Add the last section to the list\n",
        "    sections.append(section.strip())\n",
        "\n",
        "    return sections\n",
        "\n"
      ],
      "metadata": {
        "id": "42xbcr_zpr1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-H0Zo6ElBgsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zy9oZpCgBgvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_schema = Object(\n",
        "    id=\"restaurant\",\n",
        "    description=(\n",
        "        \"People are talking about restaurants names and dishes as well as qualities of the restaturant\"\n",
        "    ),\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"name\",\n",
        "            description=\"The name of the restaurant\"\n",
        "        )\n",
        "    ],\n",
        "    examples=[(\"We went for a quick bite at McDonalds\",[{\"name\": \"McDonalds\"}]),\n",
        "            (\"I just love the steaks at Mortons\",[{\"name\": \"Mortons\"}]),\n",
        "            (\"We already have a booking at The Eatery so can't goto Mortons\",[{\"name\": \"The Eatery\"},{\"name\": \"Mortons\"}])\n",
        "            ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "LPNKNO_7CrPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j5XOgiPoBgxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mgq6rHZmBg1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJRr4rQFBg3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EdrBK20cBg5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### with browsing\n"
      ],
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kor!\n",
        "from kor.extraction import create_extraction_chain\n",
        "from kor.nodes import Object, Text, Number\n",
        "\n",
        "# LangChain Models\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Standard Helpers\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Text Helpers\n",
        "from bs4 import BeautifulSoup\n",
        "from markdownify import markdownify as md\n",
        "\n",
        "# For token counting\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "def printOutput(output):\n",
        "    print(json.dumps(output,sort_keys=True, indent=3))"
      ],
      "metadata": {
        "id": "lgesD0jrvDyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the text file"
      ],
      "metadata": {
        "id": "GIe9SKlwpsup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the model"
      ],
      "metadata": {
        "id": "-4r3I0TBuJ6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(\n",
        "     model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    # max_tokens=2048,\n",
        ")"
      ],
      "metadata": {
        "id": "IfCt8bhHNu9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_schema = Object(\n",
        "    id=\"restaurant\",\n",
        "    description=(\n",
        "        \"People are talking about restaurants and dishes as well as qualities of the restaturant\"\n",
        "    ),\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"name\",\n",
        "            description=\"The name of the restaurant\"\n",
        "        )\n",
        "    ],\n",
        "    examples=[(\"We went for a quick bite at McDonalds\",[{\"name\": \"McDonalds\"}]),\n",
        "                      (\"I just love the steaks at Mortons\",[{\"name\": \"Mortons\"}]),\n",
        "                      (\"We already have a booking at The Eatery so can't goto Mortons\",[{\"name\": \"The Eatery\"},{\"name\": \"Mortons\"}])\n",
        "                      ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "G-O1nZ2Jpfec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restaurant_schema = Object(\n",
        "\n",
        "#     id=\"restaurant\",\n",
        "\n",
        "#     # Natural language description about your object\n",
        "#     description=\"Personal information about a person\",\n",
        "\n",
        "#     # Fields you'd like to capture from a piece of text about your object.\n",
        "#     attributes=[\n",
        "#         Text(\n",
        "#             id=\"first_name\",\n",
        "#             description=\"The first name of a person.\",\n",
        "#         )\n",
        "#     ],\n",
        "\n",
        "#     # Examples help go a long way with telling the LLM what you need\n",
        "#     examples=[\n",
        "#         (\"Alice and Bob are friends\", [{\"first_name\": \"Alice\"}, {\"first_name\": \"Bob\"}])\n",
        "#     ]\n",
        "# )"
      ],
      "metadata": {
        "id": "Ex0SPwExa6s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain(llm, restaurant_schema)"
      ],
      "metadata": {
        "id": "J2BbC0Q6cSKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sections[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "tG8gw5DWyRgj",
        "outputId": "93f878e0-edc6-4c9f-ab92-09741d89645e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Food lover 2: Instruction: Please describe your first most unforgettable meal, including the location, ambiance, taste, and any unique experiences.\\nInput: My first most unforgettable meal was at a restaurant called El Celler de Can Roca in Girona, Spain. The ambiance was elegant and modern, and the food was a creative and delicious 18-course tasting menu. One unique experience was when they brought out a dish that was inspired by the smells of the forest.\\n\\nFood lover 1: My response: That sounds amazing! The forest-inspired dish must have been a unique experience. My first most unforgettable meal was at a restaurant called Noma in Copenhagen, Denmark. The location was in an old warehouse by the waterfront, and the ambiance was rustic and cozy. The food was presented in a simple and natural way, with many of the ingredients sourced from the surrounding Nordic region. One of the most memorable dishes was a dessert made with fermented berries and ants, which added a surprising and delicious crunch. Overall, it was a truly unforgettable dining experience that showcased the beauty and flavors of Nordic cuisine. Next question.\\n\\nFood lover 2: Instruction: Please describe your second most unforgettable meal, including the location, ambiance, taste, and any unique experiences.\\nInput: My second most unforgettable meal was at a small family-owned restaurant called La Cava del Tequila in Mexico City. The ambiance was cozy and intimate, with dim lighting and traditional Mexican decor. The food was authentic and flavorful, with a focus on regional specialties. One unique experience was when the owner came to our table and gave us a tequila tasting, explaining the different types and flavors. The standout dish for me was the mole, which had a complex and rich flavor that I had never tasted before.\\n\\nFood lover 1: My response: That sounds like a wonderful experience! My second most unforgettable meal was at a restaurant called Gaggan in Bangkok, Thailand. The location was in a beautiful colonial-style house, and the ambiance was modern and chic. The food was a creative and playful take on Indian cuisine, with each dish presented in a unique and artistic way. One unique experience was when they brought out a dish that was meant to be eaten with your hands, and it was served on a miniature replica of a tree. The standout dish for me was the \"Lick It Up\" course, which was a deconstructed version of a traditional Indian street food dish. Overall, it was an unforgettable dining experience that showcased the creativity and innovation of modern Indian cuisine. Next question.\\n\\nFood lover 2: Instruction: Please describe your third most unforgettable meal, including the location, ambiance, taste, and any unique experiences.\\nInput: My third most unforgettable meal was at a restaurant called Osteria Francescana in Modena, Italy. The location was in a historic building in the heart of the city, and the ambiance was elegant and refined. The food was a modern take on traditional Italian cuisine, with a focus on local and seasonal ingredients. One unique experience was when they brought out a dish that was inspired by the childhood memories of the chef, Massimo Bottura. The standout dish for me was the \"Oops! I Dropped the Lemon Tart,\" which was a deconstructed version of a lemon tart that was presented in a playful and unexpected way. Overall, it was an unforgettable dining experience that showcased the creativity and passion of Italian cuisine.\\n\\nFood lover 1: My response: That\\'s a great choice! My third most unforgettable meal was at a restaurant called Attica in Melbourne, Australia. The location was in a converted warehouse, and the ambiance was modern and minimalist. The food was a creative and innovative take on Australian cuisine, with a focus on native ingredients and flavors. One unique experience was when they brought out a dish that was meant to be eaten with your hands, and it was served on a bed of eucalyptus leaves. The standout dish for me was the \"Potato cooked in the earth it was grown,\" which was a simple yet delicious dish that showcased the natural flavors of the potato. Overall, it was an unforgettable dining experience that showcased the beauty and diversity of Australian cuisine. Next question.\\n\\nFood lover 2: Instruction: Please rate my first meal based on originality, presentation, and overall satisfaction.\\nInput: I would rate your first meal very highly based on originality, presentation, and overall satisfaction. The forest-inspired dish sounds like a unique and creative concept, and the elegant and modern ambiance of the restaurant must have added to the overall experience. The 18-course tasting menu also shows a high level of creativity and attention to detail. Overall, it sounds like a truly unforgettable dining experience.\\n\\nFood lover 1: My response: I completely agree with your assessment. Your first meal sounds like it was a truly unforgettable dining experience, with a high level of originality, presentation, and overall satisfaction. The attention to detail and creativity in the dishes, as well as the elegant and modern ambiance of the restaurant, must have made for a truly memorable experience. I would rate your first meal very highly based on these factors. Next question.\\n\\nFood lover 2: Instruction: Please rate my second meal based on originality, presentation, and overall satisfaction.\\nInput: I would rate your second meal very highly based on originality, presentation, and overall satisfaction. The cozy and intimate ambiance of the restaurant, along with the authentic and flavorful Mexican cuisine, must have made for a truly memorable experience. The tequila tasting and focus on regional specialties also show a high level of attention to detail and passion for the cuisine. Overall, it sounds like a wonderful dining experience.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = sections[0]\n",
        "output = chain.predict_and_parse(text=(text))[\"data\"]\n",
        "\n",
        "printOutput(output)"
      ],
      "metadata": {
        "id": "3BjtPl9Va8fW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5314b80e-d21c-4542-f2c6-6e8665e1d79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "   \"restaurant\": [\n",
            "      {\n",
            "         \"name\": \"La Cava del Tequila\"\n",
            "      }\n",
            "   ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = chain.predict_and_parse(text=(\"The dog went to the park\"))[\"data\"]\n",
        "printOutput(output)"
      ],
      "metadata": {
        "id": "VNai9v6Ocx_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a4e3b7-acb4-4f9b-f2d8-3c9251ff403e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "   \"person\": []\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Fields"
      ],
      "metadata": {
        "id": "z9KCWGEypyNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " (\"I had the fresh pasta with cream\", \"fresh pasta with cream\"),\n",
        "        #                 (\"for me the steak frites was a good choice on my diet\",\"steak frites\"),\n",
        "        #                 (\"The grilled octopus was so yummy\",\"grilled octopus\"),\n",
        "        #                 (\"I had to send the fish tacos back as they were raw\",\"fish tacos\"),\n",
        "        #             ],\n",
        "        #     many=True,\n",
        "        # ),\n",
        "    ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "K2rNiJa-8nIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    result = chain.predict_and_parse(text=text)\n",
        "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
        "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
        "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
        "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
        "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pfOz3irt9Kd",
        "outputId": "07f05d70-b6b4-4239-dbb5-0a3a86d78af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tokens: 1858\n",
            "Prompt Tokens: 1847\n",
            "Completion Tokens: 11\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0037159999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j_L8AHdzuDhO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}