{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Prophet-Andrew-Ng/blob/main/langchain/%E6%9D%8E%E9%B2%81%E9%B2%81%E5%AD%A6LangChain_01_LLMs_%2B_Prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 李鲁鲁学LangChain 01 LLMs + Prompting\n",
        "\n",
        "这是李鲁鲁的学习笔记，原来是Sam Witteveen的笔记\n",
        "\n",
        "增加了李鲁鲁学习时候的吐槽\n",
        "\n",
        "因为一个独立的md文件导入知乎会更方便，所以这个课程的笔记会记录在md中\n",
        "\n",
        "比如这节课在\n",
        "\n",
        "https://github.com/LC1332/Prophet-Andrew-Ng/blob/main/langchain/%E6%9D%8E%E9%B2%81%E9%B2%81%E5%AD%A6LangChain%2001.md\n",
        "\n",
        "欢迎访问[骆驼项目](https://github.com/LC1332/Luotuo-Chinese-LLM)主页和点赞\n"
      ],
      "metadata": {
        "id": "rz-l-ZY7RXaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain: The basics"
      ],
      "metadata": {
        "id": "XoJ-RGiUo-uJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RSTxnoIozRN",
        "outputId": "c40afbb5-f286-4cfd-9bdc-9535ac1766f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m749.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.6/934.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install openai langchain huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-DfFy'\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'hf_'"
      ],
      "metadata": {
        "id": "9iIacDfgpB2M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plain Conditional Generation\n",
        "\n",
        "### First with OpenAI GPT3 "
      ],
      "metadata": {
        "id": "-KB9qA8bpxgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "-lzO5PfUpwfv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='text-davinci-003', \n",
        "             temperature=0.9, \n",
        "             max_tokens = 256)"
      ],
      "metadata": {
        "id": "sTiEn3tKp7mZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Why did the duck cross the road?\"\n",
        "\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCBfxD4cqXsx",
        "outputId": "3c7ad155-0e0e-4a0b-b083-629fef25087a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "To get to the other side.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 试一下turbo\n",
        "我们试一下turbo是不是可以 turbo可以便宜10倍"
      ],
      "metadata": {
        "id": "xrGDJGEkdUBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "k2SoOJd2eDBb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name=\"gpt-3.5-turbo\", \n",
        "             temperature=0.9, \n",
        "             max_tokens = 256)"
      ],
      "metadata": {
        "id": "sJg3uMvyeFco"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Why did the chicken cross the road?\"\n",
        "\n",
        "print(llm_hf(text))"
      ],
      "metadata": {
        "id": "VElT4a0CeGjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now with T5-Flan-XL"
      ],
      "metadata": {
        "id": "lCx_zw5dqxH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub"
      ],
      "metadata": {
        "id": "cZYdStv_rSVU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm_hf = HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-xl\",\n",
        "    model_kwargs={\"temperature\":0.9 }\n",
        ")"
      ],
      "metadata": {
        "id": "swswqGCyqi7A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Why did the chicken cross the road?\"\n",
        "\n",
        "print(llm_hf(text))"
      ],
      "metadata": {
        "id": "NUwUR9U7qkld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hKRIRQwlrgKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Templates"
      ],
      "metadata": {
        "id": "xidOhWp7rk_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "李鲁鲁: 这里sam的restaurant_description拼错了，被GPT老师给纠正了"
      ],
      "metadata": {
        "id": "xljpwBe9cBbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain import PromptTemplate\n",
        "\n",
        "\n",
        "# restaurant_template = \"\"\"\n",
        "# I want you to act as a naming consultant for new restaurants.\n",
        "\n",
        "# Return a list of restaurant names. Each name should be short, catchy and easy to remember. It shoud relate to the type of restaurant you are naming.\n",
        "\n",
        "# What are some good names for a restaurant that is {restaurant_desription}?\n",
        "# \"\"\"\n",
        "\n",
        "# prompt = PromptTemplate(\n",
        "#     input_variables=[\"restaurant_desription\"],\n",
        "#     template=restaurant_template,\n",
        "# )"
      ],
      "metadata": {
        "id": "dWFJY6-Qrm0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "\n",
        "restaurant_template = \"\"\"\n",
        "我希望你能充当一个新餐厅的命名顾问。\n",
        "\n",
        "返回一个餐厅名称列表。每个名称都应该简短，易记，与你正在命名的餐厅类型相关。\n",
        "\n",
        "如果是{restaurant_description}类型的餐厅，有哪些好的命名方式？\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"restaurant_description\"],\n",
        "    template=restaurant_template,\n",
        ")"
      ],
      "metadata": {
        "id": "-0swnC6Abm1k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An example prompt with one input variable\n",
        "prompt_template = PromptTemplate(input_variables=[\"restaurant_description\"], template=restaurant_template)\n"
      ],
      "metadata": {
        "id": "iQ0EEAywYkAb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = \"一个供应新鲜的羊肉肉串和其他希腊食物的希腊餐厅\"\n",
        "description_02 = \"一个以棒球纪念品为主题的汉堡店\"\n",
        "description_03 = \"一个咖啡馆，有现场重金属音乐和纪念品\"\n",
        "\n",
        "## to see what the prompt will be like\n",
        "prompt_template.format(restaurant_description=description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qB3E-mPeYkH-",
        "outputId": "e8a4edf5-125e-4cee-eeae-141e1dfdf266"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n我希望你能充当一个新餐厅的命名顾问。\\n\\n返回一个餐厅名称列表。每个名称都应该简短，易记，与你正在命名的餐厅类型相关。\\n\\n如果是一个供应新鲜的羊肉肉串和其他希腊食物的希腊餐厅类型的餐厅，有哪些好的命名方式？\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## querying the model with the prompt template\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(description_03))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtuuvvmTayhz",
        "outputId": "c77643aa-f8c8-4dec-d479-da973353eacc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. 重金属咖啡：重音咖啡、重金属咖啡馆。 \n",
            "2. 音乐咖啡屋：音乐之路、音乐花园、乐林咖啡。 \n",
            "3. 纪念品咖啡：忆印咖啡、收藏馆咖啡、宝藏咖啡。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## with Few Shot Learning"
      ],
      "metadata": {
        "id": "3aiOsgwJX_Ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, FewShotPromptTemplate\n"
      ],
      "metadata": {
        "id": "a2AncvoJxON6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, create the list of few shot examples.\n",
        "examples = [\n",
        "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
        "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
        "]"
      ],
      "metadata": {
        "id": "2WOFpG-RxOVb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we specify the template to format the examples we have provided.\n",
        "# We use the `PromptTemplate` class for this.\n",
        "example_formatter_template = \"\"\"\n",
        "Word: {word}\n",
        "Antonym: {antonym}\\n\n",
        "\"\"\"\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"word\", \"antonym\"],\n",
        "    template=example_formatter_template,\n",
        ")"
      ],
      "metadata": {
        "id": "qkDsAyF3xS7b"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, we create the `FewShotPromptTemplate` object.\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    # These are the examples we want to insert into the prompt.\n",
        "    examples=examples,\n",
        "    # This is how we want to format the examples when we insert them into the prompt.\n",
        "    example_prompt=example_prompt,\n",
        "    # The prefix is some text that goes before the examples in the prompt.\n",
        "    # Usually, this consists of intructions.\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    # The suffix is some text that goes after the examples in the prompt.\n",
        "    # Usually, this is where the user input will go\n",
        "    suffix=\"Word: {input}\\nAntonym:\",\n",
        "    # The input variables are the variables that the overall prompt expects.\n",
        "    input_variables=[\"input\"],\n",
        "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
        "    example_separator=\"\\n\\n\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "ihj7fUsDxTGb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    # 这是我们要插入到提示中的样例。\n",
        "    examples=examples,\n",
        "    # 这是我们在将样例插入到提示时想要格式化样例的方式。\n",
        "    example_prompt=example_prompt,\n",
        "    # 前缀是在样例之前放置的一些文本。通常，它包含说明信息。\n",
        "    prefix=\"给出每个输入的反义词\",\n",
        "    # 后缀是在样例之后放置的一些文本。通常，用户的输入会被放在这里。\n",
        "    suffix=\"单词：{input}\\n反义词：\",\n",
        "    # input_variables 是整个提示想要的变量。\n",
        "    input_variables=[\"input\"],\n",
        "    # example_separator 是我们将用来连接前缀、样例和后缀的字符串。\n",
        "    example_separator=\"\\n\\n\",\n",
        ")"
      ],
      "metadata": {
        "id": "_t5uXM9skXzc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# We can now generate a prompt using the `format` method.\n",
        "print(few_shot_prompt.format(input=\"big\"))"
      ],
      "metadata": {
        "id": "eJuHdj9wxNFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b62d4c0-b866-463a-9492-fada646330fb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "给出每个输入的反义词\n",
            "\n",
            "\n",
            "Word: happy\n",
            "Antonym: sad\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Word: tall\n",
            "Antonym: short\n",
            "\n",
            "\n",
            "\n",
            "单词：big\n",
            "反义词：\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(\"Big\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDC56SM8FEzu",
        "outputId": "47f59f3e-e4f4-41bb-ce7b-0e6d35415344"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pStpc2HIFY-9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}