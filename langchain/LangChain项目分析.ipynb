{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgj5XzzVPXGh3cRdnXMmTl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Prophet-Andrew-Ng/blob/main/langchain/LangChain%E9%A1%B9%E7%9B%AE%E5%88%86%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip -q install -U github-dependents-info"
      ],
      "metadata": {
        "id": "y_H6Xcbd-jSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://python.langchain.com/docs/ecosystem/dependents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzSQaBTB-beD",
        "outputId": "ffedcac2-692d-43a4-d39b-3be8bb51f750"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-23 08:20:42--  https://python.langchain.com/docs/ecosystem/dependents\n",
            "Resolving python.langchain.com (python.langchain.com)... 76.76.21.98, 76.76.21.22\n",
            "Connecting to python.langchain.com (python.langchain.com)|76.76.21.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84884 (83K) [text/html]\n",
            "Saving to: ‘dependents’\n",
            "\n",
            "\rdependents            0%[                    ]       0  --.-KB/s               \rdependents          100%[===================>]  82.89K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-08-23 08:20:42 (5.94 MB/s) - ‘dependents’ saved [84884/84884]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "对于网页https://python.langchain.com/docs/ecosystem/dependents\n",
        "\n",
        "我想用python下载页面上的内容，并保存到/content/page.html\n",
        "\n",
        "请用python为我实现"
      ],
      "metadata": {
        "id": "zZ7wriNG-_vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://python.langchain.com/docs/ecosystem/dependents'\n",
        "\n",
        "response = requests.get(url)\n",
        "content = response.text\n",
        "\n",
        "with open('/content/page.html', 'w') as f:\n",
        "    f.write(content)"
      ],
      "metadata": {
        "id": "tZdXF_GR-7B-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我要分析一个html文件/content/page.html\n",
        "\n",
        "里面有一个两列的表格，有大量形如\n",
        "\n",
        "```html\n",
        "<tr><td align=\"left\"><a href=\"https://github.com/openai/openai-cookbook\" target=\"_blank\" rel=\"noopener noreferrer\">openai/openai-cookbook</a></td><td align=\"right\">46276</td></tr>\n",
        "<tr><td align=\"left\"><a href=\"https://github.com/AntonOsika/gpt-engineer\" target=\"_blank\" rel=\"noopener noreferrer\">AntonOsika/gpt-engineer</a></td><td align=\"right\">41497</td></tr>\n",
        "```\n",
        "\n",
        "这样的字段，请为我实现一段python程序，\n",
        "\n",
        "提取其中的github链接，将链接和后面的数字保存为两个list\n",
        "\n",
        "如\n",
        "```python\n",
        "github_url = ['https://github.com/openai/openai-cookbook', 'https://github.com/AntonOsika/gpt-engineer']\n",
        "\n",
        "star_nums = [46276,41497]\n",
        "```"
      ],
      "metadata": {
        "id": "bdeH-iN6A7nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "with open('/content/page.html', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "github_urls = []\n",
        "star_nums = []\n",
        "\n",
        "for tr in soup.find_all('tr'):\n",
        "    tds = tr.find_all('td')\n",
        "\n",
        "    if len(tds) == 2:\n",
        "        url = tds[0].find('a')['href']\n",
        "        github_urls.append(url)\n",
        "\n",
        "        num = int(tds[1].text)\n",
        "        star_nums.append(num)\n",
        "\n",
        "print(github_urls)\n",
        "print(star_nums)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFt74mOL_LxV",
        "outputId": "efe3b51a-cf82-4019-d3dc-6656b1ee9655"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://github.com/openai/openai-cookbook', 'https://github.com/AntonOsika/gpt-engineer', 'https://github.com/imartinez/privateGPT', 'https://github.com/LAION-AI/Open-Assistant', 'https://github.com/microsoft/TaskMatrix', 'https://github.com/hpcaitech/ColossalAI', 'https://github.com/streamlit/streamlit', 'https://github.com/reworkd/AgentGPT', 'https://github.com/OpenBB-finance/OpenBBTerminal', 'https://github.com/geekan/MetaGPT', 'https://github.com/jerryjliu/llama_index', 'https://github.com/StanGirard/quivr', 'https://github.com/openai/chatgpt-retrieval-plugin', 'https://github.com/mindsdb/mindsdb', 'https://github.com/cube-js/cube', 'https://github.com/PromtEngineer/localGPT', 'https://github.com/mlflow/mlflow', 'https://github.com/chatchat-space/Langchain-Chatchat', 'https://github.com/GaiZhenbiao/ChuanhuChatGPT', 'https://github.com/logspace-ai/langflow', 'https://github.com/openai/evals', 'https://github.com/airbytehq/airbyte', 'https://github.com/databrickslabs/dolly', 'https://github.com/go-skynet/LocalAI', 'https://github.com/AIGC-Audio/AudioGPT', 'https://github.com/gventuri/pandas-ai', 'https://github.com/hwchase17/langchainjs', 'https://github.com/langgenius/dify', 'https://github.com/PipedreamHQ/pipedream', 'https://github.com/h2oai/h2ogpt', 'https://github.com/arc53/DocsGPT', 'https://github.com/0xpayne/gpt-migrate', 'https://github.com/eosphoros-ai/DB-GPT', 'https://github.com/bentoml/OpenLLM', 'https://github.com/jmorganca/ollama', 'https://github.com/e2b-dev/e2b', 'https://github.com/mage-ai/mage-ai', 'https://github.com/wenda-LLM/wenda', 'https://github.com/zilliztech/GPTCache', 'https://github.com/GreyDGL/PentestGPT', 'https://github.com/zauberzeug/nicegui', 'https://github.com/serge-chat/serge', 'https://github.com/Shaunwei/RealChar', 'https://github.com/gkamradt/langchain-tutorials', 'https://github.com/openchatai/OpenChat', 'https://github.com/intel-analytics/BigDL', 'https://github.com/madawei2699/myGPTReader', 'https://github.com/MineDojo/Voyager', 'https://github.com/embedchain/embedchain', 'https://github.com/postgresml/postgresml', 'https://github.com/assafelovic/gpt-researcher', 'https://github.com/llm-workflow-engine/llm-workflow-engine', 'https://github.com/marqo-ai/marqo', 'https://github.com/kyegomez/tree-of-thoughts', 'https://github.com/RayVentura/ShortGPT', 'https://github.com/Azure-Samples/azure-search-openai-demo', 'https://github.com/langchain-ai/chat-langchain', 'https://github.com/khoj-ai/khoj', 'https://github.com/PrefectHQ/marvin', 'https://github.com/project-baize/baize-chatbot', 'https://github.com/whitead/paper-qa', 'https://github.com/OpenGVLab/InternGPT', 'https://github.com/continuedev/continue', 'https://github.com/ParisNeo/lollms-webui', 'https://github.com/OpenBMB/ToolBench', 'https://github.com/shroominic/codeinterpreter-api', 'https://github.com/OpenBMB/BMTools', 'https://github.com/GerevAI/gerev', 'https://github.com/SamurAIGPT/EmbedAI', 'https://github.com/Unstructured-IO/unstructured', 'https://github.com/Mintplex-Labs/anything-llm', 'https://github.com/emptycrown/llama-hub', 'https://github.com/homanp/superagent', 'https://github.com/yanqiangmiffy/Chinese-LangChain', 'https://github.com/OpenGVLab/Ask-Anything', 'https://github.com/IntelligenzaArtificiale/Free-Auto-GPT', 'https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui', 'https://github.com/NVIDIA/NeMo-Guardrails', 'https://github.com/Farama-Foundation/PettingZoo', 'https://github.com/hwchase17/notion-qa', 'https://github.com/paulpierre/RasaGPT', 'https://github.com/jupyterlab/jupyter-ai', 'https://github.com/vocodedev/vocode-python', 'https://github.com/pinterest/querybook', 'https://github.com/psychic-api/psychic', 'https://github.com/Kav-K/GPTDiscord', 'https://github.com/avinashkranjan/Amazing-Python-Scripts', 'https://github.com/hegelai/prompttools', 'https://github.com/jina-ai/langchain-serve', 'https://github.com/Forethought-Technologies/AutoChain', 'https://github.com/keephq/keep', 'https://github.com/ttengwang/Caption-Anything', 'https://github.com/lunasec-io/lunasec', 'https://github.com/agiresearch/OpenAGI', 'https://github.com/noahshinn024/reflexion', 'https://github.com/jina-ai/dev-gpt', 'https://github.com/jina-ai/thinkgpt', 'https://github.com/greshake/llm-security', 'https://github.com/mmz-001/knowledge_gpt', 'https://github.com/101dotxyz/GPTeam', 'https://github.com/richardyc/Chrome-GPT', 'https://github.com/eyurtsev/kor', 'https://github.com/pluralsh/plural', 'https://github.com/juncongmoo/chatllama', 'https://github.com/visual-openllm/visual-openllm', 'https://github.com/poe-platform/api-bot-tutorial', 'https://github.com/refuel-ai/autolabel', 'https://github.com/microsoft/X-Decoder', 'https://github.com/irgolic/AutoPR', 'https://github.com/SamurAIGPT/Camel-AutoGPT', 'https://github.com/peterw/Chat-with-Github-Repo', 'https://github.com/chatarena/chatarena', 'https://github.com/griptape-ai/griptape', 'https://github.com/psychic-api/rag-stack', 'https://github.com/nod-ai/SHARK', 'https://github.com/filip-michalsky/SalesGPT', 'https://github.com/melih-unsal/DemoGPT', 'https://github.com/rlancemartin/auto-evaluator', 'https://github.com/cirediatpl/FigmaChain', 'https://github.com/seanpixel/Teenage-AGI', 'https://github.com/cheshire-cat-ai/core', 'https://github.com/run-llama/llama-lab', 'https://github.com/corca-ai/EVAL', 'https://github.com/Anil-matcha/ChatPDF', 'https://github.com/alejandro-ao/ask-multiple-pdfs', 'https://github.com/hwchase17/chat-your-data', 'https://github.com/LambdaLabsML/examples', 'https://github.com/ajndkr/lanarky', 'https://github.com/microsoft/Llama-2-Onnx', 'https://github.com/e-johnstonn/BriefGPT', 'https://github.com/billxbf/ReWOO', 'https://github.com/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference', 'https://github.com/databrickslabs/pyspark-ai', 'https://github.com/OpenBMB/AgentVerse', 'https://github.com/kreneskyp/ix', 'https://github.com/akshata29/entaoai', 'https://github.com/promptfoo/promptfoo', 'https://github.com/getmetal/motorhead', 'https://github.com/ruoccofabrizio/azure-open-ai-embeddings-qna', 'https://github.com/YiVal/YiVal', 'https://github.com/whyiyhw/chatgpt-wechat', 'https://github.com/SamurAIGPT/ChatGPT-Developer-Plugins', 'https://github.com/dot-agent/openagent', 'https://github.com/msoedov/langcorn', 'https://github.com/namuan/dr-doc-search', 'https://github.com/microsoft/PodcastCopilot', 'https://github.com/alexanderatallah/window.ai', 'https://github.com/StevenGrove/GPT4Tools', 'https://github.com/xusenlinzy/api-for-open-llm', 'https://github.com/NoDataFound/hackGPT', 'https://github.com/langchain-ai/auto-evaluator', 'https://github.com/yeagerai/yeagerai-agent', 'https://github.com/FlagOpen/FlagEmbedding', 'https://github.com/amosjyng/langchain-visualizer', 'https://github.com/OpenGenerativeAI/GenossGPT', 'https://github.com/jina-ai/agentchain', 'https://github.com/mckaywrigley/repo-chat', 'https://github.com/michaelthwan/searchGPT', 'https://github.com/explosion/spacy-llm', 'https://github.com/plastic-labs/tutor-gpt', 'https://github.com/freddyaboulton/gradio-tools', 'https://github.com/xuwenhao/geektime-ai-course', 'https://github.com/tgscan-dev/tgscan', 'https://github.com/langchain-ai/langchain-aiplugin', 'https://github.com/mpaepper/content-chatbot', 'https://github.com/yvann-hub/Robby-chatbot', 'https://github.com/steamship-core/steamship-langchain', 'https://github.com/langchain-ai/streamlit-agent', 'https://github.com/jonra1993/fastapi-alembic-sqlmodel-async', 'https://github.com/continuum-llms/chatgpt-memory', 'https://github.com/poe-platform/poe-protocol', 'https://github.com/alejandro-ao/langchain-ask-pdf', 'https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service', 'https://github.com/DataDog/dd-trace-py', 'https://github.com/daveebbelaar/langchain-experiments', 'https://github.com/jiran214/GPT-vup', 'https://github.com/Azure-Samples/openai', 'https://github.com/NimbleBoxAI/ChainFury', 'https://github.com/CarperAI/OpenELM', 'https://github.com/daodao97/chatdoc', 'https://github.com/MiuLab/Taiwan-LLaMa', 'https://github.com/logan-markewich/llama_index_starter_pack', 'https://github.com/mtenenholtz/chat-twitter', 'https://github.com/opentensor/bittensor', 'https://github.com/showlab/VLog', 'https://github.com/microsoft/sample-app-aoai-chatGPT', 'https://github.com/truera/trulens', 'https://github.com/Anil-matcha/Chatbase', 'https://github.com/marella/chatdocs', 'https://github.com/jondurbin/airoboros', 'https://github.com/mosaicml/examples', 'https://github.com/wandb/weave', 'https://github.com/huchenxucs/ChatDB', 'https://github.com/rsaryev/talk-codebase', 'https://github.com/steamship-packages/langchain-production-starter', 'https://github.com/jerlendds/osintbuddy', 'https://github.com/andylokandy/gpt-4-search', 'https://github.com/MagnivOrg/prompt-layer-library', 'https://github.com/personoids/personoids-lite', 'https://github.com/momegas/megabots', 'https://github.com/itamargol/openai', 'https://github.com/intel/intel-extension-for-transformers', 'https://github.com/monarch-initiative/ontogpt', 'https://github.com/BlackHC/llm-strategy', 'https://github.com/Nuggt-dev/Nuggt', 'https://github.com/cofactoryai/textbase', 'https://github.com/Cheems-Seminar/grounded-segment-any-parts', 'https://github.com/onlyphantom/llm-python', 'https://github.com/morpheuslord/GPT_Vuln-analyzer', 'https://github.com/sullivan-sean/chat-langchainjs', 'https://github.com/wandb/edu', 'https://github.com/austin2035/chatpdf', 'https://github.com/liangwq/Chatglm_lora_multi-gpu', 'https://github.com/preset-io/promptimize', 'https://github.com/Haste171/langchain-chatbot', 'https://github.com/hnawaz007/pythondataanalysis', 'https://github.com/JohnSnowLabs/langtest', 'https://github.com/conceptofmind/toolformer', 'https://github.com/sugarforever/LangChain-Tutorials', 'https://github.com/Safiullah-Rahu/CSV-AI', 'https://github.com/artitw/text2text', 'https://github.com/bborn/howdoi.ai', 'https://github.com/JayZeeDesign/researcher-gpt', 'https://github.com/paolorechia/learn-langchain', 'https://github.com/ur-whitelab/exmol', 'https://github.com/Azure-Samples/miyagi', 'https://github.com/recalign/RecAlign', 'https://github.com/airobotlab/KoChatGPT', 'https://github.com/explodinggradients/ragas', 'https://github.com/kaleido-lab/dolphin', 'https://github.com/hwchase17/chroma-langchain', 'https://github.com/eosphoros-ai/DB-GPT-Hub', 'https://github.com/shaman-ai/agent-actors', 'https://github.com/gia-guar/JARVIS-ChatGPT', 'https://github.com/shamspias/customizable-gpt-chatbot', 'https://github.com/hwchase17/langchain-streamlit-template', 'https://github.com/alvarosevilla95/autolang', 'https://github.com/radi-cho/datasetGPT', 'https://github.com/gustavz/DataChad', 'https://github.com/pablomarin/GPT-Azure-Search-Engine', 'https://github.com/su77ungr/CASALIOY', 'https://github.com/ennucore/clippinator', 'https://github.com/edreisMD/plugnplai', 'https://github.com/kaarthik108/snowChat', 'https://github.com/PradipNichite/Youtube-Tutorials', 'https://github.com/ur-whitelab/chemcrow-public', 'https://github.com/CambioML/pykoi', 'https://github.com/jbrukh/gpt-jargon', 'https://github.com/LC1332/Chat-Haruhi-Suzumiya', 'https://github.com/nicknochnack/LangchainDocuments', 'https://github.com/yuanjie-ai/ChatLLM', 'https://github.com/plchld/InsightFlow', 'https://github.com/yakami129/VirtualWife', 'https://github.com/Mintplex-Labs/vector-admin', 'https://github.com/SamPink/dev-gpt', 'https://github.com/yasyf/compress-gpt', 'https://github.com/benthecoder/ClassGPT', 'https://github.com/WongSaang/chatgpt-ui-server', 'https://github.com/voxel51/voxelgpt', 'https://github.com/hardbyte/qabot', 'https://github.com/orgexyz/BlockAGI', 'https://github.com/handrew/browserpilot', 'https://github.com/miaoshouai/miaoshouai-assistant', 'https://github.com/microsoft/azure-openai-in-a-day-workshop', 'https://github.com/kyegomez/swarms', 'https://github.com/Azure-Samples/azure-search-power-skills', 'https://github.com/chakkaradeep/pyCodeAGI', 'https://github.com/ethanyanjiali/minChatGPT', 'https://github.com/ccurme/yolopandas', 'https://github.com/ju-bezdek/langchain-decorators', 'https://github.com/Azure-Samples/azure-search-openai-demo-csharp', 'https://github.com/fengyuli-dev/multimedia-gpt', 'https://github.com/grumpyp/aixplora', 'https://github.com/langchain-ai/web-explorer', 'https://github.com/JorisdeJong123/7-Days-of-LangChain', 'https://github.com/shauryr/S2QA', 'https://github.com/Azure-Samples/jp-azureopenai-samples', 'https://github.com/AkshitIreddy/Interactive-LLM-Powered-NPCs', 'https://github.com/ibiscp/LLM-IMDB', 'https://github.com/jmpaz/promptlib', 'https://github.com/mayooear/private-chatbot-mpt30b-langchain', 'https://github.com/homanp/vercel-langchain', 'https://github.com/mlops-for-all/mlops-for-all.github.io', 'https://github.com/vaibkumr/prompt-optimizer', 'https://github.com/Agenta-AI/agenta', 'https://github.com/Klingefjord/chatgpt-telegram', 'https://github.com/menloparklab/falcon-langchain', 'https://github.com/deeppavlov/dream', 'https://github.com/positive666/Prompt-Can-Anything', 'https://github.com/menloparklab/langchain-cohere-qdrant-doc-retrieval', 'https://github.com/realminchoi/babyagi-ui', 'https://github.com/SpecterOps/Nemesis', 'https://github.com/Jaseci-Labs/jaseci', 'https://github.com/summarizepaper/summarizepaper', 'https://github.com/peterw/StoryStorm', 'https://github.com/Aggregate-Intellect/practical-llms', 'https://github.com/streamlit/llm-examples', 'https://github.com/hirokidaichi/wanna', 'https://github.com/Chainlit/cookbook', 'https://github.com/alphasecio/langchain-examples', 'https://github.com/flurb18/AgentOoba', 'https://github.com/Teahouse-Studios/akari-bot', 'https://github.com/yasyf/summ', 'https://github.com/kulltc/chatgpt-sql', 'https://github.com/v7labs/benchllm', 'https://github.com/ray-project/langchain-ray', 'https://github.com/petehunt/langchain-github-bot', 'https://github.com/peterwnjenga/aigent', 'https://github.com/jina-ai/fastapi-serve', 'https://github.com/retr0reg/Ret2GPT', 'https://github.com/agenthubdev/agenthub_operators', 'https://github.com/eunomia-bpf/GPTtrace', 'https://github.com/solana-labs/chatgpt-plugin', 'https://github.com/aurelio-labs/arxiv-bot', 'https://github.com/ChuloAI/BrainChulo', 'https://github.com/ssheng/BentoChain', 'https://github.com/mallahyari/drqa', 'https://github.com/fixie-ai/fixie-examples', 'https://github.com/davila7/file-gpt', 'https://github.com/showlab/UniVTG', 'https://github.com/zenml-io/zenml-projects', 'https://github.com/RedisVentures/redis-openai-qna', 'https://github.com/PJLab-ADG/DriveLikeAHuman', 'https://github.com/prof-frink-lab/slangchain', 'https://github.com/Coding-Crashkurse/Langchain-Full-Course', 'https://github.com/ciare-robotics/world-creator', 'https://github.com/blob42/Instrukt', 'https://github.com/langchain-ai/langsmith-cookbook', 'https://github.com/OpenPluginACI/openplugin', 'https://github.com/defenseunicorns/leapfrogai', 'https://github.com/sdaaron/QueryGPT', 'https://github.com/grumpyp/chroma-langchain-tutorial', 'https://github.com/3Alan/DocsMind', 'https://github.com/CodeAlchemyAI/ViLT-GPT', 'https://github.com/emarco177/ice_breaker', 'https://github.com/nftblackmagic/flask-langchain', 'https://github.com/log1stics/voice-generator-webui', 'https://github.com/nrl-ai/pautobot', 'https://github.com/Azure/business-process-automation', 'https://github.com/MedalCollector/Orator', 'https://github.com/wombyz/HormoziGPT', 'https://github.com/afaqueumer/DocQA', 'https://github.com/mortium91/langchain-assistant', 'https://github.com/Azure/azure-sdk-tools', 'https://github.com/yeagerai/genworlds', 'https://github.com/AmineDiro/cria', 'https://github.com/langchain-ai/text-split-explorer', 'https://github.com/luisroque/large_laguage_models', 'https://github.com/xuwenhao/mactalk-ai-course', 'https://github.com/Open-Swarm-Net/GPT-Swarm', 'https://github.com/langchain-ai/langchain-aws-template', 'https://github.com/aws-samples/aws-genai-llm-chatbot', 'https://github.com/crosleythomas/MirrorGPT', 'https://github.com/Dicklesworthstone/llama2_aided_tesseract']\n",
            "[46276, 41497, 36296, 34861, 33906, 31654, 26571, 25819, 23180, 21968, 20204, 20142, 19215, 17580, 16003, 15134, 15027, 14024, 12020, 11599, 11509, 11493, 10531, 9955, 9081, 8201, 7754, 7348, 6950, 6858, 6300, 6193, 6026, 5641, 5448, 5365, 5352, 5192, 4993, 4831, 4824, 4783, 4779, 4752, 4452, 4286, 4167, 3952, 3887, 3636, 3480, 3445, 3397, 3366, 3335, 3316, 3270, 3266, 3176, 2999, 2932, 2816, 2803, 2679, 2673, 2492, 2486, 2450, 2448, 2255, 2216, 2198, 2177, 2144, 2092, 2060, 2039, 1992, 1949, 1915, 1783, 1761, 1627, 1509, 1499, 1476, 1471, 1392, 1370, 1360, 1357, 1345, 1342, 1332, 1314, 1314, 1313, 1299, 1237, 1232, 1223, 1192, 1126, 1117, 1110, 1096, 1080, 1075, 1068, 984, 957, 955, 944, 942, 909, 899, 896, 889, 868, 854, 847, 836, 818, 798, 782, 748, 741, 732, 722, 710, 710, 707, 704, 704, 692, 682, 670, 662, 650, 632, 624, 617, 602, 588, 585, 581, 569, 568, 559, 558, 554, 537, 534, 534, 524, 496, 495, 494, 492, 490, 488, 481, 480, 480, 473, 471, 467, 463, 463, 463, 441, 437, 432, 431, 431, 428, 419, 414, 411, 404, 402, 399, 394, 393, 392, 391, 390, 363, 360, 357, 353, 352, 350, 343, 335, 335, 329, 325, 319, 317, 312, 310, 310, 308, 305, 304, 296, 288, 285, 280, 277, 275, 273, 272, 271, 268, 268, 263, 260, 259, 257, 256, 252, 251, 251, 248, 243, 242, 232, 232, 230, 229, 227, 224, 223, 222, 221, 221, 219, 217, 217, 211, 210, 210, 206, 202, 199, 198, 196, 196, 196, 196, 194, 191, 190, 190, 190, 182, 181, 176, 174, 173, 172, 170, 169, 169, 169, 167, 166, 165, 164, 164, 162, 158, 158, 158, 157, 156, 156, 156, 155, 152, 151, 151, 150, 149, 148, 146, 145, 145, 145, 144, 144, 142, 141, 140, 140, 140, 139, 139, 139, 138, 138, 137, 135, 134, 134, 133, 133, 132, 131, 131, 130, 130, 128, 128, 127, 127, 127, 125, 125, 124, 122, 122, 121, 120, 120, 119, 118, 118, 117, 117, 116, 114, 113, 113, 112, 110, 110, 109, 108, 106, 106, 105, 105, 104, 104, 104, 104, 104, 104, 103, 103, 101]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我有一个list of string分别是很多github repo的地址\n",
        "\n",
        "github_urls = ['https://github.com/openai/openai-cookbook', 'https://github.com/AntonOsika/gpt-engineer']\n",
        "\n",
        "我有办法实现一段python程序\n",
        "\n",
        "依次提取每个repo的README.md吗？\n",
        "\n",
        "比如第一个repo对应的readme在\n",
        "\n",
        "https://raw.githubusercontent.com/openai/openai-cookbook/main/README.md\n",
        "\n",
        "其实应该可以直接通过wget获取，\n",
        "\n",
        "注意，有时候可能是Readme.md或者readme.md\n",
        "\n",
        "请为我获取所有的readme，重命名成项目的名字保存到/content/output"
      ],
      "metadata": {
        "id": "dHNXMSQ_B1LK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkWhwK4HC8pw",
        "outputId": "02d96344-c245-4329-d1ae-241c2a0864ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output\n",
        "\n",
        "!mkdir output"
      ],
      "metadata": {
        "id": "2qYYW9FAP-Fh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import wget\n",
        "from tqdm import tqdm\n",
        "\n",
        "output_dir = '/content/output'\n",
        "\n",
        "save_names = []\n",
        "\n",
        "count = 0\n",
        "\n",
        "for url in tqdm(github_urls):\n",
        "\n",
        "    count = count + 1\n",
        "\n",
        "    repo_name = re.search(r'github.com/(.+)', url).group(1)\n",
        "\n",
        "    readme_filenames = ['README.md', 'Readme.md', 'readme.md']\n",
        "\n",
        "    downloaded = False\n",
        "\n",
        "    for filename in readme_filenames:\n",
        "\n",
        "        readme_url = f'https://raw.githubusercontent.com/{repo_name}/main/{filename}'\n",
        "\n",
        "        save_name = repo_name.replace('/', '_') + '.md'\n",
        "\n",
        "        outfile = os.path.join(output_dir, save_name)\n",
        "\n",
        "        try:\n",
        "            wget.download(readme_url, out=outfile)\n",
        "            downloaded = True\n",
        "            save_names.append( outfile )\n",
        "            break\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # readme_url = f'https://raw.githubusercontent.com/{repo_name}/main/README.md'\n",
        "\n",
        "    # save_name = repo_name.replace('/', '_')\n",
        "\n",
        "    # print(f'Downloaded {outfile}')\n",
        "\n",
        "    # outfile = os.path.join(output_dir, save_name + '.md')\n",
        "\n",
        "    # wget.download(readme_url, out=outfile)\n",
        "\n"
      ],
      "metadata": {
        "id": "pN-A5eDZBtKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01332e65-4ad3-4361-e818-eeb3b52eeaa6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 354/354 [01:48<00:00,  3.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "现在我们来考虑每个readme调用openAI进行自动总结\n",
        "\n",
        "这里我们要先提取readme里面的前3k个字符"
      ],
      "metadata": {
        "id": "MrmS3HtRExl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(save_names[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im77bkoiFxtG",
        "outputId": "642b88c0-71b0-4dc4-d9fa-bc62b7f4417b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/output/openai_openai-cookbook.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "save_names 是一个python的list of string\n",
        "\n",
        "max_token = 2000\n",
        "\n",
        "里面是很多文件，对于里面每个save_name对应的文件\n",
        "\n",
        "使用utf8编码打开,使用\\n进行split\n",
        "\n",
        "然后初始化一个字符串txt_show为空\n",
        "\n",
        "把文件中的内容逐行添加到txt_show中，直到添加的长度即将超过max_token则停止\n",
        "\n",
        "请用python为我实现"
      ],
      "metadata": {
        "id": "KGRUd2a2FUAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import codecs\n",
        "\n",
        "# max_token = 2000\n",
        "\n",
        "# for star_num, url, save_name in zip(star_nums, github_urls, save_names):\n",
        "\n",
        "#     with codecs.open(save_name, 'r', 'utf-8') as f:\n",
        "#         lines = f.read().split('\\n')\n",
        "\n",
        "#     txt_show = ''\n",
        "\n",
        "#     total_len = 0\n",
        "\n",
        "#     for line in lines:\n",
        "#         if total_len + len(line) < max_token:\n",
        "#             txt_show += line + '\\n'\n",
        "#             total_len += len(line) + 1\n",
        "#         else:\n",
        "#             break\n",
        "\n",
        "#     print(txt_show)\n",
        "\n",
        "#     break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGnVf_jbCSm5",
        "outputId": "e5a349bd-c0d4-4e42-ba3e-0e1f29eba5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# OpenAI Cookbook\n",
            "\n",
            "The OpenAI Cookbook shares example code for accomplishing common tasks with the [OpenAI API].\n",
            "\n",
            "To run these examples, you'll need an OpenAI account and API key ([create a free account][api signup]).\n",
            "\n",
            "Most code examples are written in Python, though the concepts can be applied in any language.\n",
            "\n",
            "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=468576060&machine=basicLinux32gb&location=EastUs)\n",
            "\n",
            "## Recently added/updated 🆕 ✨\n",
            "- [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb) [Aug 22, 2023]\n",
            "- [How to evaluate abstractive summarization](examples/evaluation/How_to_eval_abstractive_summarization.ipynb) [Aug 16, 2023]\n",
            "- [Whisper prompting guide](examples/Whisper_prompting_guide.ipynb) [June 27, 2023]\n",
            "- [Question answering using a search API and re-ranking](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_a_search_API.ipynb) [June 16, 2023]\n",
            "- [How to call functions with Chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb) [June 13, 2023]\n",
            "\n",
            "## Guides & examples\n",
            "\n",
            "- API usage\n",
            "  - [How to handle rate limits](examples/How_to_handle_rate_limits.ipynb)\n",
            "    - [Example parallel processing script that avoids hitting rate limits](examples/api_request_parallel_processor.py)\n",
            "  - [How to count tokens with tiktoken](examples/How_to_count_tokens_with_tiktoken.ipynb)\n",
            "- GPT\n",
            "  - [How to format inputs to ChatGPT models](examples/How_to_format_inputs_to_ChatGPT_models.ipynb)\n",
            "  - [How to stream completions](examples/How_to_stream_completions.ipynb)\n",
            "  - [How to use a multi-step prompt to write unit tests](examples/Unit_test_writing_using_a_multi-step_prompt.ipynb)\n",
            "  - [Guide: How to work with large language models](how_to_work_with_large_language_models.md)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai tiktoken langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehrP_GHiDKMJ",
        "outputId": "12a301c2-ec44-4851-95bb-56be28800112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")"
      ],
      "metadata": {
        "id": "9ROprVllG6Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "\n",
        "max_token = 2000\n",
        "\n",
        "txt_show = ''\n",
        "\n",
        "for star_num, url, save_name in zip(star_nums, github_urls, save_names):\n",
        "\n",
        "    with codecs.open(save_name, 'r', 'utf-8') as f:\n",
        "        lines = f.read().split('\\n')\n",
        "\n",
        "    txt_show = ''\n",
        "\n",
        "    total_len = 0\n",
        "\n",
        "    for line in lines:\n",
        "\n",
        "        current_len = len( enc.encode(line + '\\n') )\n",
        "        if total_len + current_len < max_token:\n",
        "            txt_show += line + '\\n'\n",
        "            total_len += current_len\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print(txt_show)\n",
        "\n",
        "    break\n"
      ],
      "metadata": {
        "id": "7tn6OCzRG9Ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4642f87-c390-4f5e-baa5-a8cffd751ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# OpenAI Cookbook\n",
            "\n",
            "The OpenAI Cookbook shares example code for accomplishing common tasks with the [OpenAI API].\n",
            "\n",
            "To run these examples, you'll need an OpenAI account and API key ([create a free account][api signup]).\n",
            "\n",
            "Most code examples are written in Python, though the concepts can be applied in any language.\n",
            "\n",
            "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=468576060&machine=basicLinux32gb&location=EastUs)\n",
            "\n",
            "## Recently added/updated 🆕 ✨\n",
            "- [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb) [Aug 22, 2023]\n",
            "- [How to evaluate abstractive summarization](examples/evaluation/How_to_eval_abstractive_summarization.ipynb) [Aug 16, 2023]\n",
            "- [Whisper prompting guide](examples/Whisper_prompting_guide.ipynb) [June 27, 2023]\n",
            "- [Question answering using a search API and re-ranking](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_a_search_API.ipynb) [June 16, 2023]\n",
            "- [How to call functions with Chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb) [June 13, 2023]\n",
            "\n",
            "## Guides & examples\n",
            "\n",
            "- API usage\n",
            "  - [How to handle rate limits](examples/How_to_handle_rate_limits.ipynb)\n",
            "    - [Example parallel processing script that avoids hitting rate limits](examples/api_request_parallel_processor.py)\n",
            "  - [How to count tokens with tiktoken](examples/How_to_count_tokens_with_tiktoken.ipynb)\n",
            "- GPT\n",
            "  - [How to format inputs to ChatGPT models](examples/How_to_format_inputs_to_ChatGPT_models.ipynb)\n",
            "  - [How to stream completions](examples/How_to_stream_completions.ipynb)\n",
            "  - [How to use a multi-step prompt to write unit tests](examples/Unit_test_writing_using_a_multi-step_prompt.ipynb)\n",
            "  - [Guide: How to work with large language models](how_to_work_with_large_language_models.md)\n",
            "  - [Guide: Techniques to improve reliability](techniques_to_improve_reliability.md)\n",
            "- Embeddings\n",
            "  - [Text comparison examples](text_comparison_examples.md)\n",
            "  - [How to get embeddings](examples/Get_embeddings.ipynb)\n",
            "  - [Question answering using embeddings](examples/Question_answering_using_embeddings.ipynb)\n",
            "  - [Using vector databases for embeddings search](examples/vector_databases)\n",
            "  - [Semantic search using embeddings](examples/Semantic_text_search_using_embeddings.ipynb)\n",
            "  - [Recommendations using embeddings](examples/Recommendation_using_embeddings.ipynb)\n",
            "  - [Clustering embeddings](examples/Clustering.ipynb)\n",
            "  - [Visualizing embeddings in 2D](examples/Visualizing_embeddings_in_2D.ipynb) or [3D](examples/Visualizing_embeddings_in_3D.ipynb)\n",
            "  - [Embedding long texts](examples/Embedding_long_inputs.ipynb)\n",
            "  - [Embeddings playground (streamlit app)](apps/embeddings-playground/README.md)\n",
            "  - [Search reranking with cross-encoders](examples/Search_reranking_with_cross-encoders.ipynb)\n",
            "- Apps\n",
            "  - [File Q&A](apps/file-q-and-a/)\n",
            "  - [Web Crawl Q&A](apps/web-crawl-q-and-a)\n",
            "  - [Powering your products with ChatGPT and your own data](apps/chatbot-kickstarter/powering_your_products_with_chatgpt_and_your_data.ipynb)\n",
            "- Fine-tuning GPT-3\n",
            "  - [Guide: best practices for fine-tuning GPT-3 to classify text](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit)\n",
            "  - [Fine-tuned classification](examples/Fine-tuned_classification.ipynb)\n",
            "- DALL-E\n",
            "  - [How to generate and edit images with DALL·E](examples/dalle/Image_generations_edits_and_variations_with_DALL-E.ipynb)\n",
            "  - [How to create dynamic masks with DALL·E and Segment Anything](examples/dalle/How_to_create_dynamic_masks_with_DALL-E_and_Segment_Anything.ipynb)\n",
            "- Whisper\n",
            "  - [Whisper prompting guide](examples/Whisper_prompting_guide.ipynb)\n",
            "- Azure OpenAI (alternative API from Microsoft Azure)\n",
            "  - [How to use ChatGPT with Azure OpenAI](examples/azure/chat.ipynb)\n",
            "  - [How to get completions from Azure OpenAI](examples/azure/completions.ipynb)\n",
            "  - [How to get embeddings from Azure OpenAI](examples/azure/embeddings.ipynb)\n",
            "  - [How to generate images with DALL·E fom Azure OpenAI](examples/azure/DALL-E.ipynb)\n",
            "\n",
            "## Related OpenAI resources\n",
            "\n",
            "Beyond the code examples here, you can learn about the [OpenAI API] from the following resources:\n",
            "\n",
            "- Experiment with [ChatGPT]\n",
            "- Try the API in the [OpenAI Playground]\n",
            "- Read about the API in the [OpenAI Documentation]\n",
            "- Get help in the [OpenAI Help Center]\n",
            "- Discuss the API in the [OpenAI Community Forum] or [OpenAI Discord channel]\n",
            "- See example prompts in the [OpenAI Examples]\n",
            "- Stay updated with the [OpenAI Blog]\n",
            "\n",
            "## Related resources from around the web\n",
            "\n",
            "People are writing great tools and papers for improving outputs from GPT. Here are some cool ones we've seen:\n",
            "\n",
            "### Prompting libraries & tools\n",
            "\n",
            "- [Guidance](https://github.com/microsoft/guidance): A handy looking Python library from Microsoft that uses Handlebars templating to interleave generation, prompting, and logical control.\n",
            "- [LangChain](https://github.com/hwchase17/langchain): A popular Python/JavaScript library for chaining sequences of language model prompts.\n",
            "- [FLAML (A Fast Library for Automated Machine Learning & Tuning)](https://microsoft.github.io/FLAML/docs/Getting-Started/): A Python library for automating selection of models, hyperparameters, and other tunable choices.\n",
            "- [Chainlit](https://docs.chainlit.io/overview): A Python library for making chatbot interfaces.\n",
            "- [Guardrails.ai](https://shreyar.github.io/guardrails/): A Python library for validating outputs and retrying failures. Still in alpha, so expect sharp edges and bugs.\n",
            "- [Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel/): A Python/C# library from Microsoft that supports prompt templating, function chaining, vectorized memory, and intelligent planning.\n",
            "- [Prompttools](https://github.com/hegelai/prompttools): Open-source Python tools for testing and evaluating models, vector DBs, and prompts.\n",
            "- [Outlines](https://github.com/normal-computing/outlines): A Python library that provides a domain-specific language to simplify prompting and constrain generation.\n",
            "- [Promptify](https://github.com/promptslab/Promptify): A small Python library for using language models to perform NLP tasks.\n",
            "- [Scale Spellbook](https://scale.com/spellbook): A paid product for building, comparing, and shipping language model apps.\n",
            "- [PromptPerfect](https://promptperfect.jina.ai/prompts): A paid product for testing and improving prompts.\n",
            "- [Weights & Biases](https://wandb.ai/site/solutions/llmops): A paid product for tracking model training and prompt engineering experiments.\n",
            "- [OpenAI Evals](https://github.com/openai/evals): An open-source library for evaluating task performance of language models and prompts.\n",
            "- [LlamaIndex](https://github.com/jerryjliu/llama_index): A Python library for augmenting LLM apps with data.\n",
            "- [Arthur Shield](https://www.arthur.ai/get-started): A paid product for detecting toxicity, hallucination, prompt injection, etc.\n",
            "- [LMQL](https://lmql.ai): A programming language for LLM interaction with support for typed prompting, control flow, constraints, and tools.\n",
            "\n",
            "### Prompting guides\n",
            "\n",
            "- [Brex's Prompt Engineering Guide](https://github.com/brexhq/prompt-engineering): Brex's introduction to language models and prompt engineering.\n",
            "- [promptingguide.ai](https://www.promptingguide.ai/): A prompt engineering guide that demonstrates many techniques.\n",
            "- [OpenAI Cookbook: Techniques to improve reliability](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md): A slightly dated (Sep 2022) review of techniques for prompting language models.\n",
            "- [Lil'Log Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/): An OpenAI researcher's review of the prompt engineering literature (as of March 2023).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XJ_OP5QP0c0",
        "outputId": "d7bd5fea-5290-43e5-c2f3-6c78affa42e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['random_string']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(star_nums)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kYC_l6FPYmJ",
        "outputId": "80dd2b15-216f-4d88-a262-e03771580582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46276, 41497, 36296, 34861, 33906, 31654, 26571, 25819, 23180, 21968, 20204, 20142, 19215, 17580, 16003, 15134, 15027, 14024, 12020, 11599, 11509, 11493, 10531, 9955, 9081, 8201, 7754, 7348, 6950, 6858, 6300, 6193, 6026, 5641, 5448, 5365, 5352, 5192, 4993, 4831, 4824, 4783, 4779, 4752, 4452, 4286, 4167, 3952, 3887, 3636, 3480, 3445, 3397, 3366, 3335, 3316, 3270, 3266, 3176, 2999, 2932, 2816, 2803, 2679, 2673, 2492, 2486, 2450, 2448, 2255, 2216, 2198, 2177, 2144, 2092, 2060, 2039, 1992, 1949, 1915, 1783, 1761, 1627, 1509, 1499, 1476, 1471, 1392, 1370, 1360, 1357, 1345, 1342, 1332, 1314, 1314, 1313, 1299, 1237, 1232, 1223, 1192, 1126, 1117, 1110, 1096, 1080, 1075, 1068, 984, 957, 955, 944, 942, 909, 899, 896, 889, 868, 854, 847, 836, 818, 798, 782, 748, 741, 732, 722, 710, 710, 707, 704, 704, 692, 682, 670, 662, 650, 632, 624, 617, 602, 588, 585, 581, 569, 568, 559, 558, 554, 537, 534, 534, 524, 496, 495, 494, 492, 490, 488, 481, 480, 480, 473, 471, 467, 463, 463, 463, 441, 437, 432, 431, 431, 428, 419, 414, 411, 404, 402, 399, 394, 393, 392, 391, 390, 363, 360, 357, 353, 352, 350, 343, 335, 335, 329, 325, 319, 317, 312, 310, 310, 308, 305, 304, 296, 288, 285, 280, 277, 275, 273, 272, 271, 268, 268, 263, 260, 259, 257, 256, 252, 251, 251, 248, 243, 242, 232, 232, 230, 229, 227, 224, 223, 222, 221, 221, 219, 217, 217, 211, 210, 210, 206, 202, 199, 198, 196, 196, 196, 196, 194, 191, 190, 190, 190, 182, 181, 176, 174, 173, 172, 170, 169, 169, 169, 167, 166, 165, 164, 164, 162, 158, 158, 158, 157, 156, 156, 156, 155, 152, 151, 151, 150, 149, 148, 146, 145, 145, 145, 144, 144, 142, 141, 140, 140, 140, 139, 139, 139, 138, 138, 137, 135, 134, 134, 133, 133, 132, 131, 131, 130, 130, 128, 128, 127, 127, 127, 125, 125, 124, 122, 122, 121, 120, 120, 119, 118, 118, 117, 117, 116, 114, 113, 113, 112, 110, 110, 109, 108, 106, 106, 105, 105, 104, 104, 104, 104, 104, 104, 103, 103, 101]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "好了，接下来就是加一个总结"
      ],
      "metadata": {
        "id": "uJgSYDLFHNoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = '​​sk-VvF4zQ' # 在这里输入你的OpenAI API Token\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ],
      "metadata": {
        "id": "iPucHCr9HM-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_system_prompt = \"\"\"You are ChatGPT, a large language model trained by OpenAI.\n",
        "Knowledge cutoff: 2021-09\n",
        "Current date: 2023-03-15\"\"\""
      ],
      "metadata": {
        "id": "PqIt7H9pHJU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "QF8O2-PaHdmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "YsNe6snjHhJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prefix_prompt = \"\"\"\n",
        "# 根据这个popular的github的repo，为我总结这个github repo的功能和创新点:\n",
        "# \"\"\"\n",
        "\n",
        "# content_prompt = prefix_prompt + '```\\n' + txt_show + '\\n```'\n",
        "\n",
        "# smart_system_prompt_utf8 = smart_system_prompt.encode('utf-8')\n",
        "# content_utf8 = content_prompt.encode('utf-8')\n",
        "\n",
        "\n",
        "# messages = [\n",
        "#     SystemMessage(content=smart_system_prompt_utf8),\n",
        "#     HumanMessage(content=content_utf8),\n",
        "# ]\n",
        "\n",
        "# response = chat(messages)\n",
        "\n",
        "# print(response)"
      ],
      "metadata": {
        "id": "rG0rRaIdHj01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_summary( txt_show ):\n",
        "    prefix_prompt = \"根据这个popular的github的repo，为我总结这个github repo的功能和创新点:\\n\"\n",
        "\n",
        "    content_prompt = prefix_prompt + '```\\n' + txt_show + '\\n```'\n",
        "\n",
        "    smart_system_prompt_utf8 = smart_system_prompt.encode('utf-8')\n",
        "    content_utf8 = content_prompt.encode('utf-8')\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=smart_system_prompt_utf8),\n",
        "        HumanMessage(content=content_utf8),\n",
        "    ]\n",
        "\n",
        "    response = chat(messages)\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "PWRWNbJxND0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(save_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0J80IP9IBY0",
        "outputId": "674791a9-889a-4752-ee2a-edcdf9c8f545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/summary"
      ],
      "metadata": {
        "id": "HvZzpYpGN-f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.basename(save_names[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOoZ_hF3QbK-",
        "outputId": "1c70e847-18f5-4a09-e108-26ca9273c660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openai_openai-cookbook.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "save_path = '/content/summary'\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.mkdir(save_path)\n",
        "\n",
        "max_token = 2000\n",
        "\n",
        "for star_num, url, save_name in zip(star_nums, github_urls, save_names):\n",
        "\n",
        "    if not os.path.exists(save_name):\n",
        "        print('warning unfound, ', save_name)\n",
        "        continue\n",
        "\n",
        "    # 读取文件\n",
        "    try:\n",
        "        with codecs.open(save_name, 'r', 'utf-8') as f:\n",
        "            lines = f.read().split('\\n')\n",
        "    except:\n",
        "        print('warning encode error on ', save_name)\n",
        "        continue\n",
        "\n",
        "    txt_show = ''\n",
        "\n",
        "    total_len = 0\n",
        "\n",
        "    for line in lines:\n",
        "\n",
        "        current_len = len(enc.encode(line + '\\n'))\n",
        "        if total_len + current_len < max_token:\n",
        "            txt_show += line + '\\n'\n",
        "            total_len += current_len\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    summary = get_summary(txt_show)\n",
        "    # summary = 'random_string'\n",
        "\n",
        "    base_name = os.path.basename(save_name)\n",
        "    sum_file = os.path.join(save_path, base_name)\n",
        "    # 保存summary到指定路径\n",
        "    with open(sum_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    # print('save ', sum_file)\n",
        "    # break\n",
        "\n",
        "# 将summary目录打包成zip文件\n",
        "zip_file = zipfile.ZipFile('/content/zip_all.zip', 'w')\n",
        "for folder, subfolders, files in os.walk(save_path):\n",
        "    for file in files:\n",
        "        zip_file.write(os.path.join(folder, file),\n",
        "                       os.path.relpath(os.path.join(folder,file), save_path),\n",
        "                       compress_type = zipfile.ZIP_DEFLATED)\n",
        "zip_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJmZMjDDIj4y",
        "outputId": "f4958f25-c2a4-44e4-be5e-37533c90b8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warning encode error on  /content/output/microsoft_azure-openai-in-a-day-workshop.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "修改这段代码，在头部增加一个save_path = '/content/summary' 的文件夹\n",
        "\n",
        "我希望把summary以utf8编码形式 写入到这个文件夹中，文件名使用与save_name一致的文件名\n",
        "\n",
        "并最终把/content/summary文件夹中的所有文件打包到/content/zip_all.zip"
      ],
      "metadata": {
        "id": "PAUxfP8fNdy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_names = ['tangshiye','murongfu','liyunlong',\n",
        "                'Luna','wangduoyu','Ron','jiumozhi',\n",
        "                'Snape','haruhi','Malfoy','xuzhu',\n",
        "                'xiaofeng','duanyu','Hermione','Dumbledore',\n",
        "                'wangyuyan',\n",
        "                'Harry','McGonagall' ,\n",
        "                'baizhantang','tongxiangyu','guofurong',\n",
        "                'wanderer','zhongli','hutao',\n",
        "                'Sheldon','Raj','Penny',\n",
        "                'weixiaobao','qiaofeng','ayaka',\n",
        "                'raidenShogun','yuqian']\n",
        "\n",
        "character_names = ['汤师爷','慕容复','李云龙',\n",
        "              'Luna','王多鱼','Ron','鸠摩智',\n",
        "              'Snape','春日','Malfoy','虚竹',\n",
        "              '萧峰','段誉','Hermione','Dumbledore',\n",
        "              '王语嫣',\n",
        "              'Harry','McGonagall',\n",
        "              '白展堂','佟湘玉','郭芙蓉',\n",
        "              '旅行者','钟离','胡桃',\n",
        "              'Sheldon','Raj','Penny',\n",
        "              '韦小宝','乔峰','神里绫华',\n",
        "              '雷电将军','于谦']\n",
        "name_dic = {}\n",
        "for cn_role_name, en_role_name in zip(character_names, folder_names):\n",
        "    name_dic.update({cn_role_name: en_role_name})\n",
        "\n",
        "print(len(folder_names))\n",
        "\n",
        "name_dic.update({\"八重神子\": \"yaemiko\"})\n",
        "\n",
        "name_dic.update({\"赫敏\": \"Hermione\"})\n",
        "name_dic.update({\"罗恩\": \"Ron\"})\n",
        "name_dic.update({\"哈利\": \"Harry\"})\n",
        "name_dic.update({\"流浪者\": \"wanderer\"})\n",
        "name_dic.update({\"邓布利多\": \"Dumbledore\"})\n",
        "\n",
        "name_dic.update({\"凉宫春日\": \"haruhi\"})\n",
        "name_dic.update({\"涼宮ハルヒ\": \"haruhi\"})\n",
        "name_dic.update({\"涼宮\": \"haruhi\"})\n",
        "\n",
        "\n",
        "name_dic.update({\"展堂\": \"baizhantang\"})\n",
        "name_dic.update({\"Professor McGonagall\": \"McGonagall\"})\n",
        "\n",
        "for folder_name in folder_names:\n",
        "    tmp_list = []\n",
        "    print(folder_name)\n",
        "    for key in name_dic.keys():\n",
        "        if name_dic[key] == folder_name:\n",
        "            # print(name_dic[key] , key )\n",
        "            tmp_list.append(key)\n",
        "    print(tmp_list)"
      ],
      "metadata": {
        "id": "WFVogqxoJH59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f59fe7-8fe6-49c8-f58f-951204e32a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "tangshiye\n",
            "['汤师爷']\n",
            "murongfu\n",
            "['慕容复']\n",
            "liyunlong\n",
            "['李云龙']\n",
            "Luna\n",
            "['Luna']\n",
            "wangduoyu\n",
            "['王多鱼']\n",
            "Ron\n",
            "['Ron', '罗恩']\n",
            "jiumozhi\n",
            "['鸠摩智']\n",
            "Snape\n",
            "['Snape']\n",
            "haruhi\n",
            "['春日', '凉宫春日', '涼宮ハルヒ', '涼宮']\n",
            "Malfoy\n",
            "['Malfoy']\n",
            "xuzhu\n",
            "['虚竹']\n",
            "xiaofeng\n",
            "['萧峰']\n",
            "duanyu\n",
            "['段誉']\n",
            "Hermione\n",
            "['Hermione', '赫敏']\n",
            "Dumbledore\n",
            "['Dumbledore', '邓布利多']\n",
            "wangyuyan\n",
            "['王语嫣']\n",
            "Harry\n",
            "['Harry', '哈利']\n",
            "McGonagall\n",
            "['McGonagall', 'Professor McGonagall']\n",
            "baizhantang\n",
            "['白展堂', '展堂']\n",
            "tongxiangyu\n",
            "['佟湘玉']\n",
            "guofurong\n",
            "['郭芙蓉']\n",
            "wanderer\n",
            "['旅行者', '流浪者']\n",
            "zhongli\n",
            "['钟离']\n",
            "hutao\n",
            "['胡桃']\n",
            "Sheldon\n",
            "['Sheldon']\n",
            "Raj\n",
            "['Raj']\n",
            "Penny\n",
            "['Penny']\n",
            "weixiaobao\n",
            "['韦小宝']\n",
            "qiaofeng\n",
            "['乔峰']\n",
            "ayaka\n",
            "['神里绫华']\n",
            "raidenShogun\n",
            "['雷电将军']\n",
            "yuqian\n",
            "['于谦']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7Dd5CqFWN8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvlc9MdrWfCk",
        "outputId": "5aef7a09-c03c-4ba4-eed9-75832ea2cde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tangshiye\n",
            "['汤师爷']\n",
            "murongfu\n",
            "['慕容复']\n",
            "liyunlong\n",
            "['李云龙']\n",
            "Luna\n",
            "['Luna']\n",
            "wangduoyu\n",
            "['王多鱼']\n",
            "Ron\n",
            "['Ron', '罗恩']\n",
            "jiumozhi\n",
            "['鸠摩智']\n",
            "Snape\n",
            "['Snape']\n",
            "haruhi\n",
            "['春日']\n",
            "Malfoy\n",
            "['Malfoy']\n",
            "xuzhu\n",
            "['虚竹']\n",
            "xiaofeng\n",
            "['萧峰']\n",
            "duanyu\n",
            "['段誉']\n",
            "Hermione\n",
            "['Hermione', '赫敏']\n",
            "Dumbledore\n",
            "['Dumbledore', '邓布利多']\n",
            "wangyuyan\n",
            "['王语嫣']\n",
            "Harry\n",
            "['Harry', '哈利']\n",
            "McGonagall\n",
            "['McGonagall', 'Professor McGonagall']\n",
            "baizhantang\n",
            "['白展堂', '展堂']\n",
            "tongxiangyu\n",
            "['佟湘玉']\n",
            "guofurong\n",
            "['郭芙蓉']\n",
            "wanderer\n",
            "['旅行者', '流浪者']\n",
            "zhongli\n",
            "['钟离']\n",
            "hutao\n",
            "['胡桃']\n",
            "Sheldon\n",
            "['Sheldon']\n",
            "Raj\n",
            "['Raj']\n",
            "Penny\n",
            "['Penny']\n",
            "weixiaobao\n",
            "['韦小宝']\n",
            "qiaofeng\n",
            "['乔峰']\n",
            "ayaka\n",
            "['神里绫华']\n",
            "raidenShogun\n",
            "['雷电将军']\n",
            "yuqian\n",
            "['于谦']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(star_nums))\n",
        "print(len(github_urls))\n",
        "print(len(save_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCNcWeV9fT85",
        "outputId": "d2b39fa6-b754-4296-f335-ccaef3d4effb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354\n",
            "354\n",
            "297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/zip_all.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WmTa_OCfic8",
        "outputId": "282832db-3b12-49f2-96aa-cdb3405ddc46"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/zip_all.zip\n",
            "  inflating: itamargol_openai.md     \n",
            "  inflating: bentoml_OpenLLM.md      \n",
            "  inflating: xuwenhao_mactalk-ai-course.md  \n",
            "  inflating: conceptofmind_toolformer.md  \n",
            "  inflating: MedalCollector_Orator.md  \n",
            "  inflating: irgolic_AutoPR.md       \n",
            "  inflating: jondurbin_airoboros.md  \n",
            "  inflating: andylokandy_gpt-4-search.md  \n",
            "  inflating: alexanderatallah_window.ai.md  \n",
            "  inflating: nod-ai_SHARK.md         \n",
            "  inflating: MiuLab_Taiwan-LLaMa.md  \n",
            "  inflating: jina-ai_dev-gpt.md      \n",
            "  inflating: intel_intel-extension-for-transformers.md  \n",
            "  inflating: 3Alan_DocsMind.md       \n",
            "  inflating: openai_openai-cookbook.md  \n",
            "  inflating: daveebbelaar_langchain-experiments.md  \n",
            "  inflating: juncongmoo_chatllama.md  \n",
            "  inflating: kaarthik108_snowChat.md  \n",
            "  inflating: jbrukh_gpt-jargon.md    \n",
            "  inflating: hnawaz007_pythondataanalysis.md  \n",
            "  inflating: CambioML_pykoi.md       \n",
            "  inflating: amosjyng_langchain-visualizer.md  \n",
            "  inflating: Jaseci-Labs_jaseci.md   \n",
            "  inflating: peterwnjenga_aigent.md  \n",
            "  inflating: explodinggradients_ragas.md  \n",
            "  inflating: ibiscp_LLM-IMDB.md      \n",
            "  inflating: mmz-001_knowledge_gpt.md  \n",
            "  inflating: AIGC-Audio_AudioGPT.md  \n",
            "  inflating: StanGirard_quivr.md     \n",
            "  inflating: streamlit_llm-examples.md  \n",
            "  inflating: davila7_file-gpt.md     \n",
            "  inflating: ju-bezdek_langchain-decorators.md  \n",
            "  inflating: run-llama_llama-lab.md  \n",
            "  inflating: mpaepper_content-chatbot.md  \n",
            "  inflating: SpecterOps_Nemesis.md   \n",
            "  inflating: chatarena_chatarena.md  \n",
            "  inflating: logan-markewich_llama_index_starter_pack.md  \n",
            "  inflating: hardbyte_qabot.md       \n",
            "  inflating: petehunt_langchain-github-bot.md  \n",
            "  inflating: Cheems-Seminar_grounded-segment-any-parts.md  \n",
            "  inflating: steamship-core_steamship-langchain.md  \n",
            "  inflating: truera_trulens.md       \n",
            "  inflating: wenda-LLM_wenda.md      \n",
            "  inflating: corca-ai_EVAL.md        \n",
            "  inflating: ccurme_yolopandas.md    \n",
            "  inflating: positive666_Prompt-Can-Anything.md  \n",
            "  inflating: seanpixel_Teenage-AGI.md  \n",
            "  inflating: rsaryev_talk-codebase.md  \n",
            "  inflating: wombyz_HormoziGPT.md    \n",
            "  inflating: kaleido-lab_dolphin.md  \n",
            "  inflating: monarch-initiative_ontogpt.md  \n",
            "  inflating: ChuloAI_BrainChulo.md   \n",
            "  inflating: Azure-Samples_miyagi.md  \n",
            "  inflating: peterw_StoryStorm.md    \n",
            "  inflating: promptfoo_promptfoo.md  \n",
            "  inflating: freddyaboulton_gradio-tools.md  \n",
            "  inflating: billxbf_ReWOO.md        \n",
            "  inflating: zilliztech_GPTCache.md  \n",
            "  inflating: alphasecio_langchain-examples.md  \n",
            "  inflating: Anil-matcha_Chatbase.md  \n",
            "  inflating: Forethought-Technologies_AutoChain.md  \n",
            "  inflating: GerevAI_gerev.md        \n",
            "  inflating: OpenBMB_AgentVerse.md   \n",
            "  inflating: shamspias_customizable-gpt-chatbot.md  \n",
            "  inflating: imartinez_privateGPT.md  \n",
            "  inflating: LAION-AI_Open-Assistant.md  \n",
            "  inflating: langchain-ai_text-split-explorer.md  \n",
            "  inflating: OpenBMB_BMTools.md      \n",
            "  inflating: mckaywrigley_repo-chat.md  \n",
            "  inflating: eosphoros-ai_DB-GPT.md  \n",
            "  inflating: Nuggt-dev_Nuggt.md      \n",
            "  inflating: langchain-ai_langsmith-cookbook.md  \n",
            "  inflating: Coding-Crashkurse_Langchain-Full-Course.md  \n",
            "  inflating: logspace-ai_langflow.md  \n",
            "  inflating: griptape-ai_griptape.md  \n",
            "  inflating: microsoft_Llama-2-Onnx.md  \n",
            "  inflating: marqo-ai_marqo.md       \n",
            "  inflating: microsoft_X-Decoder.md  \n",
            "  inflating: cirediatpl_FigmaChain.md  \n",
            "  inflating: personoids_personoids-lite.md  \n",
            "  inflating: dot-agent_openagent.md  \n",
            "  inflating: getmetal_motorhead.md   \n",
            "  inflating: morpheuslord_GPT_Vuln-analyzer.md  \n",
            "  inflating: onlyphantom_llm-python.md  \n",
            "  inflating: eyurtsev_kor.md         \n",
            "  inflating: liangwq_Chatglm_lora_multi-gpu.md  \n",
            "  inflating: deeppavlov_dream.md     \n",
            "  inflating: noahshinn024_reflexion.md  \n",
            "  inflating: Azure-Samples_azure-search-power-skills.md  \n",
            "  inflating: NVIDIA_NeMo-Guardrails.md  \n",
            "  inflating: keephq_keep.md          \n",
            "  inflating: aurelio-labs_arxiv-bot.md  \n",
            "  inflating: jina-ai_thinkgpt.md     \n",
            "  inflating: mosaicml_examples.md    \n",
            "  inflating: MineDojo_Voyager.md     \n",
            "  inflating: handrew_browserpilot.md  \n",
            "  inflating: SamurAIGPT_ChatGPT-Developer-Plugins.md  \n",
            "  inflating: zenml-io_zenml-projects.md  \n",
            "  inflating: msoedov_langcorn.md     \n",
            "  inflating: visual-openllm_visual-openllm.md  \n",
            "  inflating: sullivan-sean_chat-langchainjs.md  \n",
            "  inflating: GreyDGL_PentestGPT.md   \n",
            "  inflating: whyiyhw_chatgpt-wechat.md  \n",
            "  inflating: yasyf_summ.md           \n",
            "  inflating: embedchain_embedchain.md  \n",
            "  inflating: PrefectHQ_marvin.md     \n",
            "  inflating: Aggregate-Intellect_practical-llms.md  \n",
            "  inflating: mayooear_private-chatbot-mpt30b-langchain.md  \n",
            "  inflating: GaiZhenbiao_ChuanhuChatGPT.md  \n",
            "  inflating: marella_chatdocs.md     \n",
            "  inflating: xuwenhao_geektime-ai-course.md  \n",
            "  inflating: emarco177_ice_breaker.md  \n",
            "  inflating: microsoft_TaskMatrix.md  \n",
            "  inflating: vocodedev_vocode-python.md  \n",
            "  inflating: Safiullah-Rahu_CSV-AI.md  \n",
            "  inflating: refuel-ai_autolabel.md  \n",
            "  inflating: llm-workflow-engine_llm-workflow-engine.md  \n",
            "  inflating: plastic-labs_tutor-gpt.md  \n",
            "  inflating: Klingefjord_chatgpt-telegram.md  \n",
            "  inflating: AkshitIreddy_Interactive-LLM-Powered-NPCs.md  \n",
            "  inflating: huchenxucs_ChatDB.md    \n",
            "  inflating: OpenGVLab_Ask-Anything.md  \n",
            "  inflating: akshata29_entaoai.md    \n",
            "  inflating: menloparklab_langchain-cohere-qdrant-doc-retrieval.md  \n",
            "  inflating: plchld_InsightFlow.md   \n",
            "  inflating: OpenGenerativeAI_GenossGPT.md  \n",
            "  inflating: richardyc_Chrome-GPT.md  \n",
            "  inflating: SamurAIGPT_Camel-AutoGPT.md  \n",
            "  inflating: poe-platform_poe-protocol.md  \n",
            "  inflating: psychic-api_psychic.md  \n",
            "  inflating: jmpaz_promptlib.md      \n",
            "  inflating: yeagerai_yeagerai-agent.md  \n",
            "  inflating: langchain-ai_web-explorer.md  \n",
            "  inflating: langgenius_dify.md      \n",
            "  inflating: BlackHC_llm-strategy.md  \n",
            "  inflating: JohnSnowLabs_langtest.md  \n",
            "  inflating: kennethleungty_Llama-2-Open-Source-LLM-CPU-Inference.md  \n",
            "  inflating: grumpyp_aixplora.md     \n",
            "  inflating: yakami129_VirtualWife.md  \n",
            "  inflating: hwchase17_langchainjs.md  \n",
            "  inflating: log1stics_voice-generator-webui.md  \n",
            "  inflating: microsoft_PodcastCopilot.md  \n",
            "  inflating: edreisMD_plugnplai.md   \n",
            "  inflating: Azure-Samples_azure-search-openai-demo-csharp.md  \n",
            "  inflating: mtenenholtz_chat-twitter.md  \n",
            "  inflating: gventuri_pandas-ai.md   \n",
            "  inflating: kyegomez_tree-of-thoughts.md  \n",
            "  inflating: Azure-Samples_openai.md  \n",
            "  inflating: jerryjliu_llama_index.md  \n",
            "  inflating: openai_chatgpt-retrieval-plugin.md  \n",
            "  inflating: mage-ai_mage-ai.md      \n",
            "  inflating: avinashkranjan_Amazing-Python-Scripts.md  \n",
            "  inflating: shaman-ai_agent-actors.md  \n",
            "  inflating: showlab_UniVTG.md       \n",
            "  inflating: su77ungr_CASALIOY.md    \n",
            "  inflating: arc53_DocsGPT.md        \n",
            "  inflating: austin2035_chatpdf.md   \n",
            "  inflating: Azure-Samples_jp-azureopenai-samples.md  \n",
            "  inflating: zauberzeug_nicegui.md   \n",
            "  inflating: LambdaLabsML_examples.md  \n",
            "  inflating: ParisNeo_lollms-webui.md  \n",
            "  inflating: e2b-dev_e2b.md          \n",
            "  inflating: airobotlab_KoChatGPT.md  \n",
            "  inflating: Unstructured-IO_unstructured.md  \n",
            "  inflating: SamurAIGPT_EmbedAI.md   \n",
            "  inflating: poe-platform_api-bot-tutorial.md  \n",
            "  inflating: RedisVentures_redis-openai-qna.md  \n",
            "  inflating: paolorechia_learn-langchain.md  \n",
            "  inflating: langchain-ai_langchain-aws-template.md  \n",
            "  inflating: openchatai_OpenChat.md  \n",
            "  inflating: openai_evals.md         \n",
            "  inflating: prof-frink-lab_slangchain.md  \n",
            "  inflating: homanp_superagent.md    \n",
            "  inflating: paulpierre_RasaGPT.md   \n",
            "  inflating: NoDataFound_hackGPT.md  \n",
            "  inflating: wandb_edu.md            \n",
            "  inflating: JorisdeJong123_7-Days-of-LangChain.md  \n",
            "  inflating: yeagerai_genworlds.md   \n",
            "  inflating: greshake_llm-security.md  \n",
            "  inflating: fixie-ai_fixie-examples.md  \n",
            "  inflating: benthecoder_ClassGPT.md  \n",
            "  inflating: IntelligenzaArtificiale_Free-Auto-GPT.md  \n",
            "  inflating: cheshire-cat-ai_core.md  \n",
            "  inflating: mortium91_langchain-assistant.md  \n",
            "  inflating: steamship-packages_langchain-production-starter.md  \n",
            "  inflating: nrl-ai_pautobot.md      \n",
            "  inflating: nicknochnack_LangchainDocuments.md  \n",
            "  inflating: alejandro-ao_ask-multiple-pdfs.md  \n",
            "  inflating: Dicklesworthstone_llama2_aided_tesseract.md  \n",
            "  inflating: project-baize_baize-chatbot.md  \n",
            "  inflating: LC1332_Chat-Haruhi-Suzumiya.md  \n",
            "  inflating: luisroque_large_laguage_models.md  \n",
            "  inflating: rlancemartin_auto-evaluator.md  \n",
            "  inflating: eosphoros-ai_DB-GPT-Hub.md  \n",
            "  inflating: eunomia-bpf_GPTtrace.md  \n",
            "  inflating: preset-io_promptimize.md  \n",
            "  inflating: gia-guar_JARVIS-ChatGPT.md  \n",
            "  inflating: hegelai_prompttools.md  \n",
            "  inflating: continuum-llms_chatgpt-memory.md  \n",
            "  inflating: afaqueumer_DocQA.md     \n",
            "  inflating: sdaaron_QueryGPT.md     \n",
            "  inflating: mlops-for-all_mlops-for-all.github.io.md  \n",
            "  inflating: hirokidaichi_wanna.md   \n",
            "  inflating: Kav-K_GPTDiscord.md     \n",
            "  inflating: langchain-ai_auto-evaluator.md  \n",
            "  inflating: yasyf_compress-gpt.md   \n",
            "  inflating: 0xpayne_gpt-migrate.md  \n",
            "  inflating: madawei2699_myGPTReader.md  \n",
            "  inflating: Dicklesworthstone_llama_embeddings_fastapi_service.md  \n",
            "  inflating: miaoshouai_miaoshouai-assistant.md  \n",
            "  inflating: recalign_RecAlign.md    \n",
            "  inflating: yvann-hub_Robby-chatbot.md  \n",
            "  inflating: kyegomez_swarms.md      \n",
            "  inflating: cofactoryai_textbase.md  \n",
            "  inflating: ciare-robotics_world-creator.md  \n",
            "  inflating: agiresearch_OpenAGI.md  \n",
            "  inflating: PromtEngineer_localGPT.md  \n",
            "  inflating: voxel51_voxelgpt.md     \n",
            "  inflating: Azure_business-process-automation.md  \n",
            "  inflating: ttengwang_Caption-Anything.md  \n",
            "  inflating: gkamradt_langchain-tutorials.md  \n",
            "  inflating: AmineDiro_cria.md       \n",
            "  inflating: wandb_weave.md          \n",
            "  inflating: alejandro-ao_langchain-ask-pdf.md  \n",
            "  inflating: emptycrown_llama-hub.md  \n",
            "  inflating: ur-whitelab_exmol.md    \n",
            "  inflating: Azure-Samples_azure-search-openai-demo.md  \n",
            "  inflating: pablomarin_GPT-Azure-Search-Engine.md  \n",
            "  inflating: v7labs_benchllm.md      \n",
            "  inflating: Anil-matcha_ChatPDF.md  \n",
            "  inflating: ruoccofabrizio_azure-open-ai-embeddings-qna.md  \n",
            "  inflating: Haste171_langchain-chatbot.md  \n",
            "  inflating: OpenGVLab_InternGPT.md  \n",
            "  inflating: jonra1993_fastapi-alembic-sqlmodel-async.md  \n",
            "  inflating: continuedev_continue.md  \n",
            "  inflating: jupyterlab_jupyter-ai.md  \n",
            "  inflating: Azure_azure-sdk-tools.md  \n",
            "  inflating: intel-analytics_BigDL.md  \n",
            "  inflating: showlab_VLog.md         \n",
            "  inflating: fengyuli-dev_multimedia-gpt.md  \n",
            "  inflating: menloparklab_falcon-langchain.md  \n",
            "  inflating: nftblackmagic_flask-langchain.md  \n",
            "  inflating: CodeAlchemyAI_ViLT-GPT.md  \n",
            "  inflating: ur-whitelab_chemcrow-public.md  \n",
            "  inflating: momegas_megabots.md     \n",
            "  inflating: mallahyari_drqa.md      \n",
            "  inflating: Chainlit_cookbook.md    \n",
            "  inflating: aws-samples_aws-genai-llm-chatbot.md  \n",
            "  inflating: radi-cho_datasetGPT.md  \n",
            "  inflating: melih-unsal_DemoGPT.md  \n",
            "  inflating: ethanyanjiali_minChatGPT.md  \n",
            "  inflating: Shaunwei_RealChar.md    \n",
            "  inflating: gustavz_DataChad.md     \n",
            "  inflating: bborn_howdoi.ai.md      \n",
            "  inflating: chakkaradeep_pyCodeAGI.md  \n",
            "  inflating: jina-ai_fastapi-serve.md  \n",
            "  inflating: jmorganca_ollama.md     \n",
            "  inflating: geekan_MetaGPT.md       \n",
            "  inflating: jerlendds_osintbuddy.md  \n",
            "  inflating: grumpyp_chroma-langchain-tutorial.md  \n",
            "  inflating: serge-chat_serge.md     \n",
            "  inflating: flurb18_AgentOoba.md    \n",
            "  inflating: Agenta-AI_agenta.md     \n",
            "  inflating: langchain-ai_langchain-aiplugin.md  \n",
            "  inflating: reworkd_AgentGPT.md     \n",
            "  inflating: defenseunicorns_leapfrogai.md  \n",
            "  inflating: langchain-ai_streamlit-agent.md  \n",
            "  inflating: sugarforever_LangChain-Tutorials.md  \n",
            "  inflating: retr0reg_Ret2GPT.md     \n",
            "  inflating: AntonOsika_gpt-engineer.md  \n",
            "  inflating: jina-ai_agentchain.md   \n",
            "  inflating: crosleythomas_MirrorGPT.md  \n",
            "  inflating: whitead_paper-qa.md     \n",
            "  inflating: NimbleBoxAI_ChainFury.md  \n",
            "  inflating: homanp_vercel-langchain.md  \n",
            "  inflating: PJLab-ADG_DriveLikeAHuman.md  \n",
            "  inflating: OpenBB-finance_OpenBBTerminal.md  \n",
            "  inflating: h2oai_h2ogpt.md         \n",
            "  inflating: psychic-api_rag-stack.md  \n",
            "  inflating: jina-ai_langchain-serve.md  \n",
            "  inflating: OpenPluginACI_openplugin.md  \n",
            "  inflating: 101dotxyz_GPTeam.md     \n",
            "  inflating: tgscan-dev_tgscan.md    \n",
            "  inflating: shroominic_codeinterpreter-api.md  \n",
            "  inflating: peterw_Chat-with-Github-Repo.md  \n",
            "  inflating: realminchoi_babyagi-ui.md  \n",
            "  inflating: CarperAI_OpenELM.md     \n",
            "  inflating: ajndkr_lanarky.md       \n",
            "  inflating: WongSaang_chatgpt-ui-server.md  \n",
            "  inflating: filip-michalsky_SalesGPT.md  \n",
            "  inflating: explosion_spacy-llm.md  \n",
            "  inflating: hpcaitech_ColossalAI.md  \n",
            "  inflating: microsoft_sample-app-aoai-chatGPT.md  \n",
            "  inflating: ssheng_BentoChain.md    \n",
            "  inflating: ray-project_langchain-ray.md  \n",
            "  inflating: namuan_dr-doc-search.md  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import wget\n",
        "from tqdm import tqdm\n",
        "\n",
        "output_dir = '/content/output'\n",
        "\n",
        "save_names = []\n",
        "\n",
        "count = 0\n",
        "\n",
        "url2summary = {}\n",
        "\n",
        "for i in range(len(github_urls)):\n",
        "\n",
        "    url = github_urls[i]\n",
        "\n",
        "    count = count + 1\n",
        "\n",
        "    repo_name = re.search(r'github.com/(.+)', url).group(1)\n",
        "\n",
        "    readme_filenames = ['README.md', 'Readme.md', 'readme.md']\n",
        "\n",
        "    # downloaded = False\n",
        "\n",
        "    for filename in readme_filenames:\n",
        "\n",
        "        readme_url = f'https://raw.githubusercontent.com/{repo_name}/main/{filename}'\n",
        "\n",
        "        save_name = repo_name.replace('/', '_') + '.md'\n",
        "\n",
        "        possible_summary = f'/content/{save_name}'\n",
        "\n",
        "        if os.path.exists(os.path.join(output_dir, possible_summary)):\n",
        "            url2summary[url] = possible_summary\n",
        "            # downloaded = True\n",
        "            break\n",
        "\n",
        "    # readme_url = f'https://raw.githubusercontent.com/{repo_name}/main/README.md'\n",
        "\n",
        "    # save_name = repo_name.replace('/', '_')\n",
        "\n",
        "    # print(f'Downloaded {outfile}')\n",
        "\n",
        "    # outfile = os.path.join(output_dir, save_name + '.md')\n",
        "\n",
        "    # wget.download(readme_url, out=outfile)\n",
        "\n",
        "print(url2summary)\n",
        "\n"
      ],
      "metadata": {
        "id": "K2-H188SWobD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d72edf3-22bc-45a6-99d2-e6c2b465778f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'https://github.com/openai/openai-cookbook': '/content/openai_openai-cookbook.md', 'https://github.com/AntonOsika/gpt-engineer': '/content/AntonOsika_gpt-engineer.md', 'https://github.com/imartinez/privateGPT': '/content/imartinez_privateGPT.md', 'https://github.com/LAION-AI/Open-Assistant': '/content/LAION-AI_Open-Assistant.md', 'https://github.com/microsoft/TaskMatrix': '/content/microsoft_TaskMatrix.md', 'https://github.com/hpcaitech/ColossalAI': '/content/hpcaitech_ColossalAI.md', 'https://github.com/reworkd/AgentGPT': '/content/reworkd_AgentGPT.md', 'https://github.com/OpenBB-finance/OpenBBTerminal': '/content/OpenBB-finance_OpenBBTerminal.md', 'https://github.com/geekan/MetaGPT': '/content/geekan_MetaGPT.md', 'https://github.com/jerryjliu/llama_index': '/content/jerryjliu_llama_index.md', 'https://github.com/StanGirard/quivr': '/content/StanGirard_quivr.md', 'https://github.com/openai/chatgpt-retrieval-plugin': '/content/openai_chatgpt-retrieval-plugin.md', 'https://github.com/PromtEngineer/localGPT': '/content/PromtEngineer_localGPT.md', 'https://github.com/GaiZhenbiao/ChuanhuChatGPT': '/content/GaiZhenbiao_ChuanhuChatGPT.md', 'https://github.com/logspace-ai/langflow': '/content/logspace-ai_langflow.md', 'https://github.com/openai/evals': '/content/openai_evals.md', 'https://github.com/AIGC-Audio/AudioGPT': '/content/AIGC-Audio_AudioGPT.md', 'https://github.com/gventuri/pandas-ai': '/content/gventuri_pandas-ai.md', 'https://github.com/hwchase17/langchainjs': '/content/hwchase17_langchainjs.md', 'https://github.com/langgenius/dify': '/content/langgenius_dify.md', 'https://github.com/h2oai/h2ogpt': '/content/h2oai_h2ogpt.md', 'https://github.com/arc53/DocsGPT': '/content/arc53_DocsGPT.md', 'https://github.com/0xpayne/gpt-migrate': '/content/0xpayne_gpt-migrate.md', 'https://github.com/eosphoros-ai/DB-GPT': '/content/eosphoros-ai_DB-GPT.md', 'https://github.com/bentoml/OpenLLM': '/content/bentoml_OpenLLM.md', 'https://github.com/jmorganca/ollama': '/content/jmorganca_ollama.md', 'https://github.com/e2b-dev/e2b': '/content/e2b-dev_e2b.md', 'https://github.com/mage-ai/mage-ai': '/content/mage-ai_mage-ai.md', 'https://github.com/wenda-LLM/wenda': '/content/wenda-LLM_wenda.md', 'https://github.com/zilliztech/GPTCache': '/content/zilliztech_GPTCache.md', 'https://github.com/GreyDGL/PentestGPT': '/content/GreyDGL_PentestGPT.md', 'https://github.com/zauberzeug/nicegui': '/content/zauberzeug_nicegui.md', 'https://github.com/serge-chat/serge': '/content/serge-chat_serge.md', 'https://github.com/Shaunwei/RealChar': '/content/Shaunwei_RealChar.md', 'https://github.com/gkamradt/langchain-tutorials': '/content/gkamradt_langchain-tutorials.md', 'https://github.com/openchatai/OpenChat': '/content/openchatai_OpenChat.md', 'https://github.com/intel-analytics/BigDL': '/content/intel-analytics_BigDL.md', 'https://github.com/madawei2699/myGPTReader': '/content/madawei2699_myGPTReader.md', 'https://github.com/MineDojo/Voyager': '/content/MineDojo_Voyager.md', 'https://github.com/embedchain/embedchain': '/content/embedchain_embedchain.md', 'https://github.com/llm-workflow-engine/llm-workflow-engine': '/content/llm-workflow-engine_llm-workflow-engine.md', 'https://github.com/marqo-ai/marqo': '/content/marqo-ai_marqo.md', 'https://github.com/kyegomez/tree-of-thoughts': '/content/kyegomez_tree-of-thoughts.md', 'https://github.com/Azure-Samples/azure-search-openai-demo': '/content/Azure-Samples_azure-search-openai-demo.md', 'https://github.com/PrefectHQ/marvin': '/content/PrefectHQ_marvin.md', 'https://github.com/project-baize/baize-chatbot': '/content/project-baize_baize-chatbot.md', 'https://github.com/whitead/paper-qa': '/content/whitead_paper-qa.md', 'https://github.com/OpenGVLab/InternGPT': '/content/OpenGVLab_InternGPT.md', 'https://github.com/continuedev/continue': '/content/continuedev_continue.md', 'https://github.com/ParisNeo/lollms-webui': '/content/ParisNeo_lollms-webui.md', 'https://github.com/shroominic/codeinterpreter-api': '/content/shroominic_codeinterpreter-api.md', 'https://github.com/OpenBMB/BMTools': '/content/OpenBMB_BMTools.md', 'https://github.com/GerevAI/gerev': '/content/GerevAI_gerev.md', 'https://github.com/SamurAIGPT/EmbedAI': '/content/SamurAIGPT_EmbedAI.md', 'https://github.com/Unstructured-IO/unstructured': '/content/Unstructured-IO_unstructured.md', 'https://github.com/emptycrown/llama-hub': '/content/emptycrown_llama-hub.md', 'https://github.com/homanp/superagent': '/content/homanp_superagent.md', 'https://github.com/OpenGVLab/Ask-Anything': '/content/OpenGVLab_Ask-Anything.md', 'https://github.com/IntelligenzaArtificiale/Free-Auto-GPT': '/content/IntelligenzaArtificiale_Free-Auto-GPT.md', 'https://github.com/NVIDIA/NeMo-Guardrails': '/content/NVIDIA_NeMo-Guardrails.md', 'https://github.com/paulpierre/RasaGPT': '/content/paulpierre_RasaGPT.md', 'https://github.com/jupyterlab/jupyter-ai': '/content/jupyterlab_jupyter-ai.md', 'https://github.com/vocodedev/vocode-python': '/content/vocodedev_vocode-python.md', 'https://github.com/psychic-api/psychic': '/content/psychic-api_psychic.md', 'https://github.com/Kav-K/GPTDiscord': '/content/Kav-K_GPTDiscord.md', 'https://github.com/avinashkranjan/Amazing-Python-Scripts': '/content/avinashkranjan_Amazing-Python-Scripts.md', 'https://github.com/hegelai/prompttools': '/content/hegelai_prompttools.md', 'https://github.com/jina-ai/langchain-serve': '/content/jina-ai_langchain-serve.md', 'https://github.com/Forethought-Technologies/AutoChain': '/content/Forethought-Technologies_AutoChain.md', 'https://github.com/keephq/keep': '/content/keephq_keep.md', 'https://github.com/ttengwang/Caption-Anything': '/content/ttengwang_Caption-Anything.md', 'https://github.com/agiresearch/OpenAGI': '/content/agiresearch_OpenAGI.md', 'https://github.com/noahshinn024/reflexion': '/content/noahshinn024_reflexion.md', 'https://github.com/jina-ai/dev-gpt': '/content/jina-ai_dev-gpt.md', 'https://github.com/jina-ai/thinkgpt': '/content/jina-ai_thinkgpt.md', 'https://github.com/greshake/llm-security': '/content/greshake_llm-security.md', 'https://github.com/mmz-001/knowledge_gpt': '/content/mmz-001_knowledge_gpt.md', 'https://github.com/101dotxyz/GPTeam': '/content/101dotxyz_GPTeam.md', 'https://github.com/richardyc/Chrome-GPT': '/content/richardyc_Chrome-GPT.md', 'https://github.com/eyurtsev/kor': '/content/eyurtsev_kor.md', 'https://github.com/juncongmoo/chatllama': '/content/juncongmoo_chatllama.md', 'https://github.com/visual-openllm/visual-openllm': '/content/visual-openllm_visual-openllm.md', 'https://github.com/poe-platform/api-bot-tutorial': '/content/poe-platform_api-bot-tutorial.md', 'https://github.com/refuel-ai/autolabel': '/content/refuel-ai_autolabel.md', 'https://github.com/microsoft/X-Decoder': '/content/microsoft_X-Decoder.md', 'https://github.com/irgolic/AutoPR': '/content/irgolic_AutoPR.md', 'https://github.com/SamurAIGPT/Camel-AutoGPT': '/content/SamurAIGPT_Camel-AutoGPT.md', 'https://github.com/peterw/Chat-with-Github-Repo': '/content/peterw_Chat-with-Github-Repo.md', 'https://github.com/chatarena/chatarena': '/content/chatarena_chatarena.md', 'https://github.com/griptape-ai/griptape': '/content/griptape-ai_griptape.md', 'https://github.com/psychic-api/rag-stack': '/content/psychic-api_rag-stack.md', 'https://github.com/nod-ai/SHARK': '/content/nod-ai_SHARK.md', 'https://github.com/filip-michalsky/SalesGPT': '/content/filip-michalsky_SalesGPT.md', 'https://github.com/melih-unsal/DemoGPT': '/content/melih-unsal_DemoGPT.md', 'https://github.com/rlancemartin/auto-evaluator': '/content/rlancemartin_auto-evaluator.md', 'https://github.com/cirediatpl/FigmaChain': '/content/cirediatpl_FigmaChain.md', 'https://github.com/seanpixel/Teenage-AGI': '/content/seanpixel_Teenage-AGI.md', 'https://github.com/cheshire-cat-ai/core': '/content/cheshire-cat-ai_core.md', 'https://github.com/run-llama/llama-lab': '/content/run-llama_llama-lab.md', 'https://github.com/corca-ai/EVAL': '/content/corca-ai_EVAL.md', 'https://github.com/Anil-matcha/ChatPDF': '/content/Anil-matcha_ChatPDF.md', 'https://github.com/alejandro-ao/ask-multiple-pdfs': '/content/alejandro-ao_ask-multiple-pdfs.md', 'https://github.com/LambdaLabsML/examples': '/content/LambdaLabsML_examples.md', 'https://github.com/ajndkr/lanarky': '/content/ajndkr_lanarky.md', 'https://github.com/microsoft/Llama-2-Onnx': '/content/microsoft_Llama-2-Onnx.md', 'https://github.com/billxbf/ReWOO': '/content/billxbf_ReWOO.md', 'https://github.com/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference': '/content/kennethleungty_Llama-2-Open-Source-LLM-CPU-Inference.md', 'https://github.com/OpenBMB/AgentVerse': '/content/OpenBMB_AgentVerse.md', 'https://github.com/akshata29/entaoai': '/content/akshata29_entaoai.md', 'https://github.com/promptfoo/promptfoo': '/content/promptfoo_promptfoo.md', 'https://github.com/getmetal/motorhead': '/content/getmetal_motorhead.md', 'https://github.com/ruoccofabrizio/azure-open-ai-embeddings-qna': '/content/ruoccofabrizio_azure-open-ai-embeddings-qna.md', 'https://github.com/whyiyhw/chatgpt-wechat': '/content/whyiyhw_chatgpt-wechat.md', 'https://github.com/SamurAIGPT/ChatGPT-Developer-Plugins': '/content/SamurAIGPT_ChatGPT-Developer-Plugins.md', 'https://github.com/dot-agent/openagent': '/content/dot-agent_openagent.md', 'https://github.com/msoedov/langcorn': '/content/msoedov_langcorn.md', 'https://github.com/namuan/dr-doc-search': '/content/namuan_dr-doc-search.md', 'https://github.com/microsoft/PodcastCopilot': '/content/microsoft_PodcastCopilot.md', 'https://github.com/alexanderatallah/window.ai': '/content/alexanderatallah_window.ai.md', 'https://github.com/NoDataFound/hackGPT': '/content/NoDataFound_hackGPT.md', 'https://github.com/langchain-ai/auto-evaluator': '/content/langchain-ai_auto-evaluator.md', 'https://github.com/yeagerai/yeagerai-agent': '/content/yeagerai_yeagerai-agent.md', 'https://github.com/amosjyng/langchain-visualizer': '/content/amosjyng_langchain-visualizer.md', 'https://github.com/OpenGenerativeAI/GenossGPT': '/content/OpenGenerativeAI_GenossGPT.md', 'https://github.com/jina-ai/agentchain': '/content/jina-ai_agentchain.md', 'https://github.com/mckaywrigley/repo-chat': '/content/mckaywrigley_repo-chat.md', 'https://github.com/explosion/spacy-llm': '/content/explosion_spacy-llm.md', 'https://github.com/plastic-labs/tutor-gpt': '/content/plastic-labs_tutor-gpt.md', 'https://github.com/freddyaboulton/gradio-tools': '/content/freddyaboulton_gradio-tools.md', 'https://github.com/xuwenhao/geektime-ai-course': '/content/xuwenhao_geektime-ai-course.md', 'https://github.com/tgscan-dev/tgscan': '/content/tgscan-dev_tgscan.md', 'https://github.com/langchain-ai/langchain-aiplugin': '/content/langchain-ai_langchain-aiplugin.md', 'https://github.com/mpaepper/content-chatbot': '/content/mpaepper_content-chatbot.md', 'https://github.com/yvann-hub/Robby-chatbot': '/content/yvann-hub_Robby-chatbot.md', 'https://github.com/steamship-core/steamship-langchain': '/content/steamship-core_steamship-langchain.md', 'https://github.com/langchain-ai/streamlit-agent': '/content/langchain-ai_streamlit-agent.md', 'https://github.com/jonra1993/fastapi-alembic-sqlmodel-async': '/content/jonra1993_fastapi-alembic-sqlmodel-async.md', 'https://github.com/continuum-llms/chatgpt-memory': '/content/continuum-llms_chatgpt-memory.md', 'https://github.com/poe-platform/poe-protocol': '/content/poe-platform_poe-protocol.md', 'https://github.com/alejandro-ao/langchain-ask-pdf': '/content/alejandro-ao_langchain-ask-pdf.md', 'https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service': '/content/Dicklesworthstone_llama_embeddings_fastapi_service.md', 'https://github.com/daveebbelaar/langchain-experiments': '/content/daveebbelaar_langchain-experiments.md', 'https://github.com/Azure-Samples/openai': '/content/Azure-Samples_openai.md', 'https://github.com/NimbleBoxAI/ChainFury': '/content/NimbleBoxAI_ChainFury.md', 'https://github.com/CarperAI/OpenELM': '/content/CarperAI_OpenELM.md', 'https://github.com/MiuLab/Taiwan-LLaMa': '/content/MiuLab_Taiwan-LLaMa.md', 'https://github.com/logan-markewich/llama_index_starter_pack': '/content/logan-markewich_llama_index_starter_pack.md', 'https://github.com/mtenenholtz/chat-twitter': '/content/mtenenholtz_chat-twitter.md', 'https://github.com/showlab/VLog': '/content/showlab_VLog.md', 'https://github.com/microsoft/sample-app-aoai-chatGPT': '/content/microsoft_sample-app-aoai-chatGPT.md', 'https://github.com/truera/trulens': '/content/truera_trulens.md', 'https://github.com/Anil-matcha/Chatbase': '/content/Anil-matcha_Chatbase.md', 'https://github.com/marella/chatdocs': '/content/marella_chatdocs.md', 'https://github.com/jondurbin/airoboros': '/content/jondurbin_airoboros.md', 'https://github.com/mosaicml/examples': '/content/mosaicml_examples.md', 'https://github.com/wandb/weave': '/content/wandb_weave.md', 'https://github.com/huchenxucs/ChatDB': '/content/huchenxucs_ChatDB.md', 'https://github.com/rsaryev/talk-codebase': '/content/rsaryev_talk-codebase.md', 'https://github.com/steamship-packages/langchain-production-starter': '/content/steamship-packages_langchain-production-starter.md', 'https://github.com/jerlendds/osintbuddy': '/content/jerlendds_osintbuddy.md', 'https://github.com/andylokandy/gpt-4-search': '/content/andylokandy_gpt-4-search.md', 'https://github.com/personoids/personoids-lite': '/content/personoids_personoids-lite.md', 'https://github.com/momegas/megabots': '/content/momegas_megabots.md', 'https://github.com/itamargol/openai': '/content/itamargol_openai.md', 'https://github.com/intel/intel-extension-for-transformers': '/content/intel_intel-extension-for-transformers.md', 'https://github.com/monarch-initiative/ontogpt': '/content/monarch-initiative_ontogpt.md', 'https://github.com/BlackHC/llm-strategy': '/content/BlackHC_llm-strategy.md', 'https://github.com/Nuggt-dev/Nuggt': '/content/Nuggt-dev_Nuggt.md', 'https://github.com/cofactoryai/textbase': '/content/cofactoryai_textbase.md', 'https://github.com/Cheems-Seminar/grounded-segment-any-parts': '/content/Cheems-Seminar_grounded-segment-any-parts.md', 'https://github.com/onlyphantom/llm-python': '/content/onlyphantom_llm-python.md', 'https://github.com/morpheuslord/GPT_Vuln-analyzer': '/content/morpheuslord_GPT_Vuln-analyzer.md', 'https://github.com/sullivan-sean/chat-langchainjs': '/content/sullivan-sean_chat-langchainjs.md', 'https://github.com/wandb/edu': '/content/wandb_edu.md', 'https://github.com/austin2035/chatpdf': '/content/austin2035_chatpdf.md', 'https://github.com/liangwq/Chatglm_lora_multi-gpu': '/content/liangwq_Chatglm_lora_multi-gpu.md', 'https://github.com/preset-io/promptimize': '/content/preset-io_promptimize.md', 'https://github.com/Haste171/langchain-chatbot': '/content/Haste171_langchain-chatbot.md', 'https://github.com/hnawaz007/pythondataanalysis': '/content/hnawaz007_pythondataanalysis.md', 'https://github.com/JohnSnowLabs/langtest': '/content/JohnSnowLabs_langtest.md', 'https://github.com/conceptofmind/toolformer': '/content/conceptofmind_toolformer.md', 'https://github.com/sugarforever/LangChain-Tutorials': '/content/sugarforever_LangChain-Tutorials.md', 'https://github.com/Safiullah-Rahu/CSV-AI': '/content/Safiullah-Rahu_CSV-AI.md', 'https://github.com/bborn/howdoi.ai': '/content/bborn_howdoi.ai.md', 'https://github.com/paolorechia/learn-langchain': '/content/paolorechia_learn-langchain.md', 'https://github.com/ur-whitelab/exmol': '/content/ur-whitelab_exmol.md', 'https://github.com/Azure-Samples/miyagi': '/content/Azure-Samples_miyagi.md', 'https://github.com/recalign/RecAlign': '/content/recalign_RecAlign.md', 'https://github.com/airobotlab/KoChatGPT': '/content/airobotlab_KoChatGPT.md', 'https://github.com/explodinggradients/ragas': '/content/explodinggradients_ragas.md', 'https://github.com/kaleido-lab/dolphin': '/content/kaleido-lab_dolphin.md', 'https://github.com/eosphoros-ai/DB-GPT-Hub': '/content/eosphoros-ai_DB-GPT-Hub.md', 'https://github.com/shaman-ai/agent-actors': '/content/shaman-ai_agent-actors.md', 'https://github.com/gia-guar/JARVIS-ChatGPT': '/content/gia-guar_JARVIS-ChatGPT.md', 'https://github.com/shamspias/customizable-gpt-chatbot': '/content/shamspias_customizable-gpt-chatbot.md', 'https://github.com/radi-cho/datasetGPT': '/content/radi-cho_datasetGPT.md', 'https://github.com/gustavz/DataChad': '/content/gustavz_DataChad.md', 'https://github.com/pablomarin/GPT-Azure-Search-Engine': '/content/pablomarin_GPT-Azure-Search-Engine.md', 'https://github.com/su77ungr/CASALIOY': '/content/su77ungr_CASALIOY.md', 'https://github.com/edreisMD/plugnplai': '/content/edreisMD_plugnplai.md', 'https://github.com/kaarthik108/snowChat': '/content/kaarthik108_snowChat.md', 'https://github.com/ur-whitelab/chemcrow-public': '/content/ur-whitelab_chemcrow-public.md', 'https://github.com/CambioML/pykoi': '/content/CambioML_pykoi.md', 'https://github.com/jbrukh/gpt-jargon': '/content/jbrukh_gpt-jargon.md', 'https://github.com/LC1332/Chat-Haruhi-Suzumiya': '/content/LC1332_Chat-Haruhi-Suzumiya.md', 'https://github.com/nicknochnack/LangchainDocuments': '/content/nicknochnack_LangchainDocuments.md', 'https://github.com/plchld/InsightFlow': '/content/plchld_InsightFlow.md', 'https://github.com/yakami129/VirtualWife': '/content/yakami129_VirtualWife.md', 'https://github.com/yasyf/compress-gpt': '/content/yasyf_compress-gpt.md', 'https://github.com/benthecoder/ClassGPT': '/content/benthecoder_ClassGPT.md', 'https://github.com/WongSaang/chatgpt-ui-server': '/content/WongSaang_chatgpt-ui-server.md', 'https://github.com/voxel51/voxelgpt': '/content/voxel51_voxelgpt.md', 'https://github.com/hardbyte/qabot': '/content/hardbyte_qabot.md', 'https://github.com/handrew/browserpilot': '/content/handrew_browserpilot.md', 'https://github.com/miaoshouai/miaoshouai-assistant': '/content/miaoshouai_miaoshouai-assistant.md', 'https://github.com/kyegomez/swarms': '/content/kyegomez_swarms.md', 'https://github.com/Azure-Samples/azure-search-power-skills': '/content/Azure-Samples_azure-search-power-skills.md', 'https://github.com/chakkaradeep/pyCodeAGI': '/content/chakkaradeep_pyCodeAGI.md', 'https://github.com/ethanyanjiali/minChatGPT': '/content/ethanyanjiali_minChatGPT.md', 'https://github.com/ccurme/yolopandas': '/content/ccurme_yolopandas.md', 'https://github.com/ju-bezdek/langchain-decorators': '/content/ju-bezdek_langchain-decorators.md', 'https://github.com/Azure-Samples/azure-search-openai-demo-csharp': '/content/Azure-Samples_azure-search-openai-demo-csharp.md', 'https://github.com/fengyuli-dev/multimedia-gpt': '/content/fengyuli-dev_multimedia-gpt.md', 'https://github.com/grumpyp/aixplora': '/content/grumpyp_aixplora.md', 'https://github.com/langchain-ai/web-explorer': '/content/langchain-ai_web-explorer.md', 'https://github.com/JorisdeJong123/7-Days-of-LangChain': '/content/JorisdeJong123_7-Days-of-LangChain.md', 'https://github.com/Azure-Samples/jp-azureopenai-samples': '/content/Azure-Samples_jp-azureopenai-samples.md', 'https://github.com/AkshitIreddy/Interactive-LLM-Powered-NPCs': '/content/AkshitIreddy_Interactive-LLM-Powered-NPCs.md', 'https://github.com/ibiscp/LLM-IMDB': '/content/ibiscp_LLM-IMDB.md', 'https://github.com/jmpaz/promptlib': '/content/jmpaz_promptlib.md', 'https://github.com/mayooear/private-chatbot-mpt30b-langchain': '/content/mayooear_private-chatbot-mpt30b-langchain.md', 'https://github.com/homanp/vercel-langchain': '/content/homanp_vercel-langchain.md', 'https://github.com/mlops-for-all/mlops-for-all.github.io': '/content/mlops-for-all_mlops-for-all.github.io.md', 'https://github.com/Agenta-AI/agenta': '/content/Agenta-AI_agenta.md', 'https://github.com/Klingefjord/chatgpt-telegram': '/content/Klingefjord_chatgpt-telegram.md', 'https://github.com/menloparklab/falcon-langchain': '/content/menloparklab_falcon-langchain.md', 'https://github.com/deeppavlov/dream': '/content/deeppavlov_dream.md', 'https://github.com/positive666/Prompt-Can-Anything': '/content/positive666_Prompt-Can-Anything.md', 'https://github.com/menloparklab/langchain-cohere-qdrant-doc-retrieval': '/content/menloparklab_langchain-cohere-qdrant-doc-retrieval.md', 'https://github.com/realminchoi/babyagi-ui': '/content/realminchoi_babyagi-ui.md', 'https://github.com/SpecterOps/Nemesis': '/content/SpecterOps_Nemesis.md', 'https://github.com/Jaseci-Labs/jaseci': '/content/Jaseci-Labs_jaseci.md', 'https://github.com/peterw/StoryStorm': '/content/peterw_StoryStorm.md', 'https://github.com/Aggregate-Intellect/practical-llms': '/content/Aggregate-Intellect_practical-llms.md', 'https://github.com/streamlit/llm-examples': '/content/streamlit_llm-examples.md', 'https://github.com/hirokidaichi/wanna': '/content/hirokidaichi_wanna.md', 'https://github.com/Chainlit/cookbook': '/content/Chainlit_cookbook.md', 'https://github.com/alphasecio/langchain-examples': '/content/alphasecio_langchain-examples.md', 'https://github.com/flurb18/AgentOoba': '/content/flurb18_AgentOoba.md', 'https://github.com/yasyf/summ': '/content/yasyf_summ.md', 'https://github.com/v7labs/benchllm': '/content/v7labs_benchllm.md', 'https://github.com/ray-project/langchain-ray': '/content/ray-project_langchain-ray.md', 'https://github.com/petehunt/langchain-github-bot': '/content/petehunt_langchain-github-bot.md', 'https://github.com/peterwnjenga/aigent': '/content/peterwnjenga_aigent.md', 'https://github.com/jina-ai/fastapi-serve': '/content/jina-ai_fastapi-serve.md', 'https://github.com/retr0reg/Ret2GPT': '/content/retr0reg_Ret2GPT.md', 'https://github.com/eunomia-bpf/GPTtrace': '/content/eunomia-bpf_GPTtrace.md', 'https://github.com/aurelio-labs/arxiv-bot': '/content/aurelio-labs_arxiv-bot.md', 'https://github.com/ChuloAI/BrainChulo': '/content/ChuloAI_BrainChulo.md', 'https://github.com/ssheng/BentoChain': '/content/ssheng_BentoChain.md', 'https://github.com/mallahyari/drqa': '/content/mallahyari_drqa.md', 'https://github.com/fixie-ai/fixie-examples': '/content/fixie-ai_fixie-examples.md', 'https://github.com/davila7/file-gpt': '/content/davila7_file-gpt.md', 'https://github.com/showlab/UniVTG': '/content/showlab_UniVTG.md', 'https://github.com/zenml-io/zenml-projects': '/content/zenml-io_zenml-projects.md', 'https://github.com/RedisVentures/redis-openai-qna': '/content/RedisVentures_redis-openai-qna.md', 'https://github.com/PJLab-ADG/DriveLikeAHuman': '/content/PJLab-ADG_DriveLikeAHuman.md', 'https://github.com/prof-frink-lab/slangchain': '/content/prof-frink-lab_slangchain.md', 'https://github.com/Coding-Crashkurse/Langchain-Full-Course': '/content/Coding-Crashkurse_Langchain-Full-Course.md', 'https://github.com/ciare-robotics/world-creator': '/content/ciare-robotics_world-creator.md', 'https://github.com/langchain-ai/langsmith-cookbook': '/content/langchain-ai_langsmith-cookbook.md', 'https://github.com/OpenPluginACI/openplugin': '/content/OpenPluginACI_openplugin.md', 'https://github.com/defenseunicorns/leapfrogai': '/content/defenseunicorns_leapfrogai.md', 'https://github.com/sdaaron/QueryGPT': '/content/sdaaron_QueryGPT.md', 'https://github.com/grumpyp/chroma-langchain-tutorial': '/content/grumpyp_chroma-langchain-tutorial.md', 'https://github.com/3Alan/DocsMind': '/content/3Alan_DocsMind.md', 'https://github.com/CodeAlchemyAI/ViLT-GPT': '/content/CodeAlchemyAI_ViLT-GPT.md', 'https://github.com/emarco177/ice_breaker': '/content/emarco177_ice_breaker.md', 'https://github.com/nftblackmagic/flask-langchain': '/content/nftblackmagic_flask-langchain.md', 'https://github.com/log1stics/voice-generator-webui': '/content/log1stics_voice-generator-webui.md', 'https://github.com/nrl-ai/pautobot': '/content/nrl-ai_pautobot.md', 'https://github.com/Azure/business-process-automation': '/content/Azure_business-process-automation.md', 'https://github.com/MedalCollector/Orator': '/content/MedalCollector_Orator.md', 'https://github.com/wombyz/HormoziGPT': '/content/wombyz_HormoziGPT.md', 'https://github.com/afaqueumer/DocQA': '/content/afaqueumer_DocQA.md', 'https://github.com/mortium91/langchain-assistant': '/content/mortium91_langchain-assistant.md', 'https://github.com/Azure/azure-sdk-tools': '/content/Azure_azure-sdk-tools.md', 'https://github.com/yeagerai/genworlds': '/content/yeagerai_genworlds.md', 'https://github.com/AmineDiro/cria': '/content/AmineDiro_cria.md', 'https://github.com/langchain-ai/text-split-explorer': '/content/langchain-ai_text-split-explorer.md', 'https://github.com/luisroque/large_laguage_models': '/content/luisroque_large_laguage_models.md', 'https://github.com/xuwenhao/mactalk-ai-course': '/content/xuwenhao_mactalk-ai-course.md', 'https://github.com/langchain-ai/langchain-aws-template': '/content/langchain-ai_langchain-aws-template.md', 'https://github.com/aws-samples/aws-genai-llm-chatbot': '/content/aws-samples_aws-genai-llm-chatbot.md', 'https://github.com/crosleythomas/MirrorGPT': '/content/crosleythomas_MirrorGPT.md', 'https://github.com/Dicklesworthstone/llama2_aided_tesseract': '/content/Dicklesworthstone_llama2_aided_tesseract.md'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(github_urls)):\n",
        "\n",
        "    url = github_urls[i]\n",
        "\n",
        "    star_num = star_nums[i]\n",
        "\n",
        "    summary = ''\n",
        "\n",
        "    repo_name = re.search(r'github.com/(.+)', url).group(1)\n",
        "\n",
        "    if url in url2summary.keys():\n",
        "\n",
        "        save_name = url2summary[url]\n",
        "\n",
        "        # read save_name in utf-8 code\n",
        "        with open(save_name, 'r', encoding='utf-8') as f:\n",
        "            summary = f.read()\n",
        "\n",
        "    print('---\\n')\n",
        "    print(f'{star_num} [{repo_name}]({url})\\n')\n",
        "    print(summary)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTYup_IugKmw",
        "outputId": "14f7b90b-4906-4716-fc8a-53f3cfb12f44"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "\n",
            "46276 [openai/openai-cookbook](https://github.com/openai/openai-cookbook)\n",
            "\n",
            "这个GitHub仓库是OpenAI Cookbook，它分享了使用OpenAI API完成常见任务的示例代码。\n",
            "\n",
            "该仓库的功能和创新点包括：\n",
            "\n",
            "1. 提供了使用OpenAI API的示例代码，涵盖了多个领域和应用，如API使用、GPT模型、嵌入、Fine-tuning GPT-3、DALL-E、Whisper等。\n",
            "2. 提供了针对不同任务和应用的指南和示例，帮助用户理解和使用OpenAI API。\n",
            "3. 示例代码大部分使用Python编写，但其中的概念可以应用于任何编程语言。\n",
            "4. 最近添加/更新的部分列出了最新的示例代码，包括如何微调聊天模型、如何评估抽象摘要、如何使用搜索API和重新排序进行问答等。\n",
            "5. 提供了与OpenAI API相关的资源链接，包括OpenAI Playground、OpenAI文档、OpenAI帮助中心、OpenAI社区论坛等，帮助用户更好地了解和使用OpenAI API。\n",
            "6. 在\"Related resources from around the web\"部分，列出了一些与GPT相关的工具和论文，包括用于提示生成的库和工具、提示工程指南等。\n",
            "\n",
            "总之，OpenAI Cookbook是一个开源的GitHub仓库，提供了使用OpenAI API的示例代码和指南，帮助用户在各种任务和应用中使用OpenAI API，并提供了与GPT相关的其他资源链接。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/final_output.md', 'w', encoding='utf-8') as f:\n",
        "\n",
        "    for i in range(len(github_urls)):\n",
        "\n",
        "        url = github_urls[i]\n",
        "\n",
        "        star_num = star_nums[i]\n",
        "\n",
        "        summary = ''\n",
        "\n",
        "        repo_name = re.search(r'github.com/(.+)', url).group(1)\n",
        "\n",
        "        if url in url2summary.keys():\n",
        "\n",
        "            save_name = url2summary[url]\n",
        "\n",
        "            # read save_name in utf-8 code\n",
        "            with open(save_name, 'r', encoding='utf-8') as f_current:\n",
        "                summary = f_current.read()\n",
        "\n",
        "        f.write('\\n---\\n')\n",
        "        f.write(f'\\n{star_num} [{repo_name}]({url})\\n')\n",
        "        f.write(summary)"
      ],
      "metadata": {
        "id": "v1a-74O4gM6_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oTMaRKymhICt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}