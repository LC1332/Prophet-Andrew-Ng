{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/prompt-ng-andrew/blob/main/content/5.%20%E6%8E%A8%E6%96%AD%20Inferring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 吴恩达老师的Prompt Engineering课程学习\n",
        "\n",
        "本项目由李鲁鲁老师在DataWhale翻译的中文版本的吴恩达老师与 OpenAI 合作推出的 《ChatGPT Prompt Engineering for Developers》基础上，进行了一些自己的实践思考。\n",
        "\n",
        "项目链接 [https://github.com/LC1332/prompt-ng-andrew](https://github.com/LC1332/prompt-ng-andrew)\n",
        "\n",
        "原来DataWhale项目的链接是 [https://github.com/datawhalechina/prompt-engineering-for-developers](https://github.com/datawhalechina/prompt-engineering-for-developers)\n",
        "\n",
        "每一课都在colab上进行了改造，并将链接放在了readme，可以直接用colab进行学习。"
      ],
      "metadata": {
        "id": "IsCdF9AVQOPS"
      },
      "id": "IsCdF9AVQOPS"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai\n",
        "! pip install python-dotenv"
      ],
      "metadata": {
        "id": "AeyuzeSKTySX"
      },
      "id": "AeyuzeSKTySX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3630c235-f891-4874-bd0a-5277d4d6aa82",
      "metadata": {
        "id": "3630c235-f891-4874-bd0a-5277d4d6aa82"
      },
      "source": [
        "# 推断\n",
        "\n",
        "在这节课中，你将从产品评论和新闻文章中推断情感和主题。\n",
        "\n",
        "这些任务可以看作是模型接收文本作为输入并执行某种分析的过程。这可能涉及提取标签、提取实体、理解文本情感等等。如果你想要从一段文本中提取正面或负面情感，在传统的机器学习工作流程中，需要收集标签数据集、训练模型、确定如何在云端部署模型并进行推断。这样做可能效果还不错，但是这个过程需要很多工作。而且对于每个任务，如情感分析、提取实体等等，都需要训练和部署单独的模型。\n",
        "\n",
        "大型语言模型的一个非常好的特点是，对于许多这样的任务，你只需要编写一个prompt即可开始产生结果，而不需要进行大量的工作。这极大地加快了应用程序开发的速度。你还可以只使用一个模型和一个 API 来执行许多不同的任务，而不需要弄清楚如何训练和部署许多不同的模型。\n",
        "\n",
        "\n",
        "## 启动"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a821d943",
      "metadata": {
        "height": 132,
        "id": "a821d943"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY2\")\n",
        "openai.api_key = 'sk-' # 在这里输入你的OpenAI API token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e82f5577",
      "metadata": {
        "height": 164,
        "id": "e82f5577"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51d2fdfa-c99f-4750-8574-dba7712cd7f0",
      "metadata": {
        "id": "51d2fdfa-c99f-4750-8574-dba7712cd7f0"
      },
      "source": [
        "## 商品评论文本\n",
        "\n",
        "这是一盏台灯的评论。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b0f3b49b",
      "metadata": {
        "height": 200,
        "id": "b0f3b49b"
      },
      "outputs": [],
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had \\\n",
        "additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the \\\n",
        "transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put \\\n",
        "together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! \\\n",
        "Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bc6260f0",
      "metadata": {
        "id": "bc6260f0"
      },
      "outputs": [],
      "source": [
        "# 中文\n",
        "lamp_review_zh = \"\"\"\n",
        "我需要一盏漂亮的卧室灯，这款灯具有额外的储物功能，价格也不算太高。\\\n",
        "我很快就收到了它。在运输过程中，我们的灯绳断了，但是公司很乐意寄送了一个新的。\\\n",
        "几天后就收到了。这款灯很容易组装。我发现少了一个零件，于是联系了他们的客服，他们很快就给我寄来了缺失的零件！\\\n",
        "在我看来，Lumina 是一家非常关心顾客和产品的优秀公司！\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30d6e4bd-3337-45a3-8c99-a734cdd06743",
      "metadata": {
        "id": "30d6e4bd-3337-45a3-8c99-a734cdd06743"
      },
      "source": [
        "## 情感（正向/负向）\n",
        "\n",
        "现在让我们来编写一个prompt来分类这个评论的情感。如果我想让系统告诉我这个评论的情感是什么，只需要编写 “以下产品评论的情感是什么” 这个prompt，加上通常的分隔符和评论文本等等。\n",
        "\n",
        "然后让我们运行一下。结果显示这个产品评论的情感是积极的，这似乎是非常正确的。虽然这盏台灯不完美，但这个客户似乎非常满意。这似乎是一家关心客户和产品的伟大公司，可以认为积极的情感似乎是正确的答案。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e3157601",
      "metadata": {
        "height": 149,
        "id": "e3157601",
        "outputId": "2f0ce76e-a9a1-4629-c22a-539564d37402",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the product review is positive.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review, \n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Review text: ```{lamp_review}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ac5b0bb9",
      "metadata": {
        "id": "ac5b0bb9",
        "outputId": "ed1c7f9e-d9ed-4b3f-d3b7-cedf789eed7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "情感是积极的/正面的。\n"
          ]
        }
      ],
      "source": [
        "# 中文\n",
        "prompt = f\"\"\"\n",
        "以下用三个反引号分隔的产品评论的情感是什么？\n",
        "\n",
        "评论文本: ```{lamp_review_zh}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76be2320",
      "metadata": {
        "id": "76be2320"
      },
      "source": [
        "如果你想要给出更简洁的答案，以便更容易进行后处理，可以使用上面的prompt并添加另一个指令，以一个单词 “正面” 或 “负面” 的形式给出答案。这样就只会打印出 “正面” 这个单词，这使得文本更容易接受这个输出并进行处理。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "acf9ca16",
      "metadata": {
        "height": 200,
        "id": "acf9ca16",
        "outputId": "1cab6079-be2a-49a7-d4d8-cf2b7068945c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review, \n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Give your answer as a single word, either \"positive\" \\\n",
        "or \"negative\".\n",
        "\n",
        "Review text: ```{lamp_review}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "84a761b3",
      "metadata": {
        "id": "84a761b3",
        "outputId": "d970ed58-36f8-48e1-d120-57bf330ac57c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正面\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "以下用三个反引号分隔的产品评论的情感是什么？\n",
        "\n",
        "用一个单词回答：\"正面\"或\"负面\"。\n",
        "\n",
        "评论文本: ```{lamp_review_zh}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81d2a973-1fa4-4a35-ae35-a2e746c0e91b",
      "metadata": {
        "id": "81d2a973-1fa4-4a35-ae35-a2e746c0e91b"
      },
      "source": [
        "## 识别情感类型\n",
        "\n",
        "让我们看看另一个prompt，仍然使用台灯评论。这次我要让它识别出以下评论作者所表达的情感列表，不超过五个。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8aa7934b",
      "metadata": {
        "height": 183,
        "id": "8aa7934b",
        "outputId": "8b10bd4a-b7cf-4b9e-bd82-971728cac2de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "satisfied, grateful, impressed, content, pleased\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the \\\n",
        "following review is expressing. Include no more than \\\n",
        "five items in the list. Format your answer as a list of \\\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: ```{lamp_review}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e615c13a",
      "metadata": {
        "id": "e615c13a",
        "outputId": "eee60180-ccbe-476b-ee8f-4d58293babce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "满意,感激,信任,赞扬,愉快\n"
          ]
        }
      ],
      "source": [
        "# 中文\n",
        "prompt = f\"\"\"\n",
        "识别以下评论的作者表达的情感。包含不超过五个项目。将答案格式化为以逗号分隔的单词列表。\n",
        "\n",
        "评论文本: ```{lamp_review_zh}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc4444f7",
      "metadata": {
        "id": "cc4444f7"
      },
      "source": [
        "大型语言模型非常擅长从一段文本中提取特定的东西。在上面的例子中，评论正在表达情感，这可能有助于了解客户如何看待特定的产品。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "李鲁鲁： 这里我有点好奇拿修仙小说里面的描述，会怎么样，让我们来试一下\n",
        "\n",
        "这个片段是老魔第一次看到南宫婉"
      ],
      "metadata": {
        "id": "zOxd6u3HUgAZ"
      },
      "id": "zOxd6u3HUgAZ"
    },
    {
      "cell_type": "code",
      "source": [
        "fiction_text = \"\"\"\n",
        "一个狭长的地下山洞内，悄然无声的走着一行白衣男女，看人数约有十五六人左右，竟是所有禁地内活下来的掩月宗弟子都在了此地，而走在最前面的，就是曾远远见过韩立一面的那位精灵一样的少女！\n",
        "\n",
        "白衣少女虽然面似童真清纯，此时却神情肃然，全身上下笼罩在了一层奇异的银辉之下，让人显得越发的神秘诡异！\n",
        "\n",
        "最让人惊讶的是，跟在少女身后的白衣男女全都一副兢兢战战的模样，竟连一个窃窃私语小声嘀咕的都没有，望向少女背影的眼神更是充满了敬畏之色！\n",
        "\n",
        "而曾在沙地出现过的刁蛮女子与她的修炼道侣也身在其中，只是脸上的骄横之色已无影无踪，和旁人一样的大气也不敢喘一下，显得格外的乖巧老实！\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "识别以下评论的作者表达的情感。包含不超过五个项目。将答案格式化为以逗号分隔的单词列表。\n",
        "\n",
        "评论文本: ```{fiction_text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "WDD6OxVRUmg6",
        "outputId": "a3218aa2-2381-48ac-ce68-2214af55286d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WDD6OxVRUmg6",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "神秘, 敬畏, 惊讶, 乖巧, 肃然\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a428d093-51c9-461c-b41e-114e80876409",
      "metadata": {
        "id": "a428d093-51c9-461c-b41e-114e80876409"
      },
      "source": [
        "## 识别愤怒\n",
        "\n",
        "对于很多企业来说，了解某个顾客是否非常生气很重要。所以你可能有一个类似这样的分类问题：以下评论的作者是否表达了愤怒情绪？因为如果有人真的很生气，那么可能值得额外关注，让客户支持或客户成功团队联系客户以了解情况，并为客户解决问题。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dba1a538",
      "metadata": {
        "height": 166,
        "id": "dba1a538",
        "outputId": "c1248961-28de-42f6-81c4-34bbb40eaa1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Is the writer of the following review expressing anger?\\\n",
        "The review is delimited with triple backticks. \\\n",
        "Give your answer as either yes or no.\n",
        "\n",
        "Review text: ```{lamp_review}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "85bad324",
      "metadata": {
        "id": "85bad324",
        "outputId": "9f47de90-a105-4977-a044-976824ba423b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "否\n"
          ]
        }
      ],
      "source": [
        "# 中文\n",
        "prompt = f\"\"\"\n",
        "以下评论的作者是否表达了愤怒？评论用三个反引号分隔。给出是或否的答案。\n",
        "\n",
        "评论文本: ```{lamp_review_zh}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ca57a2",
      "metadata": {
        "id": "11ca57a2"
      },
      "source": [
        "上面这个例子中，客户并没有生气。注意，如果使用常规的监督学习，如果想要建立所有这些分类器，不可能在几分钟内就做到这一点。我们鼓励大家尝试更改一些这样的prompt，也许询问客户是否表达了喜悦，或者询问是否有任何遗漏的部分，并看看是否可以让prompt对这个灯具评论做出不同的推论。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "936a771e-ca78-4e55-8088-2da6f3820ddc",
      "metadata": {
        "id": "936a771e-ca78-4e55-8088-2da6f3820ddc"
      },
      "source": [
        "## 从客户评论中提取产品和公司名称\n",
        "\n",
        "接下来，让我们从客户评论中提取更丰富的信息。信息提取是自然语言处理（NLP）的一部分，与从文本中提取你想要知道的某些事物相关。因此，在这个prompt中，我要求它识别以下内容：购买物品和制造物品的公司名称。\n",
        "\n",
        "同样，如果你试图总结在线购物电子商务网站的许多评论，对于这些评论来说，弄清楚是什么物品，谁制造了该物品，弄清楚积极和消极的情感，以跟踪特定物品或特定制造商的积极或消极情感趋势，可能会很有用。\n",
        "\n",
        "在下面这个示例中，我们要求它将响应格式化为一个 JSON 对象，其中物品和品牌是键。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a13bea1b",
      "metadata": {
        "height": 285,
        "id": "a13bea1b",
        "outputId": "acdbefa2-e01c-4e8f-997c-dadadc247534",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Item\": \"lamp with additional storage\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text: \n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Item\" and \"Brand\" as the keys. \n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "  \n",
        "Review text: ```{lamp_review}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e9ffe056",
      "metadata": {
        "id": "e9ffe056",
        "outputId": "34b19316-40d2-4ef9-f0bf-7e60f407f636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"物品\": \"卧室灯\",\n",
            "  \"品牌\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# 中文\n",
        "prompt = f\"\"\"\n",
        "从评论文本中识别以下项目：\n",
        "- 评论者购买的物品\n",
        "- 制造该物品的公司\n",
        "\n",
        "评论文本用三个反引号分隔。将你的响应格式化为以 “物品” 和 “品牌” 为键的 JSON 对象。\n",
        "如果信息不存在，请使用 “未知” 作为值。\n",
        "让你的回应尽可能简短。\n",
        "  \n",
        "评论文本: ```{lamp_review_zh}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "954d125d",
      "metadata": {
        "id": "954d125d"
      },
      "source": [
        "如上所示，它会说这个物品是一个卧室灯，品牌是 Luminar，你可以轻松地将其加载到 Python 字典中，然后对此输出进行其他处理。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a38880a5-088f-4609-9913-f8fa41fb7ba0",
      "metadata": {
        "id": "a38880a5-088f-4609-9913-f8fa41fb7ba0"
      },
      "source": [
        "## 一次完成多项任务\n",
        "\n",
        "提取上面所有这些信息使用了 3 或 4 个prompt，但实际上可以编写单个prompt来同时提取所有这些信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e7dda9e5",
      "metadata": {
        "height": 336,
        "id": "e7dda9e5",
        "outputId": "68be6034-a0f1-4ba5-ebce-9566f582fe02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Sentiment\": \"positive\",\n",
            "  \"Anger\": false,\n",
            "  \"Item\": \"lamp with additional storage\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text: \n",
        "- Sentiment (positive or negative)\n",
        "- Is the reviewer expressing anger? (true or false)\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "Format the Anger value as a boolean.\n",
        "\n",
        "Review text: ```{lamp_review}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "939c2b0e",
      "metadata": {
        "scrolled": true,
        "id": "939c2b0e",
        "outputId": "24bcc82f-c48f-46bd-bc71-414947a4c55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Sentiment\": \"正面\",\n",
            "  \"Anger\": false,\n",
            "  \"Item\": \"卧室灯\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# 中文\n",
        "prompt = f\"\"\"\n",
        "从评论文本中识别以下项目：\n",
        "- 情绪（正面或负面）\n",
        "- 审稿人是否表达了愤怒？（是或否）\n",
        "- 评论者购买的物品\n",
        "- 制造该物品的公司\n",
        "\n",
        "评论用三个反引号分隔。将您的响应格式化为 JSON 对象，以 “Sentiment”、“Anger”、“Item” 和 “Brand” 作为键。\n",
        "如果信息不存在，请使用 “未知” 作为值。\n",
        "让你的回应尽可能简短。\n",
        "将 Anger 值格式化为布尔值。\n",
        "\n",
        "评论文本: ```{lamp_review_zh}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e09a673",
      "metadata": {
        "id": "5e09a673"
      },
      "source": [
        "这个例子中，我们告诉它将愤怒值格式化为布尔值，然后输出一个 JSON。大家可以自己尝试不同的变化，或者甚至尝试完全不同的评论，看看是否仍然可以准确地提取这些内容。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235fc223-2c89-49ec-ac2d-78a8e74a43ac",
      "metadata": {
        "id": "235fc223-2c89-49ec-ac2d-78a8e74a43ac"
      },
      "source": [
        "## 推断主题\n",
        "\n",
        "大型语言模型的一个很酷的应用是推断主题。给定一段长文本，这段文本是关于什么的？有什么话题？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8a74cc3e",
      "metadata": {
        "height": 472,
        "id": "8a74cc3e"
      },
      "outputs": [],
      "source": [
        "story = \"\"\"\n",
        "In a recent survey conducted by the government, \n",
        "public sector employees were asked to rate their level \n",
        "of satisfaction with the department they work at. \n",
        "The results revealed that NASA was the most popular \n",
        "department with a satisfaction rating of 95%.\n",
        "\n",
        "One NASA employee, John Smith, commented on the findings, \n",
        "stating, \"I'm not surprised that NASA came out on top. \n",
        "It's a great place to work with amazing people and \n",
        "incredible opportunities. I'm proud to be a part of \n",
        "such an innovative organization.\"\n",
        "\n",
        "The results were also welcomed by NASA's management team, \n",
        "with Director Tom Johnson stating, \"We are thrilled to \n",
        "hear that our employees are satisfied with their work at NASA. \n",
        "We have a talented and dedicated team who work tirelessly \n",
        "to achieve our goals, and it's fantastic to see that their \n",
        "hard work is paying off.\"\n",
        "\n",
        "The survey also revealed that the \n",
        "Social Security Administration had the lowest satisfaction \n",
        "rating, with only 45% of employees indicating they were \n",
        "satisfied with their job. The government has pledged to \n",
        "address the concerns raised by employees in the survey and \n",
        "work towards improving job satisfaction across all departments.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "811ff13f",
      "metadata": {
        "id": "811ff13f"
      },
      "outputs": [],
      "source": [
        "# 中文\n",
        "story_zh = \"\"\"\n",
        "在政府最近进行的一项调查中，要求公共部门的员工对他们所在部门的满意度进行评分。\n",
        "调查结果显示，NASA 是最受欢迎的部门，满意度为 95％。\n",
        "\n",
        "一位 NASA 员工 John Smith 对这一发现发表了评论，他表示：\n",
        "“我对 NASA 排名第一并不感到惊讶。这是一个与了不起的人们和令人难以置信的机会共事的好地方。我为成为这样一个创新组织的一员感到自豪。”\n",
        "\n",
        "NASA 的管理团队也对这一结果表示欢迎，主管 Tom Johnson 表示：\n",
        "“我们很高兴听到我们的员工对 NASA 的工作感到满意。\n",
        "我们拥有一支才华横溢、忠诚敬业的团队，他们为实现我们的目标不懈努力，看到他们的辛勤工作得到回报是太棒了。”\n",
        "\n",
        "调查还显示，社会保障管理局的满意度最低，只有 45％的员工表示他们对工作满意。\n",
        "政府承诺解决调查中员工提出的问题，并努力提高所有部门的工作满意度。\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8ea91d6-e841-4ee2-bed9-ca4a36df177f",
      "metadata": {
        "id": "a8ea91d6-e841-4ee2-bed9-ca4a36df177f"
      },
      "source": [
        "## 推断5个主题\n",
        "\n",
        "上面是一篇虚构的关于政府工作人员对他们工作机构感受的报纸文章。我们可以让它确定五个正在讨论的主题，用一两个字描述每个主题，并将输出格式化为逗号分隔的列表。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5c267cbe",
      "metadata": {
        "height": 217,
        "id": "5c267cbe",
        "outputId": "13c873f1-c9d6-49c1-cbcd-4c879830ad54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "government survey, public sector employees, job satisfaction, NASA, Social Security Administration\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the \\\n",
        "following text, which is delimited by triple backticks.\n",
        "\n",
        "Make each item one or two words long. \n",
        "\n",
        "Format your response as a list of items separated by commas.\n",
        "\n",
        "Text sample: ```{story}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f92f90fe",
      "metadata": {
        "height": 30,
        "scrolled": true,
        "id": "f92f90fe",
        "outputId": "ad1c6e29-3d21-4ae6-8f92-b281dc3431ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['government survey',\n",
              " ' public sector employees',\n",
              " ' job satisfaction',\n",
              " ' NASA',\n",
              " ' Social Security Administration']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "response.split(sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cab27b65",
      "metadata": {
        "id": "cab27b65",
        "outputId": "ca216ad2-6d1d-49c8-c40d-2bc64000cd1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "公共部门满意度调查, NASA, 社会保障管理局, 员工满意度, 政府承诺\n"
          ]
        }
      ],
      "source": [
        "# 中文\n",
        "prompt = f\"\"\"\n",
        "确定以下给定文本中讨论的五个主题。\n",
        "\n",
        "每个主题用1-2个单词概括。\n",
        "\n",
        "输出时用逗号分割每个主题。\n",
        "\n",
        "给定文本: ```{story_zh}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "李鲁鲁：我们继续拿凡人修仙传来玩一下\n",
        "\n"
      ],
      "metadata": {
        "id": "FKfRyqGdWfYl"
      },
      "id": "FKfRyqGdWfYl"
    },
    {
      "cell_type": "code",
      "source": [
        "long_fiction = \"\"\"\n",
        "修成之后，这门神通在对敌时，能借助飞剑的剑光，另行幻化出一道和飞剑一模一样的剑影来，可迷幻敌人的视线并跟随本体一同攻击敌人。虽然剑影初成时，只有本体的威力十分之一，但随着剑诀层次的提升，其威力还可增加，到了第九层时就可有了三分之一的威力了。\n",
        "\n",
        "    而且剑影在修炼时，可幻化的并不止一道，从第七层开始时每升一层就可多炼化出一道剑影。如此一来，青元剑诀炼至了极致，就可同时有三道和飞剑外观一样，但威力只有三分之一的剑影。\n",
        "\n",
        "    这样看来，这“剑光分影术”的神通似乎不赖，还可一修的样子。\n",
        "\n",
        "    但韩立已经知道，黄枫谷这么多筑基期的修士，并没有谁真的将其深炼下去，这其中的猫腻肯定小不了！因此他大为后悔，为何当初没有打听清楚其中的缘由，只以为肯定不会修炼这青元剑诀，所以就大大咧咧的马虎过去了。\n",
        "\n",
        "    到如今，韩立虽然明知此法决大有问题，可还不得不硬着头皮去修炼一下，只希望此法决可别有什么类似走火入魔的后患才行。\n",
        "\n",
        "    不过他也转念想过，其他人虽然没有深加修炼，可也有两三层在身的样子。这样看来，稍微修炼一下也没什么大问题才对。\n",
        "\n",
        "    抱着这种自我安慰的想法，韩立无奈的按照青元剑诀的法门，吸纳起了体内快要发作的药力。\n",
        "\n",
        "    此功法只简单的运行了一个循环，韩立就感到轰得一下，这种吸纳了药力让法力暴涨的感觉，让他舒畅的差点叫出声来！\n",
        "\n",
        "    沉浸在这种美妙滋味中的韩立，不由得让法决一遍遍的循环下去，而神智却渐渐的神游天外了。\n",
        "\n",
        "    不知打坐了多长时间，当韩立将体内的最后一丝药力吸纳干净的时候，终于从种美妙的体验中苏醒了过来。\n",
        "\n",
        "    清醒过来的韩立，稍微呆滞了一下，但随后二话不说的站起身来。然后眯起眼睛歪头想了一下，就突然抬起手臂在身前比划了一下，顿时从手指上窜出了尺许长的一截青濛濛剑芒，寒气逼人，锋利无比的样子。\n",
        "\n",
        "    见此寒光，韩立非但没高兴，反而苦笑了起来！然后手臂突然一甩，青光竟然猛然暴涨，一下变成了一丈多长，几乎就要插入对面的石墙内。\n",
        "\n",
        "     “这下糟了，没想到残余的药力这么强，竟然一下炼成了第四层的剑诀，不知道会不会有大碍啊！”韩立脸上阴晴不定的嘀咕道。\n",
        "\n",
        "    “不管了，顶多以后不再修炼此剑决就是了！”韩立喃喃的说道，接着把手臂一放，青色剑芒就消失了。\n",
        "\n",
        "    不过，好奇心大起的韩立，还是捡起那本《青元剑诀》，翻看了有关护体剑盾的法决并，并默记了几遍。\n",
        "\n",
        "    接着，韩立低头沉思了一下后，闭起了双目，紧接着再猛一睁眼，身上已出现了一个奇特的护盾。\n",
        "\n",
        "    此护盾通体青色，和普通的防御罩差不多大小，但表面不再是通常的平滑形态，而表现出刺猬一样的芒刺状，看上去隐隐有种煞气透露出来。\n",
        "\n",
        "    “这就是护体剑盾？”韩立仔细观察着身上的刺盾，有些惊讶。\n",
        "\n",
        "    “剑诀上说，此盾可以自行释放剑芒，反击敌人。可惜现在无法测试一下！”韩立颇为遗憾的想道。\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "确定以下给定文本中讨论的五个主题。\n",
        "\n",
        "每个主题用1-2个单词概括。\n",
        "\n",
        "输出时用逗号分割每个主题。\n",
        "\n",
        "给定文本: ```{long_fiction}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "OZoRnq0_WtW7",
        "outputId": "f6bb5154-87c9-4459-bd43-5ce17e510b22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OZoRnq0_WtW7",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "剑光分影术, 青元剑诀, 药力暴涨, 护体剑盾, 反击敌人\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "李鲁鲁：其实还挺好玩儿的。。。"
      ],
      "metadata": {
        "id": "lwInKfFOW9mM"
      },
      "id": "lwInKfFOW9mM"
    },
    {
      "cell_type": "markdown",
      "id": "34be1d2a-1309-4512-841a-b6f67338938b",
      "metadata": {
        "id": "34be1d2a-1309-4512-841a-b6f67338938b"
      },
      "source": [
        "## 为特定主题制作新闻提醒\n",
        "\n",
        "假设我们有一个新闻网站或类似的东西，这是我们感兴趣的主题：NASA、地方政府、工程、员工满意度、联邦政府等。假设我们想弄清楚，针对一篇新闻文章，其中涵盖了哪些主题。可以使用这样的prompt：确定以下主题列表中的每个项目是否是以下文本中的主题。以 0 或 1 的形式给出答案列表。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "94b8fa65",
      "metadata": {
        "height": 81,
        "id": "94b8fa65"
      },
      "outputs": [],
      "source": [
        "topic_list = [\n",
        "    \"nasa\", \"local government\", \"engineering\", \n",
        "    \"employee satisfaction\", \"federal government\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "626c5b8e",
      "metadata": {
        "height": 234,
        "id": "626c5b8e",
        "outputId": "47fd86e0-b7ee-4bfa-8f7c-502e5dd7f8e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nasa: 1\n",
            "local government: 0\n",
            "engineering: 0\n",
            "employee satisfaction: 1\n",
            "federal government: 1\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Determine whether each item in the following list of \\\n",
        "topics is a topic in the text below, which\n",
        "is delimited with triple backticks.\n",
        "\n",
        "Give your answer as list with 0 or 1 for each topic.\\\n",
        "\n",
        "List of topics: {\", \".join(topic_list)}\n",
        "\n",
        "Text sample: ```{story}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "902a7c74",
      "metadata": {
        "height": 79,
        "id": "902a7c74",
        "outputId": "875a5f31-ed20-4eb7-8cc6-d97ccbf8e300",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALERT: New NASA story!\n"
          ]
        }
      ],
      "source": [
        "topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\n",
        "if topic_dict['nasa'] == 1:\n",
        "    print(\"ALERT: New NASA story!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9f53d337",
      "metadata": {
        "id": "9f53d337",
        "outputId": "6c17301c-0457-42d7-c15e-5927846cfc99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "美国航空航天局：1\n",
            "地方政府：1\n",
            "工程：0\n",
            "员工满意度：1\n",
            "联邦政府：1\n"
          ]
        }
      ],
      "source": [
        "# 中文\n",
        "prompt = f\"\"\"\n",
        "判断主题列表中的每一项是否是给定文本中的一个话题，\n",
        "\n",
        "以列表的形式给出答案，每个主题用 0 或 1。\n",
        "\n",
        "主题列表：美国航空航天局、地方政府、工程、员工满意度、联邦政府\n",
        "\n",
        "给定文本: ```{story_zh}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08247dbf",
      "metadata": {
        "id": "08247dbf"
      },
      "source": [
        "所以，这个故事是关于 NASA 的。它不是关于地方政府的，不是关于工程的。它是关于员工满意度的，它是关于联邦政府的。这在机器学习中有时被称为 Zero-Shot 学习算法，因为我们没有给它任何标记的训练数据。仅凭prompt，它就能确定哪些主题在新闻文章中涵盖了。\n",
        "\n",
        "如果我们想生成一个新闻提醒，也可以使用这个处理新闻的过程。假设我非常喜欢 NASA 所做的工作，就可以构建一个这样的系统，每当 NASA 新闻出现时，输出提醒。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "53bf1abd",
      "metadata": {
        "id": "53bf1abd",
        "outputId": "4d7e3ffd-e710-4319-ce52-9fb0376fad2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "提醒: 关于美国航空航天局的新消息\n"
          ]
        }
      ],
      "source": [
        "topic_dict = {i.split('：')[0]: int(i.split('：')[1]) for i in response.split(sep='\\n')}\n",
        "if topic_dict['美国航空航天局'] == 1:\n",
        "    print(\"提醒: 关于美国航空航天局的新消息\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76ccd189",
      "metadata": {
        "id": "76ccd189"
      },
      "source": [
        "这就是关于推断的全部内容了，仅用几分钟时间，我们就可以构建多个用于对文本进行推理的系统，而以前则需要熟练的机器学习开发人员数天甚至数周的时间。这非常令人兴奋，无论是对于熟练的机器学习开发人员还是对于新手来说，都可以使用prompt来非常快速地构建和开始相当复杂的自然语言处理任务。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "李鲁鲁：可以试一下凡人那个文本"
      ],
      "metadata": {
        "id": "50WCxMu_XR7R"
      },
      "id": "50WCxMu_XR7R"
    },
    {
      "cell_type": "code",
      "source": [
        "# 中文\n",
        "prompt = f\"\"\"\n",
        "判断主题列表中的每一项是否是给定文本中的一个话题，\n",
        "\n",
        "以列表的形式给出答案，每个主题用 0 或 1。\n",
        "\n",
        "主题列表：黄枫谷、剑法、拳法、少林派、修仙、修炼、主动技能、防御技能、功法修炼、内功修炼、炼器、炼丹、种植草药\n",
        "\n",
        "给定文本: ```{long_fiction}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "n-asp8D3XUf1",
        "outputId": "5cef4d15-7707-4035-d853-477bbc69941b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "n-asp8D3XUf1",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "黄枫谷：1\n",
            "剑法：1\n",
            "拳法：0\n",
            "少林派：0\n",
            "修仙：1\n",
            "修炼：1\n",
            "主动技能：1\n",
            "防御技能：1\n",
            "功法修炼：1\n",
            "内功修炼：0\n",
            "炼器：0\n",
            "炼丹：0\n",
            "种植草药：0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f88408ae-469a-4b02-a043-f6b4f0b14bf9",
      "metadata": {
        "id": "f88408ae-469a-4b02-a043-f6b4f0b14bf9"
      },
      "source": [
        "## 尝试你的实验！"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "李鲁鲁：这一课其实非常有趣，特别后面那个一次性多分类的真的是学习了。"
      ],
      "metadata": {
        "id": "XIWYocNnXvcR"
      },
      "id": "XIWYocNnXvcR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bd3553f",
      "metadata": {
        "height": 30,
        "id": "1bd3553f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "256px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}